<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GaLore</title>
      <link href="/posts/10046.html"/>
      <url>/posts/10046.html</url>
      
        <content type="html"><![CDATA[<h1 id="The-problem-with-Lora"><a href="#The-problem-with-Lora" class="headerlink" title="The problem with Lora"></a>The problem with Lora</h1><p>Lora给出了一种非常 Parameter Efficient 的方法，通过更新两个额外的低秩矩阵来sft。</p><script type="math/tex; mode=display">W' = W + BAx</script><p>其中，$B \in \mathcal{R}^{m \times r}$，$A \in \mathcal{R}^{r \times n}$，$r \ll min(m, n)$</p><p>但是，参数矩阵并不满足低秩假设。根据线性代数的知识，我们知道 $rank(AB) \leq min(rank(A), rank(B))$，因此有:</p><script type="math/tex; mode=display">rank(BA) \leq r</script><p>倘若原矩阵 $rank(W) &gt;r$，则 lora 无论如何也无法很好地近似 full parameter 的更新。</p><blockquote><p>对 $rank(AB) \leq min(rank(A), rank(B))$ 的一种证明:</p><p>首先，$rank(A) = dim(Col(A)) = dim(Row(A)) = number(\text{pivots})$</p><p>考虑 $AB$ 的每一列 $AB_{[:, j]}$，我们能发现 $AB_{[:, j]} = \sum_{i=0}^{m-1} B_{[i, j]}A_{[:, i]}$</p><p>即 $AB$ 的每一列都是 $A$ 的列线性组合</p><p>所以 $rank(AB) = dim(Col(AB)) \leq dim(Col(A)) = rank(A)$， 直接转置再应用一下就可以得到完整的结论了。</p></blockquote><h1 id="Low-Rank-Property-of-Weight-Gradient"><a href="#Low-Rank-Property-of-Weight-Gradient" class="headerlink" title="Low-Rank Property of Weight Gradient"></a>Low-Rank Property of Weight Gradient</h1><p>However，Galore 这篇文章指出，虽然参数矩阵不见得是 low rank 的，不过可以证明，对于一类被称为 Reversible network 的网络结构，它们的梯度矩阵是低秩的。</p><h2 id="Reversible-network"><a href="#Reversible-network" class="headerlink" title="Reversible network"></a>Reversible network</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>一个网络 $\mathcal{N}$ 执行映射 $y = \mathcal{N}(x)$ 被称为 Reversible network 当：</p><ul><li>存在 $L(x, W)$ 使得 $y = L(x, W)x$，并且 $g_x = L^\top(x,W)g_y$</li></ul><p>其中 $g_x = \frac{\partial L}{\partial x}$，$g_y = \frac{\partial L}{\partial y}$</p><p>常见的不带偏置项bias的线性层，ReLU，leaky ReLU等激活函数，是Reversible network</p><p>定义这类网络是为了能够更加定量地分析各层梯度的数值表示，而不至于始终把梯度当作黑箱的形式</p><h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ul><li><p>线性性质：$\alpha_1 \mathcal{N}_1(x) + \alpha_2 \mathcal{N}_2(x)$ 仍然是 Reversible network</p></li><li><p>$\mathcal{N}_2(\mathcal{N}_1(x))$ 仍然是 Reversible network</p></li><li><p>$\mathcal{N}(x) = \frac{\partial \mathcal{N}(x)}{\partial x} x$</p></li></ul><p>第三个性质可以展开一点说，我们先说一下它的证明：</p><p>根据链式法则，我们知道 $g_x = (\frac{\partial y}{\partial x})^\top g_y$</p><p>与 $g_x = L^\top(x,W)g_y$ 对比后，我们知道 $(\frac{\partial y}{\partial x})^\top = L^\top(x,W)$，所以由 $y=L(x, W)x$，可得</p><script type="math/tex; mode=display">y = \frac{\partial y}{\partial x}x，\text{即} \mathcal{N}(x) = \frac{\partial \mathcal{N}(x)}{\partial x} x</script><p>这在数学上也是欧拉齐次函数定理的一种形式。欧拉齐次函数定理指出，一个函数 $f(x)$ 是 $m$ 阶齐次函数（即满足 $f(tx) = t^mf(x)$）的充要条件是 $\nabla f(x) \cdot x = mf(x) $。显然，Reversible Network 即是满足 $m=1$ 的一阶齐次函数。</p><p>既然 $\mathcal{N}(x)$ 是一阶齐次函数，那么 $\mathcal{N}(x)$ 满足 $\mathcal{N}(tx) = tN(x), \forall t &gt; 0$，对其两边求导，得到：</p><script type="math/tex; mode=display">\begin{aligned}t \frac{\text{d}\mathcal{N}(tx)}{\text{d} x} &= t \frac{\text{d}\mathcal{N}(x)}{\text{d} x} \\K(tx) &= K(x)\end{aligned}</script><p>所以一阶齐次函数对应的雅可比矩阵 $K(x) = \frac{\partial \mathcal{N}(x)}{\partial x}$ 必然是一个零阶齐次函数。</p><p>零阶齐次性并不意味着 $K(x)$ 与 $x$ 无关，有可能存在导函数阶跃的情况。</p><p>比如说Relu是一个符合要求的 Reversible Network，它的雅可比矩阵是:</p><script type="math/tex; mode=display">H(x)=\left\{\begin{aligned}1, \quad & x>0 \\0, \quad & x<0 \\\end{aligned}\right.</script><p>显然与 $x$ 有关</p><h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><p>设 $K_i$ 是第 $i$ 层的雅可比矩阵，也即 $K_l(x) = \frac{\partial N_l(f_{l-1})}{\partial f_{l-1}}$，所以</p><script type="math/tex; mode=display">\partial \mathcal{N}(x) = \partial \mathcal{N_L}(\mathcal{N_{L-1}(\cdots \mathcal{N_1}(x))}) = K_L(x)K_{L-1}(x)\cdots K_1(x) \partial x</script><p>我们可以展示一下，当损失函数为MSE loss时 $\varphi := \frac{1}{2}||y-f_L||_2^2$</p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= (\mathcal{N}(x)-y)\top\text{d}\mathcal{N}(x) \\&= (\mathcal{N}(x)-y)^\top K_L(x)K_{L-1}(x)\cdots K_{l+1}(x) \text{d}f_l \\\end{aligned}</script><p>因为 $f_l = W_lf_{l-1}$，所以 $\text{d}f_l = \text{d}W_lf_{l-1} + W_l\text{d}f_{l-1}$</p><p>我们的目标是分析到 $W_l$ 的梯度，因此可以忽略后一部分的微分</p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= (\mathcal{N}(x)-y)^\top K_L(x)K_{L-1}(x)\cdots K_L(x) \text{d}W_lf_{l-1} + \text{与d}W_l\text{无关的部分} \\\end{aligned}</script><p>令 $J_l := K_L(x) \cdots K_{l+1}(x)$</p><p>由 $\text{d} \mathcal{N}(x) = K_L(x)K_{L-1}(x)\cdots K_{l+1}(x) \text{d}f_l$ 与 $\mathcal{N}(x) = \frac{\partial \mathcal{N}(x)}{\partial x} x$，可得</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{N}(x) &= K_L(x)K_{L-1}(x)\cdots K_{l+1}(x) f_l \\&= J_l W_l f_{l-1}\end{aligned}</script><p>所以 </p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= (J_l W_l f_{l-1}-y)^\top J_l\text{d}W_lf_{l-1}\end{aligned}</script><p>因为 $\text{d}\varphi$ 是标量，因此我们可以用迹来表示结果。同时利用迹的循环不变性（$\text{tr}(ABC) = \text{tr}(BCA) = \text{tr}(CAB)$），我们可以更方便的调整结果的形式。</p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= \text{tr}((J_l W_l f_{l-1}-y)^\top J_l\text{d}W_lf_{l-1}) \\&= \text{tr}(f_{l-1}(J_l W_l f_{l-1}-y)^\top J_l\text{d}W_l) \\\end{aligned}</script><p>而由矩阵梯度的定义，$(G_l)_{ij} = \frac{\partial \varphi}{\partial (W_l)_{ij}}$，有</p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= \sum_i \sum_j (G_l)_{ij} (\text{d}W_l)_{ij} \\\end{aligned}</script><p>这就是 Frobenius 内积，它有一个重要的性质，可以用迹来代替计算</p><script type="math/tex; mode=display">\begin{aligned}\text{d}\varphi &= \langle G_l, \text{d}W_l \rangle_F \\&= \text{tr}(G_l^\top \text{d}W_l)\end{aligned}</script><p>进行比较，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}G_l^\top &= f_{l-1}(J_l W_l f_{l-1}-y)^\top J_l \\G_l &= J_l^\top (J_l W_l f_{l-1}-y) f_{l-1}^\top \\&= J_l^\top J_l W_l f_{l-1} f_{l-1}^\top - J_l^\top y f_{l-1}^\top\end{aligned}</script><p>考虑到梯度 $G_l$ 的方向是向上的，而常说的梯度下降的方向是相反的，因此我们记 $\hat{G_l} = -G_l = J_l^\top y f_{l-1}^\top - J_l^\top J_l W_l f_{l-1} f_{l-1}^\top$ 表示真实的梯度下降的方向。</p><p>其它损失函数也一样，变化一下最后一层的梯度就可以了。</p><div class="note success flat"><p>突然发现 MSE loss 和 CE loss 的梯度都是 $\mathcal{N}(x)-y$ 啊</p></div><p>作者也推导了softmax层的结果，得到的结果是 $\hat{G_l} = (J_lP_\bold{1}^{\bot}y-\gamma K^{-1}J_l^\top P_\bold{1}^{\bot}J_lW_lf_{l-1})f_{l-1}^\top$，其中 $P_{\bold{1}}^\bot := I - \frac{1}{K} \bold{1} \bold{1}^\top$，$K$ 是softmax的维度</p><p>总而言之，言而总之，除了 Attention 层不满足 Reverse Network 的定义（Attention层有 $\mathcal{N}_1(x) \cdot \mathcal{N}_2(x)$ 这样的积性操作），若我们暂且不考虑 Attention 层，则剩下的所有层的梯度似乎都可以表示为统一形式：</p><script type="math/tex; mode=display">\hat{G_l} = A - BW_lC</script><h3 id="Positive-Semi-definite"><a href="#Positive-Semi-definite" class="headerlink" title="Positive Semi-definite"></a>Positive Semi-definite</h3><p>对于 $\hat{G_l} = J_l^\top y f_{l-1}^\top - J_l^\top J_l W_l f_{l-1} f_{l-1}^\top$ 的形式</p><script type="math/tex; mode=display">\left\{\begin{aligned}B &= J_l^\top J_l \\C &= f_{l-1} f_{l-1}^\top\end{aligned}\right.</script><p>而根据线性代数的知识，我们知道这其实就是 $B$ 和 $C$ 都是半正定(Positive Semi-definite, PSD)矩阵的充要条件，因为 $x^\top B^\top B x = (Bx)^\top Bx = ||Bx||^2 \geq 0$</p><p>而到了softmax层的结果，我们只需额外证明 $J_l^\top P_\bold{1}^{\bot}J_l$ 是一个半正定矩阵。根据合同变换，我们知道如果一个矩阵 $A$ 是半正定矩阵，那对任意矩阵 $P$，$P^\top AP$ 也是半正定的。所以我们只要证明 $P_\bold{1}^{\bot}$ 是一个PSD即可</p><p>我们先来求 $Y = \bold{1}\bold{1}^T$ 的特征值。因为这是一个全1矩阵，也就意味着秩为1，因此它必然有 $K-1$ 个数值为0的特征值。</p><p>剩下一个我们简单地根据求特征值定义 $Ax = \lambda x$，能求得最后一个特征值为 $K$ </p><p>我们要求 $P = I - \frac{1}{K}Y$ 的特征值，根据定义：</p><script type="math/tex; mode=display">Pv = (I-\frac{1}{K}Y)v = Iv - \frac{1}{K}(Yv) = v - \frac{1}{K}(\lambda_Y v) = (1-\frac{\lambda_Y}{K})v</script><p>所以 $P$ 和 $Y$ 的特征值存在一个简单的关系: $\lambda_P = (1-\frac{\lambda_Y}{K})$，代入可求得 $P$ 的特征值有1个0和 $K-1$ 个1</p><p>所有特征值非负，所以 $P$ 是一个半正定矩阵。</p><p>综上，我们讨论的Large Language Model中的梯度，表达式中的 $B$ 和 $C$ 总是半正定的</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Optimizer </tag>
            
            <tag> Linear Algebra </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组合数学（一）容斥原理、二项式反演与第二类斯特林数</title>
      <link href="/posts/10045.html"/>
      <url>/posts/10045.html</url>
      
        <content type="html"><![CDATA[<h1 id="二项式反演"><a href="#二项式反演" class="headerlink" title="二项式反演"></a>二项式反演</h1><p>记 $f_n$ 表示恰好使用 $n$ 个不同元素形成特定结构的方案数，$g_n$ 表示从 $n$ 个不同元素中选出 $i\geq 0$ 个元素形成特定结构的总方案数。</p><p>若已知 $f_n$ 求 $g_n$，那么显然有：</p><script type="math/tex; mode=display">g_n = \sum_{i=0}^{n} \binom{n}{i}f_i</script><p>若已知 $g_n$ 求 $f_n$，则被称为 <strong>二项式反演</strong>，公式为：</p><script type="math/tex; mode=display">f_n = \sum_{i=0}^{n} \binom{n}{i} (-1)^{n-i} g_i</script><h2 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h2><p>对右式代入 $g_n = \sum_{i=0}^{n} \binom{n}{i}f_i$，得到</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i=0}^{n} \binom{n}{i} (-1)^{n-i} g_i &= \sum_{i=0}^{n} \binom{n}{i} (-1)^{n-i} [\sum_{j=0}^i \binom{i}{j}f_j] \\&= \sum_{i=0}^{n} \sum_{j=0}^i \binom{n}{i} \binom{i}{j} (-1)^{n-i} f_j\end{aligned}</script><p>交换 $i$ 和 $j$ 的枚举顺序，得到</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i=0}^{n} \sum_{j=0}^i \binom{n}{i} \binom{i}{j} (-1)^{n-i} f_j &= \sum_{j=0}^{n}\sum_{i=j}^n \binom{n}{i} \binom{i}{j} (-1)^{n-i} f_j \\&= \sum_{j=0}^{n} f_j \sum_{i=j}^{n} \binom{n}{i} \binom{i}{j} (-1)^{n-i}\end{aligned}</script><p>由于 $\binom{n}{i} \binom{i}{j} = \binom{n}{j} \binom{n-j}{i-j}$。这个很好理解，相当于是 $n$ 里取 $i$ 个，再 $i$ 里取 $j$ 个。现在是直接取 $j$ 个，然后从剩下的 $n-j$ 个里取剩下的 $i-j$ 个。总之得到</p><script type="math/tex; mode=display">\begin{aligned}\sum_{j=0}^{n} f_j \sum_{i=j}^{n} \binom{n}{i} \binom{i}{j} (-1)^{n-i} &= \sum_{j=0}^{n} f_j \sum_{i=j}^{n} \binom{n}{j} \binom{n-j}{i-j} (-1)^{n-i} \\ &= \sum_{j=0}^{n} \binom{n}{j} f_j \sum_{i=j}^{n} \binom{n-j}{i-j} (-1)^{n-i}\end{aligned}</script><p>令 $k = i - j$，则 $i = k+ j$，上式转换为：</p><script type="math/tex; mode=display">\begin{aligned}\sum_{j=0}^{n} \binom{n}{j} f_j \sum_{i=j}^{n} \binom{n-j}{i-j} (-1)^{n-i} &= \sum_{j=0}^{n} \binom{n}{j} f_j \sum_{k=0}^{n-j} \binom{n-j}{k} (-1)^{n-j-k}1^k \\&= \sum_{j=0}^n \binom{n}{j} f_j (-1+1)^{n-j}\end{aligned}</script><p>当且仅当 $n=j$ 时不为 $0$</p><script type="math/tex; mode=display">\sum_{j=0}^n \binom{n}{j} f_j (-1+1)^{n-j} = f_j</script><p>证毕</p><h1 id="第二类斯特林数（Stirling-Number）"><a href="#第二类斯特林数（Stirling-Number）" class="headerlink" title="第二类斯特林数（Stirling Number）"></a>第二类斯特林数（Stirling Number）</h1><p>第二类斯特林数 $S(n,k)$ 表示将 $n$ 个两两不同的元素，划分为 $k$ 个互不区分的非空子集的方案数。</p><h2 id="递推式"><a href="#递推式" class="headerlink" title="递推式"></a>递推式</h2><script type="math/tex; mode=display">S(n, k) = S(n-1, k-1) + kS(n-1, k)</script><p>考虑用组合意义来证明</p><p>当我们插入一个新元素时，有两种方案：</p><ul><li><p>将新元素单独放入一个子集，有 $S(n-1, k-1)$ 种方案</p></li><li><p>将新元素放入一个现有的非空子集，有 $kS(n-1, k)$ 种方案</p></li></ul><p>相加即得</p><h2 id="通项公式"><a href="#通项公式" class="headerlink" title="通项公式"></a>通项公式</h2><script type="math/tex; mode=display">S(n, m) = \sum_{i=0}^m \frac{(-1)^{m-i}i^n}{i!(m-i)!}</script><p>使用容斥原理证明该公式。设将 $n$ 个两两不同的元素，划分到 $i$ 个两两不同的集合（允许空集）的方案数为 $G_i$， 将 $n$ 个两两不同的元素，划分到 $i$ 个两两不同的非空集合（不允许空集）的方案数为 $F_i$</p><p>根据定义，有</p><script type="math/tex; mode=display">\begin{aligned}G_i &= i^n \\G_i &= \sum_{j=0}^i \binom{i}{j} F_j\end{aligned}</script><p>根据二项式反演，有：</p><script type="math/tex; mode=display">\begin{aligned}F_i &= \sum_{j=0}^i (-1)^{i-j} \binom{i}{j} G_j \\ &= \sum_{j=0}^i (-1)^{i-j} \binom{i}{j} j^n \\&= \sum_{j=0}^i \frac{i!(-1)^{i-j}j^n}{j!(i-j)!}\end{aligned}</script><p>而第二类斯特林数要求的集合之间是互不区分的，因此 $F_i$ 是 $S(n, i)$ 的 $i!$ 倍，所以：</p><script type="math/tex; mode=display">S(n, m) = \frac{F_m}{m!} = \sum_{i=0}^m \frac{(-1)^{m-i}i^n}{i!(m-i)!}</script>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gamma Function</title>
      <link href="/posts/10044.html"/>
      <url>/posts/10044.html</url>
      
        <content type="html"><![CDATA[<h1 id="伽马函数"><a href="#伽马函数" class="headerlink" title="伽马函数"></a>伽马函数</h1><p>定义为：</p><script type="math/tex; mode=display">\Gamma(x) = \int_0^\infty t^{x-1}e^{-t}dt</script><p>对应正整数 $n$，满足 $\Gamma(n)=(n-1)!$</p><h1 id="递推关系式"><a href="#递推关系式" class="headerlink" title="递推关系式"></a>递推关系式</h1><p>伽马函数存在递推关系式</p><script type="math/tex; mode=display">\Gamma(x+1) = x \Gamma(x)</script><p>可以简单地使用分部积分法证明：</p><script type="math/tex; mode=display">\begin{aligned}\Gamma(x+1) &= \int_0^\infty t^{x}e^{-t}dt = \int_0^\infty t^{x}d(-e^{-t}) \\ &= [-t^xe^{-t}]_0^{\infty} - \int_0^\infty(-e^{-t})dt^x \\ &= 0 + x\int_0^\infty(e^{-t})t^{x-1}dt \\&= x\Gamma(x)\end{aligned}</script><p>而 $\Gamma(1) = 1$，所以 $\Gamma(n) = (n-1)!$</p><h1 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h1><p>可以直接调 <code>math.gamma()</code> 计算</p><p>由于阶乘增长速度太快，所以可以采用 <code>math.lgamma()</code>，计算对数值增强稳定性</p><h1 id="反射公式"><a href="#反射公式" class="headerlink" title="反射公式"></a>反射公式</h1><script type="math/tex; mode=display">\Gamma(x)\Gamma(1-x) = \frac{x}{\sin(\pi x)}</script><p>这个公式允许我们计算负数的伽马函数值。同时我们也能看到，伽马函数在 $0, -1, -2$ 等处附近是发散的。</p>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Math </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2</title>
      <link href="/posts/10043.html"/>
      <url>/posts/10043.html</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>本篇是mamba系列blog的第四篇文章，系列文章见：</p><ul><li><p><a href="https://anti-entrophic.github.io/posts/10038.html" title="Part I of Mathematical Structure of Mamba - Hippo">Part I of Mathematical Structure of Mamba - Hippo</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10039.html" title="Part II of Mathematical Structure of Mamba - S4">Part II of Mathematical Structure of Mamba - S4</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10040.html" title="Part III of Mathematical Structure of Mamba - S4D">Part III of Mathematical Structure of Mamba - S4D</a></p></li><li><p>Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2</p></li></ul><p>剩余预计还有一篇文章正在生产中~</p></div><h1 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h1><p>我们都知道SSM的公式：</p><script type="math/tex; mode=display">\begin{aligned}h_t &= A_th_{t-1} + B_tx_t \\y_t &= C_t^Th_t\end{aligned}</script><p>这里的 $t$ 其实就代表了 <code>seq_len</code> 这一维。我们将公式展开，就可以得到一个卷积的形式</p><script type="math/tex; mode=display">\begin{aligned}h_0 &= B_0x_0 \\h_1 &= A_1h_0 + B_1x_1 = A_1B_0x_0 + B_1x_1 \\h_2 &= A_2A_1B_0x_0 + A_2B_1x_1 +B_2x_2 \\h_t &= \sum_{s=0}^t A_tA_{t-1}...A_{s+1}B_sx_s\end{aligned}</script><p>我们记 $A_{t:s} := A_tA_{t-1}…A_{s+1}$，则最终的输出 $y_t = C_t^Th_t = C_t^T\sum_{s=0}^t A_{t:s}B_sx_s$。</p><p>如果写成向量形式，则有 $y=Mx$，$M$ 有如下格式：</p><script type="math/tex; mode=display">\left[\begin{array}{ll|ll}{C_0^TB_0}&{}&{}&{}\\{C_1^TA_1B_0}&{C_1^TB_1}&{}&{}\\\hline{C_2^TA_2A_1B_0}&{C_2^TA_2B_1}&{C_2^TB_2}&{}\\{C_3^TA_3A_2A_1B_0}&{C_3^TA_3A_2B_1}&{C_3^TA_3B_3}&{C_3^TB_3}\\\hline{\cdots}&{\cdots}&{\cdots}&{\cdots}\end{array}\right]</script><p>其中，分为对角块与方阵。其中的方阵部分还可以进一步简化：</p><script type="math/tex; mode=display">\left[\begin{array}{ll}{C_2^TA_2A_1B_0}&{C_2^TA_2B_1} \\{C_3^TA_3A_2A_1B_0}&{C_3^TA_3A_2B_1}\end{array}\right] = \left[\begin{array}{l}{C_2^T} \\{C_3^TA_3}\end{array}\right] A_2 \left[\begin{array}{ll}{A_1B_0} & {B_1}\end{array}\right]</script><p>更一般的形式为，对于矩阵 $M_{j:j’,i’:i}$，其中 $j’ &gt; j \geq i &gt; i’$：</p><script type="math/tex; mode=display">\left[\begin{array}{ccc}{C_j^TA_{j:i'}B_{i'}}&{\cdots}&{C_j^TA_{j:i-1}B_{i-1}} \\{\vdots} & {\ddots} & {\vdots} \\{C_{j'-1}^TA_{j'-1:i'}B_{i'}}&{\cdots}&{C_{j'-1}^TA_{j'-1:i-1}B_{i-1}}\end{array}\right] = \left[\begin{array}{c}{C_j^TA_{j:j}} \\{\vdots} \\{C_{j'-1}^TA_{j'-1:j}}\end{array}\right] A_{j:i-1} \left[\begin{array}{ccc}{A_{i-1:i'}B_{i'}} & {\cdots} & {A_{i-1:i-1}B_{i-1}}\end{array}\right]</script><p>后续的工作，就是写算子把这些东西全部高效地算出来。整体思路就是，按上述分块，先块内算，再块间算。</p><h1 id="Triton-算子"><a href="#Triton-算子" class="headerlink" title="Triton 算子"></a>Triton 算子</h1><p>有关 Triton 的基本知识欢迎参考这篇<a href="https://anti-entrophic.github.io/posts/10042.html" title="Triton Tutorial">Triton Tutorial</a></p><h2 id="chunk-cumsum-fwd"><a href="#chunk-cumsum-fwd" class="headerlink" title="_chunk_cumsum_fwd"></a>_chunk_cumsum_fwd</h2><p>需要先介绍一下 $A$ 的离散化（记 $\tilde{A} $ 为离散化之前的矩阵），见 <a href="https://anti-entrophic.github.io/posts/10040.html" title="Part III of Mathematical Structure of Mamba - S4D">Part III of Mathematical Structure of Mamba - S4D</a></p><p>我们知道了，为了保证 $A$ 的实部总为负，我们需要用指数形式来处理离散化：$e^{\Delta A}$。而指数形式的乘积实际上就对应了指数的累计和，这也是这个算子在做的事情。</p><p>经过 DSS 与 S4D 这两篇文章的沉淀，作者发现A使用对角线比起NPLR也没差很多。特别是从mamba开始抛弃HiPPO后，就更没有使用NPLR的必要了，直接快进到对角线。</p><p>$dt: (B,S,H)$， $A: (H,)$，可以视作每个头都有一个控制状态衰减的变量。</p><p>这个算子做的事情其实比较简单，就是计算 $e^{\sum \Delta_i A_i}$，不过是分块做的。</p><h3 id="grid"><a href="#grid" class="headerlink" title="grid"></a>grid</h3><p>我们把 $dt$ 按照seqlen这一维切开，切成 chunk_size 大小的块。同时，head这一维也会切分，每份大小是 <code>BLOCK_SIZE_H</code>，这个参数后续会用autotune去搜。最后得到一个三维的grid，代表了 <code>[batch, seqlen, heads]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_chunk_cumsum_fwd</span>(<span class="params">dt, A, chunk_size, dt_bias=<span class="literal">None</span>, dt_softplus=<span class="literal">False</span>, dt_limit=(<span class="params"><span class="number">0.0</span>, <span class="built_in">float</span>(<span class="params"><span class="string">&quot;inf&quot;</span></span>)</span>)</span>):</span><br><span class="line">    batch, seqlen, nheads = dt.shape</span><br><span class="line">    <span class="keyword">assert</span> A.shape == (nheads,)</span><br><span class="line">    <span class="keyword">if</span> dt_bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">assert</span> dt_bias.shape == (nheads,)</span><br><span class="line">    nchunks = math.ceil(seqlen / chunk_size)</span><br><span class="line">    dt_out = torch.empty(batch, nheads, nchunks, chunk_size, device=dt.device, dtype=torch.float32)</span><br><span class="line">    dA_cumsum = torch.empty(batch, nheads, nchunks, chunk_size, device=dt.device, dtype=torch.float32)</span><br><span class="line">    grid_chunk_cs = <span class="keyword">lambda</span> META: (batch, nchunks, triton.cdiv(nheads, META[<span class="string">&#x27;BLOCK_SIZE_H&#x27;</span>]))</span><br><span class="line">    <span class="keyword">with</span> torch.cuda.device(dt.device.index):</span><br><span class="line">        _chunk_cumsum_fwd_kernel[grid_chunk_cs](</span><br><span class="line">            dt, A, dt_bias, dt_out, dA_cumsum,</span><br><span class="line">            batch, seqlen, nheads, chunk_size,</span><br><span class="line">            dt_limit[<span class="number">0</span>], dt_limit[<span class="number">1</span>],</span><br><span class="line">            dt.stride(<span class="number">0</span>), dt.stride(<span class="number">1</span>), dt.stride(<span class="number">2</span>),</span><br><span class="line">            A.stride(<span class="number">0</span>),</span><br><span class="line">            dt_bias.stride(<span class="number">0</span>) <span class="keyword">if</span> dt_bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">            dt_out.stride(<span class="number">0</span>), dt_out.stride(<span class="number">2</span>), dt_out.stride(<span class="number">1</span>), dt_out.stride(<span class="number">3</span>),</span><br><span class="line">            dA_cumsum.stride(<span class="number">0</span>), dA_cumsum.stride(<span class="number">2</span>), dA_cumsum.stride(<span class="number">1</span>), dA_cumsum.stride(<span class="number">3</span>),</span><br><span class="line">            dt_softplus,</span><br><span class="line">            HAS_DT_BIAS=dt_bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>,</span><br><span class="line">            BLOCK_SIZE_CHUNK=triton.next_power_of_2(chunk_size),</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> dA_cumsum, dt_out</span><br></pre></td></tr></table></figure><p>之后简单看一下整个triton算子的逻辑，我会以 <code>tl.load()</code> 为基础，看每份数据是怎么读进来的；然后再介绍它们之间如何计算。</p><h3 id="dt"><a href="#dt" class="headerlink" title="dt"></a>dt</h3><p>因为每块数据处理第 <code>pid_b</code> 条的 <code>chunk_size</code> 条数据，所以首先定位到 <code>dt_ptr</code>，再取下大小为 <code>[BLOCK_SIZE_H, BLOCK_SIZE_CHUNK]</code> 的一块。</p><p>这里比较需要注意的就是，在读入数据的时候交换了 $S$ 和 $H$ 这两维，是为了后续计算方便。只要stride是正确的话，读进来的数据是一定正确的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dt_ptr += pid_b * stride_dt_batch + pid_c * chunk_size * stride_dt_seqlen</span><br><span class="line">offs_h = pid_h * BLOCK_SIZE_H + tl.arange(<span class="number">0</span>, BLOCK_SIZE_H)</span><br><span class="line">offs_c = tl.arange(<span class="number">0</span>, BLOCK_SIZE_CHUNK)</span><br><span class="line">dt_ptrs = dt_ptr + (offs_h[:, <span class="literal">None</span>] * stride_dt_head + offs_c[<span class="literal">None</span>, :] * stride_dt_seqlen)</span><br><span class="line">dt = tl.load(dt_ptrs, mask=(offs_h[:, <span class="literal">None</span>] &lt; nheads) &amp; (offs_c[<span class="literal">None</span>, :] &lt; chunk_size_limit), other=<span class="number">0.0</span>).to(tl.float32)</span><br></pre></td></tr></table></figure><h3 id="A"><a href="#A" class="headerlink" title="A"></a>A</h3><p><code>A</code> 就没啥好说的，就一个维度，分成 <code>BLOCK_SIZE_H</code> 大小即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_ptrs = A_ptr + offs_h * stride_A_head</span><br><span class="line">A = tl.load(A_ptrs, mask=offs_h &lt; nheads, other=<span class="number">0.0</span>).to(tl.float32)</span><br></pre></td></tr></table></figure><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>主要就是计算 $dt * A$，然后求累计和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dA = dt * A[:, <span class="literal">None</span>]</span><br><span class="line">dA_cs = tl.cumsum(dA, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>值得一提的是，最后存下来的结果的维度是 <code>[batch, nheads, nchunks, chunk_size]</code>，等于是把seqlen这一维给拆开了。并且，块间的交互也还没做，比如说本来累计和应该是 [1,2,3,4]，现在的分块结果可能是 [1,2,1,2]，后续还需要一步块间RNN传递。</p><h2 id="chunk-state-fwd"><a href="#chunk-state-fwd" class="headerlink" title="_chunk_state_fwd"></a>_chunk_state_fwd</h2><p>这段代码主要是算states的，对应的是原计算公式中的</p><script type="math/tex; mode=display">{\left[\begin{array}{c}{B_{i'}^TA_{i-1:i'}} \\ {\vdots} \\ {B_{i-1}^TA_{i-1:i-1}}\end{array}\right]}^T \left[\begin{array}{c}{x_{i'}} \\ {\vdots} \\ {x_{i-1}}\end{array}\right] = \sum_{t=i'}^{i-1}{A_{i-1:i'}^TB_{i'}x_{i'}}</script><p>先明确一下各输入的维度。</p><p><code>x: [batch, seq_len, nheads, headdim]</code>，其中 <code>nheads * headdim = d_model</code></p><p><code>dt: [batch, nheads, nchunks, chunk_size]</code>，其中 <code>nchunks * chunk_size = seq_len</code></p><p><code>B: [batch, seq_len, ngroups, dstate]</code>，其中 <code>ngroups</code> 是为了tp的参数，一般为1；<code>dstate</code> 就是状态向量的维度</p><p><code>dA_cumsum</code> 和 <code>dt</code> 一样</p><h3 id="grid-1"><a href="#grid-1" class="headerlink" title="grid"></a>grid</h3><p>grid的分法看起来有点奇怪，第0维把 <code>headdim * dstate</code> 分成了一组，这是因为 $ABx$ 的结果就是 <code>headdim * dstate</code>，可以这么理解，表示输入 <code>x</code> 的某个维度，对内部状态 <code>h</code> 的某个维度的影响。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mamba_ssm/ops/triton/ssd_chunk_state.py</span></span><br><span class="line">grid = <span class="keyword">lambda</span> META: (triton.cdiv(headdim, META[<span class="string">&#x27;BLOCK_SIZE_M&#x27;</span>]) * triton.cdiv(dstate, META[<span class="string">&#x27;BLOCK_SIZE_N&#x27;</span>]),</span><br><span class="line">                  batch * nchunks, nheads)</span><br><span class="line"></span><br><span class="line">num_pid_n = tl.cdiv(dstate, BLOCK_SIZE_N)</span><br><span class="line">pid_m = tl.program_id(axis=<span class="number">0</span>) // num_pid_n</span><br><span class="line">pid_n = tl.program_id(axis=<span class="number">0</span>) % num_pid_n</span><br></pre></td></tr></table></figure><p>第1维是把 <code>batch</code> 和 <code>nchunks</code> 组合到一起，然后到kernel里之后又光速分开了。看起来排序方式是 <code>[nchunks, batch]</code>，不懂为啥要拼起来传进去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pid_bc = tl.program_id(axis=<span class="number">1</span>)</span><br><span class="line">pid_c = pid_bc // batch</span><br><span class="line">pid_b = pid_bc - pid_c * batch</span><br></pre></td></tr></table></figure><p>第2维就简明一点，直接对 <code>nheads</code> 分块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pid_h = tl.program_id(axis=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h3 id="dA-cs-last"><a href="#dA-cs-last" class="headerlink" title="dA_cs_last"></a>dA_cs_last</h3><p>之后依然是读取数据，我们还是以 <code>tl.load()</code> 为支点读代码。首先是 <code>dA_cumsum</code>，也就是一个 <code>chunk_size</code> 大小中的前缀和 $\sum_{i=0}^t \Delta_iA_i$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dA_cumsum_ptr += pid_b * stride_dA_cs_batch + pid_c * stride_dA_cs_chunk + pid_h * stride_dA_cs_head</span><br><span class="line">dA_cs_last = tl.load(dA_cumsum_ptr + (chunk_size - <span class="number">1</span>) * stride_dA_cs_csize).to(tl.float32)</span><br></pre></td></tr></table></figure><p><code>dA_cumsum</code> 的维度是 <code>[batch, nheads, nchunks, chunk_size]</code>。我们的读取方式很简单，分别朝第0、1、2维移动对应长度。注意，<code>dA_cs_last</code> 读的是这个chunk中的最后一个元素，因此叫last。</p><h3 id="seq-idx"><a href="#seq-idx" class="headerlink" title="seq_idx"></a>seq_idx</h3><p><code>seq_idx</code> 暂时跳过，我不知道这个是干什么的。</p><h3 id="x"><a href="#x" class="headerlink" title="x"></a>x</h3><p>这里又很神秘的，对于 <code>chunk_size</code> 这一维还要切一下。读取方式是之前说明过的交换维度，只要stride是对的，数据就是对的，只不过是写入顺序的问题罢了。所以读取进来的 <code>x</code> 是 <code>[pid_b, (k:k+1)*BLOCK_SIZE_K, pid_h, (pid_m:pid_m+1) * BLOCK_SIZE_M]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">offs_m = pid_m * BLOCK_SIZE_M + tl.arange(<span class="number">0</span>, BLOCK_SIZE_M)</span><br><span class="line">offs_k = tl.arange(<span class="number">0</span>, BLOCK_SIZE_K)</span><br><span class="line">x_ptrs = x_ptr + (offs_m[:, <span class="literal">None</span>] * stride_x_hdim + offs_k[<span class="literal">None</span>, :] * stride_x_seqlen)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, chunk_size_limit, BLOCK_SIZE_K):</span><br><span class="line">    x = tl.load(x_ptrs, mask=(offs_m[:, <span class="literal">None</span>] &lt; hdim) &amp; (offs_k[<span class="literal">None</span>, :] &lt; chunk_size_limit - k), other=<span class="number">0.0</span>)</span><br><span class="line">    x_ptrs += BLOCK_SIZE_K * stride_x_seqlen</span><br></pre></td></tr></table></figure><h3 id="b"><a href="#b" class="headerlink" title="b"></a>b</h3><p><code>b</code> 的取值是 <code>[pid_b, (k: k + 1) * BLOCK_SIZE_K, pid_group, (pid_n: pid_n+1) * BLOCK_SIZE_N]</code></p><p>注意不要搞错了 <code>b</code> 的意义，这里的 <code>b</code> 可以看作是用来处理 <code>x</code> 的投影矩阵，还是要投到 dstate 上去的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">offs_n = pid_n * BLOCK_SIZE_N + tl.arange(<span class="number">0</span>, BLOCK_SIZE_N)</span><br><span class="line">b_ptr += pid_b * stride_b_batch + pid_c * chunk_size * stride_b_seqlen + (pid_h // nheads_ngroups_ratio) * stride_b_head</span><br><span class="line">b_ptrs = b_ptr + (offs_n[<span class="literal">None</span>, :] * stride_b_dstate + offs_k[:, <span class="literal">None</span>] * stride_b_seqlen)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, chunk_size_limit, BLOCK_SIZE_K):</span><br><span class="line">  b = tl.load(b_ptrs, mask=(offs_k[:, <span class="literal">None</span>] &lt; chunk_size_limit - k) &amp; (offs_n[<span class="literal">None</span>, :] &lt; dstate), other=<span class="number">0.0</span>).to(tl.float32)</span><br><span class="line">  b_ptrs += BLOCK_SIZE_K * stride_b_seqlen</span><br></pre></td></tr></table></figure><h3 id="dA-cs-k-与-dt-k"><a href="#dA-cs-k-与-dt-k" class="headerlink" title="dA_cs_k 与 dt_k"></a>dA_cs_k 与 dt_k</h3><p>就是读进来一个chunk_size的元素，然后进一步把 chunk_size（seq_len） 这一维切了一下，不太重要</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dA_cumsum_ptrs = dA_cumsum_ptr + offs_k * stride_dA_cs_csize</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, chunk_size_limit, BLOCK_SIZE_K):</span><br><span class="line">  dA_cs_k = tl.load(dA_cumsum_ptrs, mask=offs_k &lt; chunk_size_limit - k, other=<span class="number">0.0</span>).to(tl.float32)</span><br><span class="line">  dA_cumsum_ptrs += BLOCK_SIZE_K * stride_dA_cs_csize</span><br></pre></td></tr></table></figure><h3 id="每一小块的具体计算"><a href="#每一小块的具体计算" class="headerlink" title="每一小块的具体计算"></a>每一小块的具体计算</h3><p>先把前缀和计算这一段的差，比如说 <code>dA_cs_last = A_3 * A_2 * A_1 * A_0</code>， <code>dA_cs_k = [A_0, A_1 * A_0]</code></p><p>这里的小块 <code>b</code> 是在 <code>[seq_len, dstate]</code> 维度上取出来的大小为 <code>[BLOCK_SIZE_K, BLOCK_SIZE_N]</code> 的块。这里的scale乘到了 <code>seq_len</code> 维度上，因为不同的时间步需要乘的A不同嘛。</p><p>后面和大小为 <code>[BLOCK_SIZE_M, BLOCK_SIZE_K]</code> 的 <code>x</code> 做点积，得到是一个 <code>[headdim, dstate]</code> 的矩阵。然后按照开头公式所说的加起来。最后存下来的states的维度是 <code>[batch, nchunks, nheads, headdim, dstate]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scale = tl.exp(tl.minimum((dA_cs_last - dA_cs_k), <span class="number">0.0</span>)) * dt_k</span><br><span class="line">b *= scale[:, <span class="literal">None</span>]</span><br><span class="line">acc += tl.dot(x, b)</span><br></pre></td></tr></table></figure><h2 id="state-passing-fwd"><a href="#state-passing-fwd" class="headerlink" title="_state_passing_fwd"></a>_state_passing_fwd</h2><p>上面一步的计算其实是算少了的，比如说你第一步有的块是只有 $A_7A_6A_5A_4$的，那你本来想算 $A_{7:0}B_0x_0$ 的就少算了。方法就是从算过的 $A_{3:0}B_0x_0$ 往下传。函数名字也很形象。</p><p>代码上有一点点改变，首先就是把states的后两维聚到一起了，方便计算，然后 <code>dA_cumsum</code> 只需要取最后一个就可以。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">states, final_states = _state_passing_fwd(rearrange(states, <span class="string">&quot;... p n -&gt; ... (p n)&quot;</span>), dA_cumsum[:, :, :, -<span class="number">1</span>],</span><br><span class="line">                                          initial_states=rearrange(initial_states, <span class="string">&quot;... p n -&gt; ... (p n)&quot;</span>) <span class="keyword">if</span> initial_states <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                                          seq_idx=seq_idx, chunk_size=chunk_size, out_dtype=C.dtype)</span><br></pre></td></tr></table></figure><h3 id="grid-2"><a href="#grid-2" class="headerlink" title="grid"></a>grid</h3><p>上来grid又是乱序，我真的会谢。<code>dim</code> 这一维指的是states的后两维，可能是这个算子里不涉及这个的操作，所以抛到最外侧了吧（但是内存空间又没变，早知如此为什么不之前存的时候就换顺序呢？）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid = <span class="keyword">lambda</span> META: (triton.cdiv(dim, META[<span class="string">&#x27;BLOCK_SIZE&#x27;</span>]), batch, nheads)</span><br></pre></td></tr></table></figure><h3 id="states-amp-dA"><a href="#states-amp-dA" class="headerlink" title="states &amp; dA"></a>states &amp; dA</h3><p>函数的具体内容倒是简单，读入 <code>states</code> 和 <code>dA</code>。</p><p><code>dA</code> 的维度是 <code>[batch, nheads, nchunks]</code>；<code>state</code> 的维度是 <code>[batch, nchunks, nheads, headdim*dstate]</code></p><p>这里 <code>dA</code> 好像就是把一整个 <code>nchunks</code> 取出来，这样就是 <code>nchunks</code> 段乘积。</p><p><code>states</code> 则直接在除了nchunks的方向上移动到对应位置，最后一维取了一个 <code>BLOCK_SIZE</code> 做并行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dA_cs_ptr += pid_b * stride_dA_cs_batch + pid_h * stride_dA_cs_head</span><br><span class="line">states_ptr += pid_b * stride_states_batch + pid_h * stride_states_head</span><br><span class="line">offs_m = pid_m * BLOCK_SIZE + tl.arange(<span class="number">0</span>, BLOCK_SIZE)</span><br><span class="line">states_ptrs = states_ptr + offs_m * stride_states_dim</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(nchunks):</span><br><span class="line">    new_states = tl.load(states_ptrs, mask=offs_m &lt; dim, other=<span class="number">0.0</span>).to(tl.float32)</span><br><span class="line">    dA_cs = tl.load(dA_cs_ptr).to(tl.float32)</span><br></pre></td></tr></table></figure><p>一个比较朴素的问题是，怎么保证读的正确对应呢？这里用了一个循环来更新：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(nchunks):</span><br><span class="line">    new_states = tl.load(states_ptrs, mask=offs_m &lt; dim, other=<span class="number">0.0</span>).to(tl.float32)</span><br><span class="line">    dA_cs = tl.load(dA_cs_ptr).to(tl.float32)</span><br><span class="line">    scale = tl.exp(dA_cs)</span><br><span class="line"></span><br><span class="line">    states = scale * states + new_states  <span class="comment"># 循环更新 </span></span><br><span class="line">    <span class="keyword">if</span> c &lt; nchunks - <span class="number">1</span>:</span><br><span class="line">        tl.store(out_ptrs, states, mask=offs_m &lt; dim)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        tl.store(final_states_ptrs, states, mask=offs_m &lt; dim)</span><br><span class="line">    states_ptrs += stride_states_chunk</span><br><span class="line">    dA_cs_ptr += stride_dA_cs_chunk</span><br><span class="line">    out_ptrs += stride_out_chunk</span><br></pre></td></tr></table></figure><p>但是说实话，具体怎么并行的我也有点没想清楚，为啥这么取就能把所有块的算好呢。后续又该怎么取呢？有点神秘。</p><h2 id="bmm-chunk-fwd"><a href="#bmm-chunk-fwd" class="headerlink" title="_bmm_chunk_fwd"></a>_bmm_chunk_fwd</h2><p>并非善类</p><h3 id="grid-3"><a href="#grid-3" class="headerlink" title="grid"></a>grid</h3><p>分的维度是 <code>[chunk_size, chunk_size, batch, nchunks]</code></p><p>Tridao瞎起名字，给我整笑了。外面传进去 <code>C</code> 和 <code>dstate</code>，在里面形参叫 <code>A</code> 和 <code>k</code>，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid = <span class="keyword">lambda</span> META: (triton.cdiv(chunk_size, META[<span class="string">&#x27;BLOCK_SIZE_M&#x27;</span>]) * triton.cdiv(chunk_size, META[<span class="string">&#x27;BLOCK_SIZE_N&#x27;</span>]), batch, nchunks <span class="keyword">if</span> <span class="keyword">not</span> has_groups <span class="keyword">else</span> nchunks * ngroups)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Model Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mamba </tag>
            
            <tag> Model Structure </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton Tutorial</title>
      <link href="/posts/10042.html"/>
      <url>/posts/10042.html</url>
      
        <content type="html"><![CDATA[<h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><p>Triton是一门适配python的高性能GPU编程语言（暂时只认为是语言），学习路线可以从完成官方的<a href="https://triton-lang.org/main/index.html," title="Triton Tutorial">tutorial</a>开始。我的博客里主要想讲一些不一样的。</p><p>CUDA Version: 12.2</p><p>Triton Version: 3.1.0</p><h1 id="GPU相关知识"><a href="#GPU相关知识" class="headerlink" title="GPU相关知识"></a>GPU相关知识</h1><p>想必大家上来跑tutorial遇到的第一个问题是，获取DEVICE的接口报错了！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> triton.runtime <span class="keyword">import</span> driver</span><br><span class="line">DEVICE = driver.active.get_active_torch_device()</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt;&gt; AttributeError: &#x27;CudaDriver&#x27; object has no attribute &#x27;get_active_torch_device&#x27;</span></span><br></pre></td></tr></table></figure><p>查阅源码后发现，应该是nvidia那边的接口变掉了，导致triton中无法重载：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># triton/python/triton/backends/driver.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DriverBase</span>(metaclass=ABCMeta):</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_active</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_current_target</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_active_torch_device</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_benchmarker</span>(<span class="params">self</span>) -&gt; Benchmarker:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return the benchmarking function that this backend should use by default.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">driver.active</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; &lt;nvi.CudaDriver object at 0x7ff294e43d30&gt;</span></span><br></pre></td></tr></table></figure><p>因此，我们可以用别的API来代替：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">driver.active.get_current_target()</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; GPUTarget(backend=&#x27;cuda&#x27;, arch=90, warp_size=32)</span></span><br><span class="line">DEVICE = driver.active.get_current_target().backend</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; &#x27;cuda&#x27;</span></span><br><span class="line">DEVICE_ID = driver.active.get_current_device()</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; 0</span></span><br></pre></td></tr></table></figure><p>在有些时候，我们还需要更多GPU的信息来辅助并行编程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">properties = driver.active.utils.get_device_properties(DEVICE_ID)</span><br><span class="line"><span class="comment"># &gt;&gt;&gt; &#123;&#x27;max_shared_mem&#x27;: 232448, &#x27;max_num_regs&#x27;: 65536, &#x27;multiprocessor_count&#x27;: 132, &#x27;warpSize&#x27;: 32, &#x27;sm_clock_rate&#x27;: 1980000, &#x27;mem_clock_rate&#x27;: 2619000, &#x27;mem_bus_width&#x27;: 5120&#125;</span></span><br><span class="line">NUM_SM = properties[<span class="string">&quot;multiprocessor_count&quot;</span>]</span><br><span class="line">NUM_REGS = properties[<span class="string">&quot;max_num_regs&quot;</span>]</span><br><span class="line">SIZE_SMEM = properties[<span class="string">&quot;max_shared_mem&quot;</span>]</span><br><span class="line">WARP_SIZE = properties[<span class="string">&quot;warpSize&quot;</span>]</span><br></pre></td></tr></table></figure><p>解释一下这四个主要的GPU参数：</p><ul><li><p><code>NUM_SM</code> 是指的GPU中Streaming Multiprocessor（SM）的数量。SM是GPU上的核心处理单元，包含完整的内存、寄存器等。整个CUDA编程的核心就是将任务分成多个BLOCKs，然后这些BLOCKs会被均匀地分给所有SM执行。我使用的GPU型号是H800，总共有132个SM。</p></li><li><p><code>NUM_REGS</code> 是指每个SM中可用的寄存器（registers）的最大数量。寄存器每个线程不共享，如果单个线程所需要使用的寄存器很多，则同时在一个SM上运行的线程数量就会减少。</p></li><li><p><code>SIZE_SMEM</code> 是指每个SM可用的共享内存（Shared Memory）的大小，通常以字节（Bytes）为单位。SMEM访问速度远快于显存，同一个SM中的所有线程均可共享，可用于数据交换等。linux系统中也有共享内存的概念，可以看作是“基于内存的文件系统”，通常指的是 <code>/dev/shm</code> 这块区域，用于进程间通信等操作，就不用把数据写到硬盘里去了。</p></li></ul><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df -h /dev/shm</span><br><span class="line">&gt;&gt;&gt; 文件系统        大小  已用  可用 已用% 挂载点</span><br><span class="line">&gt;&gt;&gt; tmpfs            <span class="number">64</span>G     <span class="number">0</span>   <span class="number">64</span>G    <span class="number">0</span>% /dev/shm</span><br></pre></td></tr></table></figure><ul><li><code>WARP_SIZE</code> 比较复杂一点，我们首先需要理解Warp的概念。Warp是GPU上线程调度的基本单元，一个Warp中的所有线程会执行相同的命令。这并不代表一个Warp中所有线程是完全一样的，而是说，如果Warp中有一半的指令做的是A，而另一半的指令做的是A-&gt;B，则在第一阶段所有线程会同时处理，而在第二阶段有一半的线程会陪着另一半空转。因此，避免Warp分歧也是一个很重要的优化点。<code>WARP_SIZE</code> 则表示一个Warp中包含的线程数量，基本上是32。</li></ul><h1 id="Vector-Addition"><a href="#Vector-Addition" class="headerlink" title="Vector Addition"></a>Vector Addition</h1><p>源代码很简单就不解释了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> triton</span><br><span class="line"><span class="keyword">import</span> triton.language <span class="keyword">as</span> tl</span><br><span class="line"><span class="keyword">from</span> triton.runtime <span class="keyword">import</span> autotune</span><br><span class="line"></span><br><span class="line">DEVICE = triton.runtime.driver.active.get_current_target().backend</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_kernel</span>(<span class="params"></span></span><br><span class="line"><span class="params">    x_ptr,</span></span><br><span class="line"><span class="params">    y_ptr,</span></span><br><span class="line"><span class="params">    output_ptr,</span></span><br><span class="line"><span class="params">    n_elements,</span></span><br><span class="line"><span class="params">    BLOCK_SIZE: tl.constexpr</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    pid = tl.program_id(axis=<span class="number">0</span>)</span><br><span class="line">    block_start = pid * BLOCK_SIZE</span><br><span class="line">    offsets = block_start + tl.arange(<span class="number">0</span>, BLOCK_SIZE)</span><br><span class="line">    mask = offsets &lt; n_elements</span><br><span class="line">    x = tl.load(x_ptr + offsets, mask=mask)</span><br><span class="line">    y = tl.load(y_ptr + offsets, mask=mask)</span><br><span class="line">    output = x + y</span><br><span class="line">    tl.store(output_ptr + offsets, output, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@autotune(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    configs=[</span></span></span><br><span class="line"><span class="params"><span class="meta">        triton.Config(<span class="params">&#123;<span class="string">&#x27;BLOCK_SIZE&#x27;</span>: <span class="number">256</span>&#125;, num_warps=<span class="number">4</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        triton.Config(<span class="params">&#123;<span class="string">&#x27;BLOCK_SIZE&#x27;</span>: <span class="number">512</span>&#125;, num_warps=<span class="number">4</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        triton.Config(<span class="params">&#123;<span class="string">&#x27;BLOCK_SIZE&#x27;</span>: <span class="number">512</span>&#125;, num_warps=<span class="number">8</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    ],</span></span></span><br><span class="line"><span class="params"><span class="meta">    key=[<span class="string">&#x27;n_elements&#x27;</span>],</span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_kernel_autotune</span>(<span class="params"></span></span><br><span class="line"><span class="params">    x_ptr,</span></span><br><span class="line"><span class="params">    y_ptr,</span></span><br><span class="line"><span class="params">    output_ptr,</span></span><br><span class="line"><span class="params">    n_elements,</span></span><br><span class="line"><span class="params">    BLOCK_SIZE: tl.constexpr</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    pid = tl.program_id(axis=<span class="number">0</span>)</span><br><span class="line">    block_start = pid * BLOCK_SIZE</span><br><span class="line">    offsets = block_start + tl.arange(<span class="number">0</span>, BLOCK_SIZE)</span><br><span class="line">    mask = offsets &lt; n_elements</span><br><span class="line">    x = tl.load(x_ptr + offsets, mask=mask)</span><br><span class="line">    y = tl.load(y_ptr + offsets, mask=mask)</span><br><span class="line">    output = x + y</span><br><span class="line">    tl.store(output_ptr + offsets, output, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params"></span></span><br><span class="line"><span class="params">    x: torch.Tensor,</span></span><br><span class="line"><span class="params">    y: torch.Tensor,</span></span><br><span class="line"><span class="params">    block_size: <span class="built_in">int</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    num_warps: <span class="built_in">int</span> = <span class="number">4</span>,</span></span><br><span class="line"><span class="params">    autotune: <span class="built_in">bool</span> = <span class="literal">False</span></span></span><br><span class="line"><span class="params"></span>) -&gt; torch.Tensor:</span><br><span class="line">    output = torch.empty_like(x)</span><br><span class="line">    <span class="keyword">assert</span> x.device.<span class="built_in">type</span> == DEVICE <span class="keyword">and</span> y.device.<span class="built_in">type</span> == DEVICE <span class="keyword">and</span> output.device.<span class="built_in">type</span> == DEVICE</span><br><span class="line">    n_elements = output.numel()</span><br><span class="line"></span><br><span class="line">    grid = <span class="keyword">lambda</span> meta: (triton.cdiv(n_elements, meta[<span class="string">&#x27;BLOCK_SIZE&#x27;</span>]), )   <span class="comment"># noqa: E731</span></span><br><span class="line">    <span class="keyword">if</span> autotune:</span><br><span class="line">        add_kernel_autotune[grid](x, y, output, n_elements)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=block_size, num_warps=num_warps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">    size = <span class="number">98432</span>  </span><br><span class="line">    x = torch.randn(size, device=DEVICE)</span><br><span class="line">    y = torch.randn(size, device=DEVICE)</span><br><span class="line"></span><br><span class="line">    output_triton = add(x, y, block_size=<span class="number">256</span>)</span><br><span class="line">    output_pytorch = x + y</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(output_triton)</span><br><span class="line">    <span class="built_in">print</span>(output_pytorch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;torch.<span class="built_in">max</span>(torch.<span class="built_in">abs</span>(output_triton - output_pytorch))&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@triton.testing.perf_report(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    triton.testing.Benchmark(<span class="params"></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        x_names=[<span class="string">&#x27;size&#x27;</span>],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        x_vals=[<span class="number">2</span>**i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="params"><span class="number">12</span>, <span class="number">28</span>, <span class="number">1</span></span>)],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        x_log=<span class="literal">True</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_arg=<span class="string">&#x27;provider&#x27;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_vals=[<span class="string">&#x27;torch&#x27;</span>, <span class="string">&#x27;triton_bs128&#x27;</span>, <span class="string">&#x27;triton_bs256&#x27;</span>, <span class="string">&#x27;triton_bs512&#x27;</span>, <span class="string">&#x27;triton_nw4&#x27;</span>, <span class="string">&#x27;triton_nw8&#x27;</span>, <span class="string">&#x27;triton_nw16&#x27;</span>, <span class="string">&#x27;triton_autotune&#x27;</span>],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_names=[<span class="string">&#x27;Torch&#x27;</span>, <span class="string">&#x27;Triton BS=128&#x27;</span>, <span class="string">&#x27;Triton BS=256&#x27;</span>, <span class="string">&#x27;Triton BS=512&#x27;</span>, <span class="string">&#x27;Triton NW=4&#x27;</span>, <span class="string">&#x27;Triton NW=8&#x27;</span>, <span class="string">&#x27;Triton NW=16&#x27;</span>, <span class="string">&#x27;Triton Autotune&#x27;</span>],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        styles=[(<span class="params"><span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;orange&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;cyan&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;magenta&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;yellow&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>)],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        ylabel=<span class="string">&#x27;GB/s&#x27;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        plot_name=<span class="string">&#x27;vector-add-performance&#x27;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        args=&#123;&#125;,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">    </span>)</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">benchmark</span>(<span class="params">size, provider</span>):</span><br><span class="line">    x = torch.rand(size, device=DEVICE, dtype=torch.float32)</span><br><span class="line">    y = torch.rand(size, device=DEVICE, dtype=torch.float32)</span><br><span class="line">    quantiles = [<span class="number">0.5</span>, <span class="number">0.2</span>, <span class="number">0.8</span>]</span><br><span class="line">    <span class="keyword">if</span> provider == <span class="string">&#x27;torch&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: x + y, quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_bs128&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">128</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_bs256&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">256</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_bs512&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">512</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_nw4&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">512</span>, num_warps=<span class="number">4</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_nw8&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">512</span>, num_warps=<span class="number">8</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_nw16&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, block_size=<span class="number">512</span>, num_warps=<span class="number">16</span>), quantiles=quantiles)</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_autotune&#x27;</span>:</span><br><span class="line">        ms, min_ms, max_ms = triton.testing.do_bench(<span class="keyword">lambda</span>: add(x, y, autotune=<span class="literal">True</span>), quantiles=quantiles)</span><br><span class="line">    gbps = <span class="keyword">lambda</span> ms: <span class="number">3</span> * x.numel() * x.element_size() * <span class="number">1e-9</span> / (ms * <span class="number">1e-3</span>)   <span class="comment"># noqa: E731</span></span><br><span class="line">    <span class="keyword">return</span> gbps(ms), gbps(max_ms), gbps(min_ms)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># main()</span></span><br><span class="line">    benchmark.run(print_data=<span class="literal">True</span>, show_plots=<span class="literal">True</span>, save_path=<span class="string">&quot;./results/01_vector_addition&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h2><p>比起源码，我额外增加了 <code>from triton.runtime import autotune</code> ，它的作用就是对于不同size的输入，会在首次执行时搜一遍所有可能的配置，找到其中效率最高的，后续对同样的size就会用固定的配置。</p><p>简单尝试一下的话，就会发现影响程序性能的因素有两个 <code>BLOCK_SIZE</code> 与 <code>num_warps</code>。其实理论上应该是 <code>BLOCK_SIZE</code> 、 <code>num_warps</code> 和 <code>input_size</code> 三者的关系决定了性能。我们用控制变量的方式来测一下它们的影响。</p><center><img src="https://i.072333.xyz/file/AgACAgEAAyEGAASMaMWHAAJ0iWgkKUDeOQt5_bzZKZovwbS5PBBHAALYrjEbdlsgRTJ8-RKWuAOmAQADAgADeAADNgQ.png" width="600px" /><p style="font-size: 10px;">Vector Addition Triton Kernel Performance。测BS时默认NW为4；测NW时默认BS为512</p></center><p><br></p><p>从图中我们能看出两个明显掉点的曲线，一个是 <code>BLOCK_SIZE</code> 为128时，此时的 <code>BLOCK_SIZE</code> 太小，分成的warps太多，导致管理调度 $2^{27} / 128 / 32$ 个块成了开销瓶颈；另一个是 <code>num_warps</code> 为16时，过大的线程块导致了对寄存器等资源的竞争更加剧烈，甚至可能发生寄存器溢出，显著影响效率。其实我也还不太会分析具体的原因，下面是详细的测试表格：</p><div class="table-container"><table><thead><tr><th>size</th><th>Torch</th><th>Triton BS=128</th><th>Triton BS=256</th><th>Triton BS=512</th><th>Triton NW=4</th><th>Triton NW=8</th><th>Triton NW=16</th><th>Triton Autotune</th></tr></thead><tbody><tr><td>4096.000000</td><td>9.035294</td><td>9.197604</td><td>9.142857</td><td>9.142857</td><td>9.142857</td><td>9.142857</td><td>9.088757</td><td>8.982456</td></tr><tr><td>8192.000000</td><td>17.964912</td><td>18.070588</td><td>17.860465</td><td>17.757226</td><td>18.070588</td><td>17.757226</td><td>18.070588</td><td>17.757226</td></tr><tr><td>16384.000000</td><td>35.514452</td><td>35.310345</td><td>35.310345</td><td>35.310345</td><td>35.310345</td><td>35.310345</td><td>35.720930</td><td>35.310345</td></tr><tr><td>32768.000000</td><td>68.266666</td><td>68.266666</td><td>69.423731</td><td>69.033707</td><td>69.033707</td><td>70.217145</td><td>69.818181</td><td>69.818181</td></tr><tr><td>65536.000000</td><td>132.843245</td><td>135.779009</td><td>135.779009</td><td>133.565214</td><td>133.565214</td><td>133.565214</td><td>135.032965</td><td>136.533331</td></tr><tr><td>131072.000000</td><td>253.360834</td><td>252.061538</td><td>255.999991</td><td>258.694729</td><td>260.063494</td><td>252.061538</td><td>253.360834</td><td>258.694729</td></tr><tr><td>262144.000000</td><td>457.227922</td><td>444.814490</td><td>455.111110</td><td>465.895721</td><td>463.698115</td><td>461.521112</td><td>453.013839</td><td>465.895721</td></tr><tr><td>524288.000000</td><td>750.412251</td><td>747.558951</td><td>774.047204</td><td>771.011790</td><td>771.011790</td><td>765.011652</td><td>741.916954</td><td>777.106702</td></tr><tr><td>1048576.000000</td><td>1228.800031</td><td>1159.929234</td><td>1187.963788</td><td>1221.167675</td><td>1228.800031</td><td>1184.385557</td><td>1156.517652</td><td>1217.387051</td></tr><tr><td>2097152.000000</td><td>1687.622326</td><td>1569.724635</td><td>1676.827323</td><td>1698.557221</td><td>1687.622326</td><td>1684.008546</td><td>1569.724635</td><td>1694.896509</td></tr><tr><td>4194304.000000</td><td>2154.608134</td><td>1927.529447</td><td>2148.721353</td><td>2160.527432</td><td>2163.499294</td><td>2145.789924</td><td>1852.607766</td><td>2163.499294</td></tr><tr><td>8388608.000000</td><td>2532.792214</td><td>2204.434417</td><td>2538.924930</td><td>2534.833158</td><td>2532.792214</td><td>2543.029933</td><td>2160.527432</td><td>2545.087416</td></tr><tr><td>16777216.000000</td><td>2755.784589</td><td>2349.311512</td><td>2763.045981</td><td>2756.388411</td><td>2755.784589</td><td>2763.045981</td><td>2394.920460</td><td>2758.200902</td></tr><tr><td>33554432.000000</td><td>2941.994716</td><td>2428.196121</td><td>2949.580950</td><td>2944.059933</td><td>2942.682906</td><td>2950.618366</td><td>2558.022378</td><td>2949.580950</td></tr><tr><td>67108864.000000</td><td>3021.832823</td><td>2487.232999</td><td>3032.757656</td><td>3021.832823</td><td>3022.740106</td><td>3032.392472</td><td>2644.858132</td><td>3032.027035</td></tr><tr><td>134217728.000000</td><td>3067.880595</td><td>2514.570784</td><td>3071.437476</td><td>3066.945668</td><td>3067.506556</td><td>3072.937670</td><td>2676.788108</td><td>3072.562746</td></tr></tbody></table></div><div class="note warning flat"><p>如果采用 <code>BS=4096，NW=16</code> 的配置的话，性能并不会显著下降，看起来似乎不大符合原来“寄存器溢出导致性能下降”的假设</p><p>gemini的回答是：</p><ul><li><p>当 Kernel 需要处理一个包含4096个元素的向量 (如 offsets = tl.arange(0, BLOCK_SIZE)) 时，编译器清楚地知道，不可能一次性将所有4096个元素（对于每个线程来说，是它负责的那部分）都完整地、同时地放在寄存器中进行操作。这远超出了单个线程或 Warp 的实际寄存器容量。因此，编译器很可能会生成一种高度流水线化 (pipelined) 或分块 (tiled/chunked) 的执行代码。它会将这4096个元素的操作分解成更小的、可管理的批次。例如，加载一小批数据到寄存器，计算，存储结果，然后再处理下一小批。<br>这种流水线化的处理方式，其瞬时 (instantaneous) 寄存器需求可能相对较低。也就是说，在任何特定时刻，每个线程为正在处理的小数据块所活跃使用的寄存器数量可能不多。</p></li><li><p>编译器处理512个元素时，它可能尝试一种不同的优化策略。也许它认为可以将更大部分的“向量”同时保持活跃在寄存器中，或者采用一种不那么积极分解成小块的策略，因为它认为这在某些情况下（如有足够寄存器时）可能更有效。<br>这种策略如果本身对寄存器的需求就比较高，那么当 num_warps 强制一个较紧的寄存器预算时，就更容易导致寄存器溢出。</p></li></ul><p>暂时不知道对错，感觉我还需要一些性能调优工具。</p></div><p>我们可以发现一个有趣的现象，即固定 <code>num_warps</code> 时，<code>BLOCK_SIZE</code> 设为256是最佳的；固定 <code>BLOCK_SIZE</code> 时，<code>num_warps</code> 设为8是最佳的。</p><p>由于性能受到多种因素的影响，因此影响程序效率的参数往往存在着被称为 <strong>sweet spot（甜点区）</strong> 的最佳范围，高了也不行，低了也不行。</p><p>一个比较好的方法是采用autotune，试几种可选参数后丢进去。这样程序会在初次运行时自动测试几种配置，后续对于同样的size均采用最佳配置即可。</p><p>值得一提的是，在计算非常简单的 Vector Addition 的场景下，性能瓶颈不在计算而在于带宽，因此最佳性能差距不会太大。</p><h1 id="Fused-Softmax"><a href="#Fused-Softmax" class="headerlink" title="Fused Softmax"></a>Fused Softmax</h1><p>遇到的一个神人问题是，源代码中的 <code>kernel[(num_programs, 1, 1)](y, x, x.stride(0), y.stride(0), n_rows, n_cols, BLOCK_SIZE, num_stages)</code> 报错</p><p>报错原因是，代码中已经预先编译过内核了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel = softmax_kernel.warmup(y, x, x.stride(<span class="number">0</span>), y.stride(<span class="number">0</span>), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE, num_stages=num_stages, num_warps=num_warps, grid=(<span class="number">1</span>, ))</span><br></pre></td></tr></table></figure><p>而在 <code>softmax_kernel</code> 的原始定义中，<code>BLOCK_SIZE</code> 和 <code>num_stages</code> 被声明为了 <code>tl.constexpr</code> 类型，表示编译时常量，即在内核中编译的过程中已经按照这个常量编译了，不应该在运行时再次传入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax_kernel</span>(<span class="params">output_ptr, input_ptr, input_row_stride, output_row_stride, n_rows, n_cols, BLOCK_SIZE: tl.constexpr, num_stages: tl.constexpr</span>):</span><br></pre></td></tr></table></figure><p>因此，源代码应该修改为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel[(num_programs, <span class="number">1</span>, <span class="number">1</span>)](y, x, x.stride(<span class="number">0</span>), y.stride(<span class="number">0</span>), n_rows, n_cols)</span><br></pre></td></tr></table></figure><p>最后，完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> triton</span><br><span class="line"><span class="keyword">import</span> triton.language <span class="keyword">as</span> tl</span><br><span class="line"><span class="keyword">from</span> triton.runtime <span class="keyword">import</span> driver</span><br><span class="line"></span><br><span class="line">target = driver.active.get_current_target()</span><br><span class="line">DEVICE = target.backend</span><br><span class="line">DEVICE_ID = driver.active.get_current_device()</span><br><span class="line"></span><br><span class="line">properties = driver.active.utils.get_device_properties(DEVICE_ID)</span><br><span class="line">NUM_SM = properties[<span class="string">&quot;multiprocessor_count&quot;</span>]</span><br><span class="line">NUM_REGS = properties[<span class="string">&quot;max_num_regs&quot;</span>]</span><br><span class="line">SIZE_SMEM = properties[<span class="string">&quot;max_shared_mem&quot;</span>]</span><br><span class="line">WARP_SIZE = properties[<span class="string">&quot;warpSize&quot;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">naive_softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="comment"># read MN elements, write M elements</span></span><br><span class="line">    x_max = x.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># read MN+M elements, write MN elements</span></span><br><span class="line">    z = x - x_max[:, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># read MN elements, write MN elements</span></span><br><span class="line">    numerator = torch.exp(z)</span><br><span class="line">    <span class="comment"># read MN elements, write M elements</span></span><br><span class="line">    denominator = numerator.<span class="built_in">sum</span>(dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># read MN + M elements, write MN elements</span></span><br><span class="line">    ret = numerator / denominator[:, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># in total: read 5MN + 2M elements ; wrote 3MN + 2M elements</span></span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@triton.jit</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax_kernel</span>(<span class="params">output_ptr, input_ptr, input_row_stride, output_row_stride, n_rows, n_cols, BLOCK_SIZE: tl.constexpr, num_stages: tl.constexpr</span>):</span><br><span class="line">    row_start = tl.program_id(<span class="number">0</span>)</span><br><span class="line">    row_step = tl.num_programs(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> row_idx <span class="keyword">in</span> tl.<span class="built_in">range</span>(row_start, n_rows, row_step, num_stages=num_stages):</span><br><span class="line">        row_start_ptr = input_ptr + row_idx * input_row_stride</span><br><span class="line">        col_offsets = tl.arange(<span class="number">0</span>, BLOCK_SIZE)</span><br><span class="line"></span><br><span class="line">        input_ptrs = row_start_ptr + col_offsets</span><br><span class="line">        mask = col_offsets &lt; n_cols</span><br><span class="line">        row = tl.load(input_ptrs, mask=mask, other=-<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        row_minus_max = row - tl.<span class="built_in">max</span>(row, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        numerator = tl.exp(row_minus_max)</span><br><span class="line">        denominator = tl.<span class="built_in">sum</span>(numerator, axis=<span class="number">0</span>)</span><br><span class="line">        softmax_output = numerator / denominator</span><br><span class="line"></span><br><span class="line">        output_row_start_ptr = output_ptr + row_idx * output_row_stride</span><br><span class="line">        output_ptrs = output_row_start_ptr + col_offsets</span><br><span class="line">        tl.store(output_ptrs, softmax_output, mask=mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x, num_stages_to_use</span>):</span><br><span class="line">    n_rows, n_cols = x.shape</span><br><span class="line">    BLOCK_SIZE = triton.next_power_of_2(n_cols)</span><br><span class="line"></span><br><span class="line">    num_warps = <span class="number">8</span></span><br><span class="line">    <span class="comment"># num_stages = 4 if SIZE_SMEM &gt; 200000 else 2</span></span><br><span class="line">    num_stages = num_stages_to_use</span><br><span class="line"></span><br><span class="line">    y = torch.empty_like(x)</span><br><span class="line">    kernel = softmax_kernel.warmup(y, x, x.stride(<span class="number">0</span>), y.stride(<span class="number">0</span>), n_rows, n_cols, BLOCK_SIZE=BLOCK_SIZE, num_stages=num_stages, num_warps=num_warps, grid=(<span class="number">1</span>, ))</span><br><span class="line">    kernel._init_handles()</span><br><span class="line"></span><br><span class="line">    n_regs = kernel.n_regs</span><br><span class="line">    size_smem = kernel.metadata.shared</span><br><span class="line"></span><br><span class="line">    occupancy = NUM_REGS // (n_regs * WARP_SIZE * num_warps)</span><br><span class="line">    occupancy = <span class="built_in">min</span>(occupancy, SIZE_SMEM // size_smem)</span><br><span class="line">    num_programs = NUM_SM * occupancy</span><br><span class="line"></span><br><span class="line">    num_programs = <span class="built_in">min</span>(num_programs, n_rows)</span><br><span class="line"></span><br><span class="line">    kernel[(num_programs, <span class="number">1</span>, <span class="number">1</span>)](y, x, x.stride(<span class="number">0</span>), y.stride(<span class="number">0</span>), n_rows, n_cols)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">    x = torch.randn(<span class="number">1823</span>, <span class="number">781</span>, device=DEVICE)</span><br><span class="line">    y_triton = softmax(x, <span class="number">4</span>)</span><br><span class="line">    y_torch = torch.softmax(x, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">assert</span> torch.allclose(y_triton, y_torch), (y_triton, y_torch)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@triton.testing.perf_report(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    triton.testing.Benchmark(<span class="params"></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        x_names=[<span class="string">&#x27;N&#x27;</span>],  <span class="comment"># argument names to use as an x-axis for the plot</span></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        x_vals=[<span class="number">128</span> * i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="params"><span class="number">2</span>, <span class="number">129</span></span>)],  <span class="comment"># different possible values for `x_name`</span></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_arg=<span class="string">&#x27;provider&#x27;</span>,  <span class="comment"># argument name whose value corresponds to a different line in the plot</span></span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_vals=[<span class="string">&#x27;torch&#x27;</span>, <span class="string">&#x27;triton_ns2&#x27;</span>, <span class="string">&#x27;triton_ns3&#x27;</span>, <span class="string">&#x27;triton_ns4&#x27;</span>],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        line_names=[</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="string">&quot;Torch&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="string">&quot;Triton (NS=2)&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="string">&quot;Triton (NS=3)&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">            <span class="string">&quot;Triton (NS=4)&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        ],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        styles=[(<span class="params"><span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>), (<span class="params"><span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;-&#x27;</span></span>)],</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        ylabel=<span class="string">&quot;GB/s&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        plot_name=<span class="string">&quot;softmax-performance-vs-num_stages&quot;</span>,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">        args=&#123;<span class="string">&#x27;M&#x27;</span>: <span class="number">4096</span>&#125;,</span></span></span></span><br><span class="line"><span class="params"><span class="params"><span class="meta">    </span>)</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">benchmark</span>(<span class="params">M, N, provider</span>):</span><br><span class="line">    x = torch.randn(M, N, device=DEVICE, dtype=torch.float32)</span><br><span class="line">    stream = <span class="built_in">getattr</span>(torch, DEVICE).Stream()</span><br><span class="line">    <span class="built_in">getattr</span>(torch, DEVICE).set_stream(stream)</span><br><span class="line">    <span class="keyword">if</span> provider == <span class="string">&#x27;torch&#x27;</span>:</span><br><span class="line">        ms = triton.testing.do_bench(<span class="keyword">lambda</span>: torch.softmax(x, axis=-<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_ns2&#x27;</span>:</span><br><span class="line">        ms = triton.testing.do_bench(<span class="keyword">lambda</span>: softmax(x, num_stages_to_use=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_ns3&#x27;</span>:</span><br><span class="line">        ms = triton.testing.do_bench(<span class="keyword">lambda</span>: softmax(x, num_stages_to_use=<span class="number">3</span>))</span><br><span class="line">    <span class="keyword">elif</span> provider == <span class="string">&#x27;triton_ns4&#x27;</span>:</span><br><span class="line">        ms = triton.testing.do_bench(<span class="keyword">lambda</span>: softmax(x, num_stages_to_use=<span class="number">4</span>))</span><br><span class="line">    gbps = <span class="keyword">lambda</span> ms: <span class="number">2</span> * x.numel() * x.element_size() * <span class="number">1e-9</span> / (ms * <span class="number">1e-3</span>)  <span class="comment"># noqa: E731</span></span><br><span class="line">    <span class="keyword">return</span> gbps(ms)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># main()</span></span><br><span class="line">    benchmark.run(show_plots=<span class="literal">True</span>, print_data=<span class="literal">True</span>, save_path=<span class="string">&quot;./results/02_fused_softmax&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="代码说明"><a href="#代码说明" class="headerlink" title="代码说明"></a>代码说明</h2><p>这个kernel比 <code>Vector Addition</code> 要稍微复杂一点，因为它涉及一个伪2D的并行。</p><p>说是伪2D是因为，它的 <code>BLOCK_SIZE</code> 取值是 <code>triton.next_power_of_2(n_cols)</code>，因此，每行不需要再单独划分。</p><p>主要的循环 <code>for row_idx in tl.range(row_start, n_rows, row_step, num_stages=num_stages):</code> 的功能是：</p><ul><li><p>如果总共有 P 个程序并行，当前程序为 i，则取出第 $[i, P+i, 2P+i, \cdots]$ 行处理</p></li><li><p>后续每行取 <code>BLOCK_SIZE</code> 其实就已经取完了，并没有在行上并行</p></li></ul><p>对于 <code>@triton.jit</code> 装饰的函数，其中的中间变量，会放在寄存器或者共享内存中，直到 <code>tl.store()</code> 才会写回（如果占太多了也有可能自动offload到显存）。共享内存一般是SRAM，硬件特性决定了比一般的显存（HBM）要快很多。</p><p><code>num_stages</code> 是一个流水线处理的参数，表示并行程度。如果 <code>num_stages&gt;1</code>，则在程序处理第一条数据时，会同时开始加载第二条数据，这样可以加速，但是对SRAM的大小又有了要求。</p><p>因此有 <code>num_stages = 4 if SIZE_SMEM &gt; 200000 else 2</code></p><h2 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h2><p>从图中可以看出，还是要快不少的，不同 <code>num_stages</code> 之间差距不大。</p><center><img src="https://i.072333.xyz/file/AgACAgEAAyEGAASMaMWHAAJ0j2gkMOUL6w_k6baDcCVISyal1o4NAALjrjEbdlsgRaE4ZMJECk62AQADAgADeAADNgQ.png" width="600px" /><p style="font-size: 10px;">Fused Softmax Triton Kernel Performance</p></center><p><br></p>]]></content>
      
      
      <categories>
          
          <category> cuda </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
            <tag> triton </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Part III of Mathematical Structure of Mamba - S4D</title>
      <link href="/posts/10040.html"/>
      <url>/posts/10040.html</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>本篇是mamba系列blog的第三篇文章，系列文章见：</p><ul><li><p><a href="https://anti-entrophic.github.io/posts/10038.html" title="Part I of Mathematical Structure of Mamba - Hippo">Part I of Mathematical Structure of Mamba - Hippo</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10039.html" title="Part II of Mathematical Structure of Mamba - S4">Part II of Mathematical Structure of Mamba - S4</a></p></li><li><p>Part III of Mathematical Structure of Mamba - S4D</p></li><li><p><a href="https://anti-entrophic.github.io/posts/10043.html" title="Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2">Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2</a></p></li></ul><p>剩余预计还有两篇文章正在生产中~</p></div><h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>在mamba之前，HiPPO、S4、DSS、S4D都是Albert Gu的工作，可以说是一己之力推动了SSM模型的发展。在S4到mamba之间，其实还经历了很多简化。</p><p>本篇选取中间的一篇工作S4D，来一窥目前的mamba仓库代码的雏形。（主要是比mamba清楚太多了，mamba文章和代码仓库完全看不懂，只能说被ICLR24拒稿是有原因的）</p><p>P.S. DSS和S4D都是同一年的NIPS，爽发啊</p><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>S4的突出贡献就在于给出了HiPPO矩阵及相关卷积核高阶幂的求解办法 <strong>DPLR</strong>，但是从推导就可以看出，仍然是过于复杂了。</p><p>前置工作 DSS 发现，存在使用对角线状态矩阵简化原来的HiPPO矩阵的可能性，不过还是引入了一些有难度的操作（需要复值softmax，并且没有解释为什么对角线矩阵可以work）</p><p>本篇文章就进一步梳理了SSM使用对角线状态方程的最佳表达形式。如果A只有对角线的话那A的高阶幂就太好算了。</p><h1 id="零阶保持离散化-ZOH"><a href="#零阶保持离散化-ZOH" class="headerlink" title="零阶保持离散化(ZOH)"></a>零阶保持离散化(ZOH)</h1><p>我们首先来介绍一下零阶保持离散化方法</p><h2 id="状态方程"><a href="#状态方程" class="headerlink" title="状态方程"></a>状态方程</h2><script type="math/tex; mode=display">\frac{dh(t)}{dt} = Ah(t) + Bx(t)</script><h2 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h2><p>使用<strong>积分因子法</strong>，首先将方程整理为标准形式：</p><script type="math/tex; mode=display">\frac{dh(t)}{dt} - Ah(t) = Bx(t)</script><p>接下来计算积分因子 $\mu(t)$：</p><script type="math/tex; mode=display">\mu(t) = exp(\int -Adt) = e^{-At}</script><p>将积分因子乘以方程两边：</p><script type="math/tex; mode=display">e^{-At}\frac{dh(t)}{dt}-Ae^{-At}h(t) = Be^{-At}x(t)</script><p>左边变为：</p><script type="math/tex; mode=display">\frac{d}{dt}(e^{-At}h(t)) = Be^{-At}x(t)</script><p>对两边积分：</p><script type="math/tex; mode=display">\int_{t_0}^t \frac{d}{d\tau}(e^{-A\tau}h(\tau))d\tau=\int_{t_0}^{t}Be^{-A\tau}x(\tau)d\tau</script><p>积分后得到：</p><script type="math/tex; mode=display">e^{-At}h(t) - e^{-At_0}h(t_0) = \int_{t_0}^{t}Be^{-A\tau}x(\tau)d\tau</script><p>解出 $h(t)$：</p><script type="math/tex; mode=display">h(t) = e^{A(t-t_0)}h(t_0) + \int_{t_0}^tBe^{A(t-\tau)}x(\tau)d\tau</script><h2 id="离散化"><a href="#离散化" class="headerlink" title="离散化"></a>离散化</h2><p>我们考虑 $ t = t_0 + \Delta$，则 $x(\tau)$ 在这段时间内保持恒定，不妨设为 $x_k$, 则</p><script type="math/tex; mode=display">\begin{aligned}h(t+\Delta) &= e^{A\Delta}h(t) + \int_t^{t+\Delta}Be^{A(t-\tau)}x_kd\tau \\&= e^{A\Delta}h(t) + (\int_t^{t+\Delta}e^{A(t-\tau)}d\tau)Bx_k \\&= e^{A\Delta}h(t) + (\int_0^{\Delta}e^{A\tau}d\tau)Bx_k\end{aligned}</script><p>其中，$\int_0^{\Delta}e^{A\tau}d\tau$ 的结果可以如下计算得到：</p><script type="math/tex; mode=display">\frac{d}{dt}e^{At} = Ae^{At}</script><p>两边积分得：</p><script type="math/tex; mode=display">\int Ae^{At}dt = e^{At} + C</script><p>左乘 $A^{-1}$ 得：</p><script type="math/tex; mode=display">\int e^{At}dt = A^{-1}e^{At} + C</script><p>对于定积分 $[0，\Delta]$，结果是：</p><script type="math/tex; mode=display">\int_0^{\Delta}e^{A\tau}d\tau = A^{-1}(e^{A\Delta}-I)</script><p>综上，代入积分结果，原来的离散化方程为：</p><script type="math/tex; mode=display">h(t+\Delta) = e^{A\Delta}h(t) + A^{-1}(e^{A\Delta}-I)Bx_k</script><p>所以</p><script type="math/tex; mode=display">\begin{aligned}\bar{A} &= e^{A\Delta} \\\bar{B} &=  A^{-1}(e^{A\Delta}-I)B\end{aligned}</script><p>而 SSM 中的 $C$ 和 $D$ 是不需要离散化的，因为它本来就是在离散空间上更新的。其实也不一定需要是 $x’ = Ch + Dx$ 吧，也可以是 $y = Ch + Dx$，SSM最重要的只是维护一个状态罢了——这个状态是对记忆空间正交基的投影。</p><p>之前S4中用双线性离散化，就是因为不是对角线形式的 $\bar{A} = e^{A\Delta}$ 不好算。</p><h2 id="矩阵指数"><a href="#矩阵指数" class="headerlink" title="矩阵指数"></a>矩阵指数</h2><p>矩阵指数的定义参考标量指数函数的泰勒展开：</p><script type="math/tex; mode=display">e^{At} = I + At + \frac{(At)^2}{2!}+...</script><p>系统的稳定性主要由矩阵指数 $e^{At}$ 决定，分析 $e^{At}$ 的敛散性比较复杂且经典，这里直接给出结论 —— 由矩阵 $A$ 的特征值的实部的正负决定</p><ul><li>当矩阵 $A$ 的所有特征值的实部都小于0时，矩阵指数函数 $e^{At}$ 在 $t \rightarrow \infty$ 时收敛到零矩阵。</li></ul><h3 id="证明"><a href="#证明" class="headerlink" title="证明"></a>证明</h3><div class="note warning flat"><p>意会一下，以后补上完整证明</p></div><p>任何矩阵 $A$ 都可以分解为 Jordan 标准型 $A = PJP^{-1}$，其中 $J$ 是 Jordan 矩阵。因此，$e^{At}=Pe^{Jt}P^{-1}$</p><p>每个 Jordan 块对应一个特征值 $\lambda$，其矩阵指数包含形如 $t^ke^{\lambda t}$的项（其中 $k$ 是多项式项的阶数）。当 $\lambda$ 的实部小于0时，指数衰减 $e^{\lambda t}$ 会压制多项式增长 $t^k$，使得每一项在 $t \rightarrow \infty$ 时趋于0</p><p>因此整个Jordan 矩阵的指数 $e^{Jt}$ 趋向于零矩阵，进而 $e^{At} = Pe^{Jt}P^{-1}$ 也趋向于零矩阵。</p><h2 id="Left-half-plane-condition"><a href="#Left-half-plane-condition" class="headerlink" title="Left-half plane condition"></a>Left-half plane condition</h2><p>因此，为了限制 $A$ 的实部大小，一个常见的方法是用指数函数来创建 $A$ 的实部：$A = -e^{A_{Re}} + i \cdot A_{Im}$</p><p>这样实部就总是负的，天才。</p><p>Albert Gu 在这篇文章中指出，不一定要用指数函数，用一般的激活函数比如说 ReLU, softplus也是可以的。现在transformers库对mamba的实现中就是用的exp的形式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># transformers/models/mamba2/modeling_mamba2.py</span></span><br><span class="line">A = -torch.exp(self.A_log.<span class="built_in">float</span>())</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Model Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mamba </tag>
            
            <tag> Model Structure </tag>
            
            <tag> HiPPO </tag>
            
            <tag> S4 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sparsemax</title>
      <link href="/posts/10035.html"/>
      <url>/posts/10035.html</url>
      
        <content type="html"><![CDATA[<p>介绍一篇修改softmax的文章，题目是：</p><p><a href="https://arxiv.org/pdf/1602.02068" title="950引">[ICML 2016] From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification</a></p><p>它允许softmax非平滑输出，某些位置的prob直接为0</p><h1 id="method"><a href="#method" class="headerlink" title="method"></a>method</h1><p>原来的softmax公式是通过下面的计算得到概率分布</p><script type="math/tex; mode=display">\text{softmax}_i(z) = \frac{e^{z_i}}{\sum_j e^{z_j}}</script><p>现在，作者考虑直接将隐状态向一个 $K-1$ 维的单纯形投影，求得的 $p$ 即是softmax的结果</p><script type="math/tex; mode=display">\begin{aligned}\Delta^{K-1} &:=\{p\in \mathbb{R}^K | 1^Tp=1, p \geq 0\} \\\text{sparsemax}(z) &:= \mathop{\arg\max}\limits_{p \in \Delta^{K-1}} ||p-z||^2\end{aligned}</script><h2 id="为什么是K-1维"><a href="#为什么是K-1维" class="headerlink" title="为什么是K-1维"></a>为什么是K-1维</h2><p>因为有 $1^Tp=1$ 的限制，导致自由度减1</p><p>和 $x+y+z=1$ 表示的是一个平面而不是三维空间是一个道理</p><h2 id="如何求解"><a href="#如何求解" class="headerlink" title="如何求解"></a>如何求解</h2><p>将原问题转化为一个优化问题：</p><script type="math/tex; mode=display">\begin{aligned}\text{min} \quad & ||p-z||^2 \\s.t. \quad & 1^Tp=1 \\& p \geq 0\end{aligned}</script><p>考虑求解其拉格朗日对偶问题：</p><script type="math/tex; mode=display">L(p, \lambda, \mu) = \frac{1}{2} ||p-z||^2 - \lambda^Tp + \mu(1^Tp-1)</script><p>这里系数 $\frac{1}{2}$ 是为了方便求导后消去系数</p><p>考虑KKT条件：</p><script type="math/tex; mode=display">\left\{\begin{aligned}\nabla_p L(p^*, \lambda^*, \mu^*) &= p^*-z-\lambda^*+\mu^*1 \qquad&(1)\\ 1^Tp^* &= 1 &(2)\\ p^* &\geq 0   &(3)\\\lambda^* &\geq 0  &(4)\\\lambda^*p^* &= 0  &(5)\end{aligned}\right.</script><p>对于 $p_i^{\ast} &gt; 0$，由于式(5)，此时必有 $\lambda_i^{\ast}=0$，所以由式(1)，得：</p><script type="math/tex; mode=display">p_i^* = z_i - \mu, \quad s.t.\quad p_i^* > 0</script><p>由式(2)，得：</p><script type="math/tex; mode=display">\begin{aligned}\sum_{i \in K}p_i^* &= 0 + \sum_{i \in S(z)}p_i^* \\1 &= \sum_{i \in S(z)}(z_i - \mu) \\\mu &= \frac{\sum_{i \in S(z)}z_i - 1}{|S(z)|}\end{aligned}</script><p>其中，$S(z) = \{j \in K \, | \,\, p_j^*&gt;0\}$</p><p>由此，我们知道了如何从 $z$ 得到 $p$，即：</p><script type="math/tex; mode=display">p = \text{sparsemax}(z) = [z - \mu]_+</script><p>求出 $\mu$ 的关键，是求出多大 $|S(z)|$ 才能正好满足：</p><ul><li><p>$z_j^* - \mu &gt; 0, \quad \forall j \in S(z)$</p></li><li><p>$z_j^* - \mu \leq 0, \quad \forall j \notin S(z)$</p></li></ul><p>注意 $\mu$ 不随着 $|S(z)|$ 的增加而单调，所以不能<strong>二分</strong>求解，朴素地用 $O(K)$ 的复杂度遍历寻找 $\mu$</p><div class="note success flat"><p>但是 $\Delta \mu$ 是单调的，所以理应有更快速的搜索方法</p><p>如果只是在 lm_head 位置对词表大小 vocab_size 做 softmax，那可能确实速度不要紧</p><p>但是如果是对attention做softmax就完蛋了，因为它要排序，排序的复杂度是 $O(N \log N)$。这样对于长度为 $N$ 的 attention，复杂度直接到 $O(KN\log N)$ 了，爆了</p><p>所以如果不做修改，不可能用到attention里</p></div><h2 id="具体例子"><a href="#具体例子" class="headerlink" title="具体例子"></a>具体例子</h2><p>假设我们有一个隐状态 $[1.5,2,0.5]^T$，计算过程如下：</p><p>对所有元素大小排序 $2&gt;1.5&gt;0.5$</p><p>遍历 $|S(z)|$，从 $|S(z)|=1$ 开始，求出 $\mu = \frac{2-1}{1} = 1$</p><p>验证是否满足条件：</p><script type="math/tex; mode=display">\left\{\begin{aligned}2 - 1 > 0 \\1.5 - 1 < 0 \\0.5 - 1 < 0\end{aligned}\right.</script><p>不满足，继续搜，$|S(z)|=2$，$\mu = \frac{2+1.5-1}{2} = 1.25$</p><p>验证是否满足条件：</p><script type="math/tex; mode=display">\left\{\begin{aligned}2 - 1.25 > 0 \\1.5 - 1.25 > 0 \\0.5 - 1.25 < 0\end{aligned}\right.</script><p>满足了，所以 $\text{sparsemax}(z) = [0.25, 0.75, 0]$</p>]]></content>
      
      
      <categories>
          
          <category> Model Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Model Structure </tag>
            
            <tag> softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Part II of Mathematical Structure of Mamba - S4</title>
      <link href="/posts/10039.html"/>
      <url>/posts/10039.html</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>本篇是mamba系列blog的第二篇文章，系列文章见：</p><ul><li><p><a href="https://anti-entrophic.github.io/posts/10038.html" title="Part I of Mathematical Structure of Mamba - Hippo">Part I of Mathematical Structure of Mamba - Hippo</a></p></li><li><p>Part II of Mathematical Structure of Mamba - S4</p></li><li><p><a href="https://anti-entrophic.github.io/posts/10040.html" title="Part III of Mathematical Structure of Mamba - S4D">Part III of Mathematical Structure of Mamba - S4D</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10043.html" title="Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2">Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2</a></p></li></ul><p>剩余预计还有一篇文章正在生产中~</p></div><h1 id="State-space-model"><a href="#State-space-model" class="headerlink" title="State space model"></a>State space model</h1><p>前一篇文章介绍的HiPPO为我们奠定了在离散时间系统下维护模型状态的方法。视 $c_k$ 为模型当前的状态，$f_k$ 为模型当前的输入序列，即可通过公式更新得到模型后续的状态 $c_{k+1}$，这是一个RNN-like的结构。无独有偶，在工程学科中的状态空间模型（State Space Model）也有类似的结构：</p><script type="math/tex; mode=display">\begin{aligned}x'(t) &= Ax(t) + Bu(t) \\y(t)  &= Cx(t) + Du(t)\end{aligned}</script><p>直观理解，$A$ 代表了模型当前状态如何影响后续状态，$B$ 代表了模型当前输入如何影响后续状态，$C$ 代表了模型当前状态如何影响模型输出，$D$ 代表了模型当前输入如何影响模型输出。</p><p>我们可以对这建立在连续信号上的公式离散化，得到离散数据上的形式：</p><script type="math/tex; mode=display">\begin{aligned}x_k &= \bar{A}x_{k-1} + \bar{B}u_k \\y_k &= \bar{C}x_k + \bar{D}u_k\end{aligned}</script><p>$\bar{A}, \bar{B}, \bar{C}, \bar{D}$ 的具体形式可以通过不同的离散化方法（前向欧拉、后向欧拉、双线性等）从 $A,B,C,D$ 得到。这种形式的SSM可以在离散数据上计算，并且计算方式是step-by-step的。</p><p>例如，对于双线性离散化方法有：</p><script type="math/tex; mode=display">\begin{aligned}\bar{A}&=(I-\frac{\Delta}{2}A)^{-1}(I+\frac{\Delta}{2}A) \\\bar{B}&=(I-\frac{\Delta}{2}A)^{-1}\Delta B\end{aligned}</script><h2 id="为什么我们需要离散化"><a href="#为什么我们需要离散化" class="headerlink" title="为什么我们需要离散化"></a>为什么我们需要离散化</h2><div class="note warning flat"><p>个人看法</p></div><p>这个问题很关键，它直接决定了Mamba的改进目标。</p><p>试想一下，以文本为例，我们的输入输出都是离散的模态，那所谓的连续究竟是在何处呢？是模型内部的状态演化。上述的一系列以SSM为动力学建模的模型，都假设了模型存在一个连续的状态。但这实际上有保证吗？</p><p>考虑 $h(t’) = h(t) + x(t)$，对于离散的冲击 $x(t)$，$h(t)$ 显然就无法保持连续了。所以，需要对该更新方程进行离散化，在离散方程 $h_{t+1} = \bar{A}h_t + \bar{B}x_t$ 上的冲击 $x_t$，其实被隐式地理解为了在区间 $[t, t+1)$内的持续影响。</p><p>这一步是否合理有待商榷，毕竟把离散冲击当成持续影响这一步本身就有点抽象。在mamba中，为了解决这一个问题而提出的方法是，构建输入依赖的离散采样率 $\Delta$，通过预测 $\Delta_k$ 动态调整离散化区间的长度：</p><ul><li><p>若 $\Delta_k$ 较小，系统更频繁地响应输入，接近原来的离散冲击。</p></li><li><p>若 $\Delta_k$ 较大，系统将输入“平滑扩散”到更长区间</p></li></ul><p>所以理论上，它在某些时刻应该是不能保证连续的，只是想了办法让脉冲的影响可控。</p><h3 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h3><p>经xr哥提醒，开头的token embedding可能是离散的，但是到中间层时，hidden state可能已经比较连续了。我记得S4的续作H3就有结合transformer和SSM，难道就是开头用transformer，中间用SSM？这样就可以减少离散脉冲对理论结构的影响了。所以Jamba这种混合模型，就该是开头transformer，中间SSM？</p><p>感觉mamba不同层之间的 $\Delta$ 应该会有显著差异吧</p><p>后续要再去钻研下</p><h2 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h2><p>我们首先忽略 $\bar{D}$ ，这是一个简单的残差连接。</p><p>对于离散形式公式做简单推导：</p><script type="math/tex; mode=display">\begin{aligned}x_0 &= \bar{B}u_0 & x_1 &= \bar{A}\bar{B}u_0+\bar{u_1} & x_2 &= \bar{A}^2\bar{B}u_0+\bar{A}\bar{B}u_1 + \bar{B}u_2 \\y_0 &=  \bar{C}\bar{B}u_0 & y_1 &= \bar{C}\bar{A}\bar{B}u_0 + \bar{C}\bar{B}u_1 & y_2 &= \bar{C}\bar{A}^2\bar{B}u_0 + \bar{C}\bar{A}\bar{B}u_1 + \bar{C}{B}u_2\end{aligned}</script><p>可以看到第 $k$ 步的输出具有通项形式：</p><script type="math/tex; mode=display">\begin{aligned}x_k &= \sum_{i=0}^k\bar{A}^{k-i}\bar{B}u_i\\y_k &= \sum_{i=0}^k\bar{C}\bar{A}^{k-i}\bar{B}u_i\end{aligned}</script><p>这是一个卷积核为序列长度的卷积，可以记作：</p><script type="math/tex; mode=display">y = \bar{K} * u, \quad \bar{K}\in \mathbb{R}^{L}:=\mathcal{K}_L(\bar{A}, \bar{B}, \bar{C}):=(\bar{C}\bar{A}^{i}\bar{B})_{i\in[L]} = (\bar{C}\bar{B}, \bar{C}\bar{A}\bar{B}, ..., \bar{C}\bar{A}^{L-1}\bar{B})</script><p>因此，State Space Model既可以建模为RNN，也可以建模为CNN。在我的理解中，prefill阶段就可以使用卷积形式，结合<a href="https://oi-wiki.org/math/poly/fft/#%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2" title="oi-wiki">离散傅里叶变换DFT</a>，只需要先变换到频域上再逐点相乘即可（$\mathcal{F}\{f*g\} = F(f) \cdot F(G)$），时间复杂度为 $O(L\log L)$；后续推理继续用RNN形式自回归地生成，复杂度为 $O(L)$。</p><div class="note warning flat"><p>这里我考虑得非常不严谨，实际上我自己也没想清楚。时间复杂度瓶颈还可能受到，矩阵乘法的复杂度，对矩阵进行傅里叶变换的复杂度，算子实现等的影响。如果想要严格讨论时间复杂度，可能配合代码分析更加合适。</p></div><h1 id="结构化状态空间"><a href="#结构化状态空间" class="headerlink" title="结构化状态空间"></a>结构化状态空间</h1><p>在S4的前置工作中，作者发现随机初始化的SSM性能非常差，但使用HiPPO Matrix对 $A$ 初始化：</p><script type="math/tex; mode=display">(\text{HiPPO Matrix}) \quad A_{nk} = -\left\{\begin{matrix}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} & \text{if} \quad n>k \\n+1 & \text{if} \quad n=k \\0 & \text{if} \quad n<k\end{matrix}\right. \\</script><p>就取得了非常大的性能提升。例如，仅仅对矩阵 $A$ 从随机初始化改成HiPPO初始化就在sequential MNIST上把性能从60%提升到了98%，这步可以称为是结构化。</p><div class="note warning flat"><p>注意这里把之前公式中，外面的负号放进来了。</p></div><h1 id="高效算法"><a href="#高效算法" class="headerlink" title="高效算法"></a>高效算法</h1><p>不过，对SSM进行直接计算存在效率上的问题：</p><ul><li><p>对于Recurrent形式的SSM，由于参数可学习，因此在每一步上都需要重新计算 $\bar{A}=(I-\frac{\Delta}{2}A)^{-1}(I+\frac{\Delta}{2}A)$ ，需要进行矩阵-矩阵相乘。如果能找到某种基于矩阵-向量乘积的计算方法，计算量将大幅降低。</p></li><li><p>对于Convolutional形式的SSM，除了 $DFT$ 的加速，计算瓶颈还在卷积核的计算上。长度为 $L$ 的卷积核 $\bar{K}$ 包含矩阵 $\bar{A}^{L-1}$ ，即HiPPO矩阵 $\bar{A}$ 的 $L-1$ 次幂。需要找到该高阶矩阵幂的快速算法。</p></li></ul><p>对于原始的更新公式：</p><script type="math/tex; mode=display">\begin{aligned}x_k &= \bar{A}x_{k-1} + \bar{B}u_k \\y_k &= \bar{C}x_k + \bar{D}u_k\end{aligned}</script><p>如果令 $(A,B,C)\sim (V^{-1}AV, V^{-1}B, CV)$，这实际上是对state进行了一个线性变换 $x_k=V\bar{x}_k$</p><p>如果我们能找到性质良好的矩阵 $V$ 对HiPPO矩阵 $A$ 进行规范化，比如将 $A$ 对角化，就可以很容易计算 $V^{-1}AV$ 的高次幂</p><p>事实上确实存在这样的对角化方法。S4的作者证明，对于所有的HiPPO Matrix（HiPPO-LegS、HiPPO-LegT、HiPPO-LagT），都可以用矩阵 $V_{ij} = \begin{pmatrix} i+j \\ i-j \end{pmatrix}$ 进行对角化（这里指的是组合数）。然而直接对 $A$ 进行这样的对角化会有数值稳定性上的问题，因为很容易得到:</p><script type="math/tex; mode=display">\begin{aligned}V_{3i,i} =\begin{pmatrix} 4i \\ 2i \end{pmatrix} & = \frac{(4i)!}{(2i)!(2i)!}\\& \approx \frac{\sqrt{8\pi i}(\frac{4i}{e})^{4i}}{4\pi i (\frac{2i}{e})^{4i}}, \quad \text{根据stirling公式} \quad n! \approx \sqrt{2\pi n}(\frac{n}{e})^n \\ & = \frac{2^{4i}}{\sqrt{2\pi i}} \\& \approx 2^{4i}\end{aligned}</script><p>即矩阵 $V$ 中最大元素的值的大小几乎是指数增加的，反映在实际运行时，序列长度 $L$ 只要稍微大一点，卷积核中就会出现 NaN</p><h2 id="Normal-Plus-Low-Rank"><a href="#Normal-Plus-Low-Rank" class="headerlink" title="Normal Plus Low-Rank"></a>Normal Plus Low-Rank</h2><p>直接使用 $V_{ij}=\begin{pmatrix} i+j \\ i-j \end{pmatrix}$ 虽然可以进行对角化，但会有稳定性问题。如果矩阵 $A$ 为正规矩阵，则可以用酉矩阵对 $A$ 进行酉对角化。不幸的是所有HiPPO matrix都不是正规矩阵。</p><p>虽然无法直接对 $A$ 进行稳定的对角化，但我们观察到，所有的HiPPO matrix都能被分解为一个正规矩阵和一个低秩矩阵的和。</p><script type="math/tex; mode=display">\quad A_{nk} = -\left\{\begin{matrix}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} & \text{if} \quad n>k \\n+1 & \text{if} \quad n=k \\0 & \text{if} \quad n<k\end{matrix}\right. \\</script><p>对矩阵相加一个每个元素均为 $\frac{1}{2}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}}$ 的矩阵（低秩，秩为1），可以得到：</p><script type="math/tex; mode=display">-\left\{\begin{matrix}\frac{1}{2}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} & \text{if} \quad n>k \\\frac{1}{2} & \text{if} \quad n=k \\-\frac{1}{2}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} & \text{if} \quad n<k\end{matrix}\right. \\</script><p>这个矩阵等于一个单位阵 $-\frac{1}{2}I$ 加一个斜对称矩阵 $S$ ，斜对称矩阵是正规矩阵的一个特例，可以用酉矩阵进行对角化。虽然 $-\frac{1}{2}I+S$ 不再是斜对称矩阵，但它仍可以使用某些使 $S$ 对角化的酉矩阵进行对角化，即仍为正规矩阵。</p><p>正式地，我们可以将所有HiPPO Matrix表示为<strong>NPLR</strong>（Normal Plus Low-Rank）:</p><script type="math/tex; mode=display">A = V \Lambda V^* - PQ^T</script><p>其中 $PQ^T$ 为低秩分解，像上文HiPPO-LegS的低秩矩阵直接就是秩为1，可以很方便的分解为两个向量的乘积。</p><p>为了后续的频域计算，我们从这里开始将矩阵的定义扩展到复数空间。进行一些变换我们得到：</p><script type="math/tex; mode=display">A = V \Lambda V^* - PQ^T = V(\Lambda-(V^{*}P)(V^*Q)^*)V^*</script><p>因此，计算 $A$ 的高次幂转化为对 $\Lambda - ({V^{\ast}} P)({V^{\ast}} Q)^{\ast} $ 的计算。这个矩阵具有更良好的形式，称为<strong>DPLR</strong> (Diagonal Plus Low-Rank)。然而即使是DPLR，到这一步仍然不好计算。接下来针对两种模式的SSM，即RNN view（推理）和CNN view（训练），分别用矩阵理论进行推导，找到高效的计算方法。</p><h2 id="RNN-view"><a href="#RNN-view" class="headerlink" title="RNN view"></a>RNN view</h2><p>根据前面的推导，我们知道所有HiPPO Matrices都可以表示为DPLR，不失一般性，我们记为 $A=\Lambda - PQ^{\ast}$。</p><p>在S4中，我们使用双线性离散化方法，假设步长为 $\Delta$，我们有：</p><script type="math/tex; mode=display">\begin{aligned}\bar{A}&=(I-\frac{\Delta}{2}A)^{-1}(I+\frac{\Delta}{2}A) \\\bar{B}&=(I-\frac{\Delta}{2}A)^{-1}\Delta B\end{aligned}</script><p>分别计算两个相乘项，我们有：</p><script type="math/tex; mode=display">\begin{aligned}I+\frac{\Delta}{2}A &= I + \frac{\Delta}{2}(\Lambda-PQ^*) \\&= \frac{\Delta}{2} [\frac{2}{\Delta}I + (\Lambda - PQ^*)] \\&= \frac{\Delta}{2} A_0\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}(I-\frac{\Delta}{2}A)^{-1} &= (I - \frac{\Delta}{2}(\Lambda-PQ^{\ast}))^{-1} \\&= \frac{2}{\Delta}[\frac{2}{\Delta} - \Lambda + PQ^{\ast}]\end{aligned}</script><p>使用<strong>Woodbury matrix identity</strong>: $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$，我们可以得到：</p><script type="math/tex; mode=display">\begin{aligned}(I-\frac{\Delta}{2}A)^{-1} &= \frac{2}{\Delta}[D-DP(I+Q^{\ast}DP)^{-1}Q^{\ast}D] \\ &= \frac{2}{\Delta} A_1\end{aligned}</script><p>其中 $A_0 = \frac{2}{\Delta}I + (\Lambda - PQ^{\ast}), D = (\frac{2}{\Delta}-\Lambda)^{-1}, A_1 = D-DP(I + Q^{\ast}DP) ^{-1}Q^{\ast}D$</p><p>代入可得：</p><script type="math/tex; mode=display">\begin{aligned}\bar{A} &= A_1A_0 \\\bar{B} &= \frac{2}{\Delta} A_1 \Delta B = 2A_1 B \end{aligned}</script><p>再将上式代入离散SSM，可以得到：</p><script type="math/tex; mode=display">\begin{aligned}x_k &= \bar{A}x_{k-1} + \bar{B}u_k \\&= A_1A_0x_{k-1} + 2A_1B_{u_k} \\y_k &= Cx_k\end{aligned}</script><p>注意到 $A_0, A_1$ 的组成均为单位阵、对角阵和低秩矩阵，因此 $A_1, A_0$的计算仅包含矩阵-向量乘法，RNN view计算一步的复杂度为 $O(N)$</p><h2 id="CNN-view"><a href="#CNN-view" class="headerlink" title="CNN view"></a>CNN view</h2><p>我们稍微对符号进行一点修改便于后面的推导（将 $C$ 记为列向量）：</p><script type="math/tex; mode=display">\begin{aligned}x'(t) &= Ax(t) + Bu(t) \\y(t) &= C^{\ast}x(t) + Du(t)\end{aligned}</script><p>我们得到的长度为 $L$ 的卷积核为：</p><script type="math/tex; mode=display">\mathcal{K}_L(\bar{A}, \bar{B}, \bar{C}) = (\bar{C}^{\ast}\bar{B}, \bar{C}^{\ast}\bar{A}\bar{B}, ..., \bar{C}^{\ast}\bar{A}^{L-1}\bar{B}) \in \mathbb{R}^L</script><p>我们定义一个对应于卷积核的SSM生成函数（一个定义在频域的函数，可以通过DFT变换到时域的卷积核），在节点 $z$ 其表达式为：</p><script type="math/tex; mode=display">\hat{\mathcal{K}}(z; \bar{A}, \bar{B}, \bar{C}) \in \mathbb{C} := \sum_{i=0}^{\infty} \bar{C}^{\ast} \bar{A}^i\bar{B}z^{i} = \bar{C}^{\ast}(I-\bar{A}z)^{-1}\bar{B}</script><p>特别地，截断SSM生成函数为：</p><script type="math/tex; mode=display">\hat{\mathcal{K}}_L(z; \bar{A}, \bar{B}, \bar{C})^{\ast} \in \mathbb{C} := \sum_{i=0}^{L-1} \bar{C}^{\ast}\bar{A}^i \bar{B}z^i = \bar{C}^{\ast}(I-\bar{A}^Lz^L)(I-\bar{A}z)^{-1}\bar{B}</script><p>对于 $M$ 个节点的向量 $\Omega \in \mathbb{C}^{M}$，我们有：</p><script type="math/tex; mode=display">\hat{\mathcal{K}}_L(\Omega; \bar{A}, \bar{B}, \bar{C}) \in \mathbb{C}^M := (\hat{\mathcal{K}}_L(\omega_k; \bar{A}, \bar{B}, \bar{C}))_{k \in [M]}</script><p>上面都是针对生成卷积核的函数的表达式，我们记卷积核及其频域形式如下：</p><script type="math/tex; mode=display">\begin{aligned}\bar{K} &= \mathcal{K}_L(\bar{A}, \bar{B}, \bar{C}) \\\hat{K} &= \hat{\mathcal{K}}_L(\Omega; \bar{A}, \bar{B}, \bar{C}) \\\hat{K}(z) &= \hat{\mathcal{K}}_L(z; \bar{A}, \bar{B}, \bar{C})\end{aligned}</script><p>我们取一组单位根 $\Omega = e^{-2\pi i \frac{k}{L}}, k\in[L]$，可得：</p><script type="math/tex; mode=display">\hat{K}_j = \sum_{k=0}^{L-1}\bar{K}_k e^{-2\pi i \frac{jk}{L}}</script><p>上式实际上是对卷积核进行离散傅里叶变换（DFT）: $\hat{}K = \mathcal{F}_L{K}$，下面我们推导 $\hat{K}$ 的计算。</p><p>展开截断SSM生成函数：</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{K}_L(z; \bar{A}, \bar{B}, \bar{C}) &= \bar{C}^{\ast}\bar{B} + \bar{C}^{\ast}\bar{A}\bar{B}z + ... + \bar{C}^{\ast}\bar{A}^{L-1}\bar{B}z^{L-1} \\&= \bar{C}W^{\ast}(I-\bar{A}^L)(I-\bar{A}z)^{-1}\bar{B} \\ &= \tilde{C}^{\ast}(I-\bar{A}z)^{-1}\bar{B} \\\end{aligned}</script><p>其中 $\tilde{C}^{\ast} = C^{\ast}(I-\bar{A}^L)$，由于 $C$ 可学习，实践中可以直接将 $\tilde{C}^{\ast}$ 设为可学习向量。将上式展开到可以得到：</p><script type="math/tex; mode=display">\begin{aligned}C^{\ast}(I-\bar{A}z)^{-1}\bar{B} &= C^{\ast}[(I-\frac{\Delta}{2}A)^{-1}(I-\frac{\Delta}{2}A) - (I-\frac{\Delta}{2}A)^{-1}(I+\frac{\Delta}{2}A)z]^{-1}\bar{B} \\&= C^{\ast}[(I-\frac{\Delta}{2}A) - (I + \frac{\Delta}{2}A)z]^{-1}(I-\frac{\Delta}{2}A)\bar{B} \\&= C^{\ast}[I(1-z) - \frac{\Delta}{2}A(1+z)]^{-1} \Delta B \\&= \frac{\Delta}{1-z}C^{\ast} [I - \frac{\Delta A}{2 \frac{1-z}{1+z}}]^{-1}B \\&= \frac{2\Delta}{1+z}C^{\ast}[2\frac{1-z}{1+z}I - \Delta A]^{-1}B \\\end{aligned}</script><p>即：</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{K}_L(z; \bar{A}, \bar{B}, \bar{C}) &= \frac{2}{1+z} \tilde{C}^{\ast}(\frac{2}{\Delta}\frac{1-z}{1+z}-A)^{-1}B \\&= \frac{2}{1+z}\tilde{C}^{\ast}(\frac{2}{\Delta}\frac{1-z}{1+z} - \Lambda + PQ^{\ast})^{-1}B\end{aligned}</script><p>使用<strong>Woodbury matrix identity</strong>: $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$，我们可以得到：</p><script type="math/tex; mode=display">\mathcal{K}_L(z; \bar{A}, \bar{B}, \bar{C}) = \frac{2}{1+z} [\tilde{C}^{\ast}R(z)B - \tilde{C}^{\ast}R(z)P(1+Q^{\ast}R(z)P)^{-1}Q^{\ast}R(z)B]</script><p>其中 $R(z) = (\frac{2}{\Delta}\frac{1-z}{1+z} - \Lambda)^{-1}$。到这里，截断SSM生成函数的计算可以被最终归结为对 $R(z)$ 及其与其他矩阵的乘法计算，具体来说，我们希望高效地计算 $Q^{\ast}R(\Omega; \Lambda)P$，将 $\frac{2}{\Delta}\frac{1-z}{1+z}$ 视为 $\omega \in \Omega$，我们实际上是要计算 $\sum_j\frac{q_i^{\ast}p_j}{\omega-\lambda_j}$，而这是一个 Cauchy matrix-vector multiplication，已有高效算法。</p><p>具体来说，对于 Cauchy matrix $M$：</p><script type="math/tex; mode=display">M \in \mathbb{C}^{M \times N} = M(\Omega, \Lambda) = (M_{ij})_{i\in [M], j\in [N]}</script><script type="math/tex; mode=display">M_{ij} = \frac{1}{\omega_i - \lambda_j}</script><p>Cauchy matrix-vector product的计算复杂度为：</p><script type="math/tex; mode=display">\mathcal{C}(M,N) = \left\{\begin{matrix}O(MN) & \text{naively} \\O((M+N)\log^2(M+N)) & \text{in exact arithmetic}\\O((M+N)\log(M+N)\log(\frac{1}{\epsilon})) & \text{numerically to precision} \,\,  \epsilon\end{matrix}\right. \\</script><p>因此CNN view 计算复杂度为 $O((L+N)\log(L+N)\log \frac{1}{\epsilon})$，可以记为次线性形式：$\tilde{O}(L+N)$</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>组会内部分享报告 《A Gentle Introduction to HiPPO🦛 and its Friends》</p><p><a href="https://arxiv.org/pdf/2111.00396" title="S4原文">Efficiently Modeling Long Sequences with Structured State Spaces</a></p>]]></content>
      
      
      <categories>
          
          <category> Model Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mamba </tag>
            
            <tag> Model Structure </tag>
            
            <tag> HiPPO </tag>
            
            <tag> S4 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Part I of Mathematical Structure of Mamba - Hippo</title>
      <link href="/posts/10038.html"/>
      <url>/posts/10038.html</url>
      
        <content type="html"><![CDATA[<div class="note success flat"><p>本篇是mamba系列blog的第一篇文章</p><ul><li><p>Part I of Mathematical Structure of Mamba - Hippo</p></li><li><p><a href="https://anti-entrophic.github.io/posts/10039.html" title="Part II of Mathematical Structure of Mamba - S4">Part II of Mathematical Structure of Mamba - S4</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10040.html" title="Part III of Mathematical Structure of Mamba - S4D">Part III of Mathematical Structure of Mamba - S4D</a></p></li><li><p><a href="https://anti-entrophic.github.io/posts/10043.html" title="Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2">Part IV of Mathematical Structure of Mamba - Mamba&amp;Mamba2</a></p></li></ul><p>剩余预计还有一篇文章正在生产中~</p></div><h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>考虑一个很长的一维序列，当我们希望模型具有“记忆”能力的时候，我们实际上期望模型能在当前时间步对很久以前的时间步上的数据点具有无损恢复的能力。然而，模型的大小是不可能随序列长度增长的，也就是说我们需要使用有限的参数恢复出无限多时间步的数据点。</p><p>很显然无损恢复是不可能的。但是，我们可以用一种具有渐进收敛性的方法，尽可能减少这种损失。我们面临的第一个问题就是，怎样描述这个损失？一个非常自然的想法是直接把我们恢复出来的数据点和真实的数据点的距离求 $L_2$ 范数。Naive的 $L_2$ 范数假设了所有历史数据点是同等重要的。</p><p>到这里，我们起码有了一种最简单的求损失的方法。如果我们把所有真实数据点看作对时间步的函数，那么我们上面求损失的过程正是<strong>函数逼近</strong>的过程，即我们不知道真实函数的表达式，但我们获取了它的若干采样数据点，我们可以依赖这些数据点，选取一个已知表达式的函数来逼近它。这个用于逼近的函数包含有限多的待优化的参数，而参数的数量不随序列长度变化。</p><p><strong>记忆问题转化为了函数逼近问题</strong></p><h1 id="数学框架"><a href="#数学框架" class="headerlink" title="数学框架"></a>数学框架</h1><p>考虑定义在 $t&gt;0$ 上的一维连续函数 $f(t)\in \mathbb{R}$，则 $t$ 时刻之前的<strong>历史</strong>可以表述为 </p><script type="math/tex; mode=display">f_{\leq t} := f(x)|_{x \leq t}</script><p>对于每个 $t$ 时刻，我们希望找到一个已知表达式的函数 $g^{(t)}\in \text{span\{}\mathcal{G}\}$ 来逼近历史 $f_{\leq t}$，其中 $\mathcal{G}$ 是我们所有可选择函数构成的函数族。</p><p>在给定概率测度 $M^{(t)}$ ，对应概率密度 $\mu$ 满足 $\int_{-\infty}^{t}\mu^{(t)}(x)\text{d}x = 1$ 的情况下，两个函数的内积可以表示为：</p><script type="math/tex; mode=display">\langle f,g \rangle_{\mu^{(t)}} = \int_0^{\infty} f(x)g(x)\mu^{(t)}(x)\text{d}x</script><p>同时，带概率测度的 $L_2$ 范数变为 </p><script type="math/tex; mode=display">||f||_{L_2(\mu^{(t)})} = \langle f, f \rangle_{\mu_{(t)}}^{\frac{1}{2}} = [\int_0^{\infty} f(x)^2\mu^{(t)}(x)\text{d}x]^{\frac{1}{2}}</script><p>要进行函数逼近，我们首先要选取一组基函数来构建函数族。最常见的选择是使用多项式基，来对概率测度 $M^{(t)}$ 构建一组 <strong>正交多项式</strong> $\mathcal{G}=\{g_n\}_{n&lt;N}$，满足 $\forall i,j \in [N], \langle g_i, g_j \rangle _{\mu^{(t)}}=\int_0^{\infty}g_i(x)g_j(x)\mu^{(t)}(x)\text{d}x=0$，来找到一个 $g^{(t)}=\sum_{k=0}^{N-1}c_k(t)g_k$ 去最小化在测度 $M^{(t)}$ 下与 f(t) 之间的损失，即：</p><script type="math/tex; mode=display">\hat{g}^{(t)}:=\text{argmin}||f_{\leq t}-g^{(t)}||</script><p>对于上式， $f_{\leq t}$ 可以直接<strong>观测</strong>得到，$\mathcal{G}$ 可以通过<strong>构造</strong>得到（勒让德多项式、切比雪夫多项式、雅可比多项式等等），$\mu^{(t)}$可以直接<strong>设定</strong>（例如设定为所有历史同等重要，或只关注此时刻往前固定窗口大小的历史），那么我们唯一要<strong>优化</strong>的就是一组系数 $[c_k(t)]_{k\in[N]} \in \mathbb{R}^{N}$ </p><div class="note success flat"><p>后文中介绍了如何在测度加权的情况下推导出正交多项式</p></div><p>在某一时刻 $t$ 的一组参数 $c_k(t)$ ，我们可以简单通过最小二乘法求得</p><script type="math/tex; mode=display">L = \int(f_{\leq t}(x)- \sum_{k=0}^{N-1}c_k(t)g_k^{(t)}(x))^2\mu^{(t)}(x)\text{d}x</script><p>对 $c_i$ 求导，令导数为0</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial L}{\partial c_k(t)}=-2\int (f_{\leq t}(x)-\sum_{k=0}^{N-1}c_k(t)g_k^{(t)}(x))g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x =0 \\\int f_{\leq t}(x)g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x = \sum_{k=0}^{N-1}c_k(t) \int g_k^{(t)}(x)g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x\end{aligned}</script><p>由于 $\int g_k^{(t)}(x)g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x=1$ 当且仅当 $k=i$，所以</p><script type="math/tex; mode=display">\int f_{\leq t}(x)g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x = c_i(t)</script><p>也即 $c_i(t)=\langle f_{\leq t}, g_i^{(t)} \rangle_M = \int f_{\leq t}(x)g_i^{(t)}(x)\mu^{(t)}(x)\text{d}x$</p><p>数学上，我们可以简单计算得到。但考虑时间复杂度，每次计算都需要遍历所有的历史求出 $f_{\leq t}$，$n$ 次操作的总复杂度依然是 $O(n^2)$ ，无法接受。</p><p>可以看到 $c(t)$ 是关于时间 $t$ 的函数，考虑到相比上个时刻 $T-\delta$ 仅有一个<strong>增量</strong>数据点 $f(T)$，自然考虑 $c(t)$ 的求解是否存在<strong>递推</strong>形式，也即关注 $c(t-\delta)$，$c(t)$，$f_{\leq t}$ 三者之间的关系。在连续情况下当 $\delta \rightarrow 0$ 时，我们关心的是 $\frac{d}{dt}c(t)$，$c(t)$，$f_{\leq t}$ 三者之间的关系，也就是求解一个关于 $c(t)$ 的<strong>常微分方程(ODE)</strong>：</p><script type="math/tex; mode=display">\frac{d}{dt}c(t)=u(t, c(t), f_{\leq t})</script><h1 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h1><p>根据前面的数学框架，我们需要找到一组正交多项式 $\{g_n\}_{n&lt;N}$ 和测度 $M^{(t)}$，并求解常微分方程 $\frac{d}{dt}c(t)=u(t, c(t), f_{\leq t})$。选取不同的多项式和测度，我们会得到不同的ODE方程和解，此处仅介绍 HiPPO 框架中最成功的一种变体：HiPPO-LegS（Scaled Legendre，LegS），它使用勒让德多项式作为正交多项式，并选取均匀重要性的测度。</p><h2 id="概率测度"><a href="#概率测度" class="headerlink" title="概率测度"></a>概率测度</h2><center><img src="https://i.072333.xyz/file/AgACAgEAAyEGAASMaMWHAAJHDWff7yd7GUNqtkIh5zqyg-DCBX3SAAICsjEbTk4BRyA4qfV_1b8oAQADAgADdwADNgQ.png" width="1000px" /><p style="font-size: 10px;">HiPPO论文中提出的三种概率测度，从左往右分别为：LegT（将滑动窗口内的历史视为同等重要）、LagT（历史的重要性指数衰减）、LegS（将所有历史视为同等重要）</p></center><p><br></p><p>在某个时刻 $t$，将此前的所有历史视为同等重要，我们得到HiPPO-LegS的测度：</p><script type="math/tex; mode=display">\mu^{(t)}(x)=\frac{1_{[0,t]}}{t}</script><h2 id="正交多项式"><a href="#正交多项式" class="headerlink" title="正交多项式"></a>正交多项式</h2><p>为了获得正交多项式，一般的做法是对一组函数进行Gram-Schmidt正交化。当我们对 $1, x, x^2, \cdots$ 进行正交化后，得到的就是勒让德多项式：$P_0(x), P_1(x), P_2(x), \cdots$。</p><p>标准勒让德多项式有一个性质，我们不加证明地给出：在区间 $[-1,1]$ 上，两个多项式 $P_n, P_m$ 具有以下关系：</p><script type="math/tex; mode=display">\frac{2n+1}{2}\int_{-1}^{1}P_n(x)P_m(x)\text{d}x=\delta_{nm}</script><p>$\delta_{nm}$ 表示当 $n \neq m$ 时等于 0，因为正交嘛；当 $n=m$ 时等于1</p><p>由于该性质定义在区间 $[-1,1]$ 上，我们进行变量代换 $x=\frac{2x’}{t}-1$ 放缩到我们关心的 $[0,t]$ 区间，代换后的公式为：</p><script type="math/tex; mode=display">(2n+1)\int_0^tP_n(\frac{2x}{t}-1)P_m(\frac{2x}{t}-1)\frac{1}{t}\text{d}x=\delta_{nm}</script><p>两个多项式在区间 $[0,t]$ 上积分等价于在给定测度 $\mu^{(t)}(x)=\frac{1_{[0,t]}}{t}$ 下在整个数轴上的积分，上式写为：</p><script type="math/tex; mode=display">(2n+1)\int P_n(\frac{2x}{t}-1)P_m(\frac{2x}{t}-1)\frac{1_{[0,t]}}{t}\text{d}x=\delta_{nm}</script><p>我们仅考虑 $n = m$ 的情况：</p><script type="math/tex; mode=display">\int((2n+1)^{\frac{1}{2}}P_n(\frac{2x}{t}-1))^2\mu^{(t)}(x)\text{d}x=1</script><p>令 $g_n^{(t)}(x)=(2n+1)^{\frac{1}{2}}P_n(\frac{2x}{t}-1)$，我们有：</p><script type="math/tex; mode=display">\int(g_n^{(t)}(x))^2\mu^{(t)}(x)\text{d}x = \langle g_n^{(t)}(x), g_n^{(t)}(x) \rangle_{\mu^{(t)}}=1</script><p>所以，在测度 $M^{(t)}$ 下归一化的勒让德正交多项式为：</p><script type="math/tex; mode=display">\{g_n^{(t)}(x)\}_{n<N}=\{(2n+1)^{\frac{1}{2}}P_n(\frac{2x}{t}-1)\}_{n<N}</script><div class="note warning flat"><p>怎么证明当 $n \neq m$ 时有 $\int g_n^{(t)}(x) g_m^{(t)}(x) \mu^{(t)}(x) \text{d}x = 0$ ？</p></div><h2 id="常微分方程"><a href="#常微分方程" class="headerlink" title="常微分方程"></a>常微分方程</h2><p>要计算 $\frac{d}{dt}c(t)$， 我们需要对 $c(t) \in \mathbb{R}^N$ 的每一维 $c_n(t)$ 求导。根据 $c_n(t):=\langle f_{\leq t}, g_n^{(t)} \rangle_{\mu^{(t)}}$，同时我们希望避免对 $f_{\leq t}$ 进行计算，那么可以借助计算 $\frac{d}{dt}g_n^{(t)}$ 和 $\frac{d}{dt}\mu^{(t)}$ 得到（看了后面推导就知道为什么了）。</p><p>在此前的推导中，我们将 $t$ 视为一个固定的时刻而非变量，因此 $t$ 作为上标出现。而在接下来的ODE推导中，时间 $t$ 也是变量，因此下面的记号改为类似 $g(t, x)$，$\mu(t,x)$ 的形式。</p><div class="note warning flat"><p>$f_{\leq t}$ 是一个已经确定的函数，代表的是我们看到的采样点背后的真实逻辑，并不是 $t$ 的函数。</p><p>可以理解为，$f_{\leq t}$ 是通过 $f(1), …, f(t)$ 拟合出来的一个函数，求出这个函数的复杂度是 $O(t)$</p></div><p>补充一下勒让德多项式的递推关系式 $(2n+1)P_n=P_{n+1}’-P_{n-1}’$，以及推论 $(x+1)P_n’(x)=nP_n(x) + (2n-1)P_{n-1}(x) + (2n-3)P_{n-2}(x) + \cdots$，下面是勒让德多项式的表，可以自己验证一下。</p><center><img src="https://i.072333.xyz/file/AgACAgEAAyEGAASMaMWHAAJHJ2fgAnJTyuYYaqKiJHPqYNGyYqIcAAIcsjEbTk4BR5yYeSYijuKkAQADAgADeQADNgQ.png" width="600px" /><p style="font-size: 10px;"> 标准勒让德多项式 </p></center><p><br></p><p>对于 $\frac{\partial}{\partial t}\mu(t,x)$，我们有：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial}{\partial t}\mu(t,x) &= \frac{\partial}{\partial t}(\frac{1_{[0,t]}}{t}) \\&= -t^{-2} 1_{[0,t]} + t^{-1}\delta_t \\&= t^{-1}(-\mu(t,x)+\delta_t) \end{aligned}</script><p>对于 $\frac{\partial}{\partial t}g_n(t,x)$，我们有：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial}{\partial t}g_n(t,x) &= \frac{\partial}{\partial t}((2n+1)^{\frac{1}{2}}P_n(\frac{2x}{t}-1)) \\&=-(2n+1)^{\frac{1}{2}}2xt^{-2}P_n'(\frac{2x}{t}-1) \\&=-(2n+1)^{\frac{1}{2}}t^{-1}(\frac{2x}{t}-1+1)P_n'(\frac{2x}{t}-1)\end{aligned}</script><p>进行变量代换 $z=\frac{2x}{t}-1$ 简化公式，并使用勒让德多项式的推论可以得到：</p><script type="math/tex; mode=display">\begin{aligned}\frac{\partial}{\partial t}g_n(t,x) &= -(2n+1)^{\frac{1}{2}}t^{-1}(z+1)P_n'(z) \\&= -(2n+1)^{\frac{1}{2}}t^{-1}[nP_n(z)+(2n-1)P_{n-1}(z)+(2n-3)P_{n-2}(z)+\cdots] \\&= -t^{-1}(2n+1)^{\frac{1}{2}}[n(2n+1)^{-\frac{1}{2}}g_n(t,x)+(2n-1)^{\frac{1}{2}}g_{n-1}(t,x)+(2n-3)^{\frac{1}{2}}g_{n-2}(t,x)+\cdots]\end{aligned}</script><p>然后，我们可以来计算 $\frac{d}{dt}c_n(t)$</p><script type="math/tex; mode=display">\begin{aligned}\frac{d}{dt}c_n(t) &= \frac{\partial}{\partial t}(\int f(x)g_n(t,x)\mu(t,x)\text{d}x) \\&= \int f(x) (\frac{\partial}{\partial t}g_n(t,x))\mu(t,x)\text{d}x + \int f(x)g_n(t,x)(\frac{\partial}{\partial t}\mu(t,x))\text{d}x\end{aligned}</script><p>代入 $\frac{\partial}{\partial t}g_n(t,x)$，$\frac{d}{dt}\mu(t,x)$ 的计算结果，可以得到：</p><script type="math/tex; mode=display">\begin{aligned}\frac{d}{dt}c_n(t) &= -t^{-1}(2n+1)^{\frac{1}{2}}[n(2n+1)^{-\frac{1}{2}}c_n(t)+(2n-1)^{\frac{1}{2}}c_{n-1}(t)+(2n-3)^{\frac{1}{2}}c_{n-2}(t)+\cdots]-t^{-1}c_n(t) + t^{-1}f(t)g_n(t,t)\end{aligned}</script><p>其中 $g_n(t,t) = (2n+1)^{\frac{1}{2}}P_n(1)=(2n+1)^{\frac{1}{2}}$，代入得到：</p><script type="math/tex; mode=display">\begin{aligned}\frac{d}{dt}c_n(t) &= -t^{-1}(2n+1)^{\frac{1}{2}}[(n+1)(2n+1)^{-\frac{1}{2}}c_n(t)+(2n-1)^{\frac{1}{2}}c_{n-1}(t)+(2n-3)^{\frac{1}{2}}c_{n-2}(t)+\cdots] + t^{-1}(2n+1)^{\frac{1}{2}}f(t)\end{aligned}</script><p>至此，我们完成了推导，并实现了初始目标，将 $\frac{d}{dt}c(t)$ 表示为了 $c(t)$ 与 $f_{\leq t}$ 的函数，且不依赖对观测函数 $f_{\leq t}$ 的积分，避免了对所有历史的计算。有了 $\frac{d}{dt}c_n(t)$ 的表达式，我们可以将向量 $c(t)$ 表示为矩阵计算形式：</p><script type="math/tex; mode=display">\frac{d}{dt}c(t) = -\frac{1}{t}Ac(t) + \frac{1}{t}Bf(t)</script><script type="math/tex; mode=display">A_{nk} = \left\{\begin{matrix}(2n+1)^{\frac{1}{2}}(2k+1)^{\frac{1}{2}} & \text{if} \quad n>k \\n+1 & \text{if} \quad n=k \\0 & \text{if} \quad n<k\end{matrix}\right. \\</script><script type="math/tex; mode=display">B_n = (2n+1)^{\frac{1}{2}}</script><p>这里的矩阵 $A$ 就是大名鼎鼎的<strong>HiPPO Matrix</strong>，S4（<strong>S</strong>tructured <strong>S</strong>tate <strong>S</strong>pace<strong>S</strong>）中“结构化”指的就是用结构化的矩阵 $A$ 来对 SSM 的参数初始化</p><h3 id="HiPPO矩阵初始化代码"><a href="#HiPPO矩阵初始化代码" class="headerlink" title="HiPPO矩阵初始化代码"></a>HiPPO矩阵初始化代码</h3><p>补充一下HiPPO矩阵初始化的代码，HiPPO矩阵是一个 $N \times N$ 维的下三角矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_HiPPO</span>(<span class="params">N</span>):</span><br><span class="line">    P = np.sqrt(<span class="number">1</span> + <span class="number">2</span> * np.arange(N))</span><br><span class="line">    A = P[:, np.newaxis] * P[np.newaxis, :]</span><br><span class="line">    A = np.tril(A) - np.diag(np.arange(N))</span><br><span class="line">    <span class="keyword">return</span> -A</span><br></pre></td></tr></table></figure><p>返回 $-A$ 是为了和后续的SSM状态方程对齐，把负号放到参数内部。</p><h2 id="HiPPO-离散化"><a href="#HiPPO-离散化" class="headerlink" title="HiPPO 离散化"></a>HiPPO 离散化</h2><p>以上推导都是在假设 $f(t)$ 是关于 $t$ 的连续函数的情况下进行的。通过离散化，我们可以获得针对序列数据的离散ODE。连续函数离散化的方法有很多，例如前向欧拉、后向欧拉、双线性等等。在这里我们介绍形式相对简洁的前向欧拉方法以及离散化后的HiPPO-LegS，需要注意的是在HiPPO论文的实验以及S4中使用的都是双线性离散化方法，因为具有更好的数值稳定性，而mamba则是采用的零阶保持（zero-order hold, ZOH）方法。</p><p>已知 $\frac{d}{dt}c(t) = -\frac{1}{t}Ac(t) + \frac{1}{t}Bf(t)$ ，对于前向欧拉，假设采样间隔为 $\Delta t$，我们从时刻 $t$ 向前走一小步得到 $t+\Delta t$，对这一小段在等式两边积分得到：</p><script type="math/tex; mode=display">c(t+\Delta t)-c(t)=\int_t^{t+\Delta t} (-\frac{1}{s}Ac(s)+\frac{1}{s}Bf(s))\text{d}s</script><p>对于等式右边我们将 $[t,t+\Delta t]$ 内 $\frac{d}{dt}c(t)$ 的值都保持为 $t$ 时刻的值来近似，有：</p><script type="math/tex; mode=display">c(t+\Delta t)-c(t)=\Delta t (-\frac{1}{t}Ac(t)+\frac{1}{t}Bf(t))</script><p>移项得到：</p><script type="math/tex; mode=display">c(t+\Delta t)=(1-\frac{\Delta t}{t}A)c(t)+\frac{\Delta t}{t}Bf(t)</script><p>将 $t_k$, $t_k+\Delta t$ 时刻分别当成离散的 $k$，$k+1$ 时间步，即 $t_k=k \cdot \Delta t$，我们得到前向欧拉离散化的HiPPO-LegS：</p><script type="math/tex; mode=display">c_{k+1}=(1-\frac{A}{k})c_k+\frac{B}{k}f_k</script><p>双线性离散化就是 $c(t+\Delta t)-c(t)=\frac{\Delta t }{2}(\frac{dc(t)}{dt}+ \frac{dc(t+\Delta t)}{dt})$</p><p>在S4D部分会介绍零阶保持方法。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>组会内部分享报告 《A Gentle Introduction to HiPPO🦛 and its Friends》</p>]]></content>
      
      
      <categories>
          
          <category> Model Structure </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mamba </tag>
            
            <tag> Model Structure </tag>
            
            <tag> HiPPO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Policy Gradient</title>
      <link href="/posts/10026.html"/>
      <url>/posts/10026.html</url>
      
        <content type="html"><![CDATA[<p>我去怎么不能渲染公式了。。。看看怎么解决。。。</p><p>从简单的公式推导介绍大致思想，然后从代码角度介绍具体实践。</p><h1 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h1><p>对于当前的状态 $s$，我们需要采取一个行动 $a$，假设我们行动的策略由参数 $\theta$ 决定，那我们采取行动 $a$ 的概率为 $\pi_{\theta}(a|s) = P(a|s,\theta)$</p><p>目标是求得能最大化奖励函数 $J(\theta)$ 的参数 $\theta$，即求</p><script type="math/tex; mode=display">\mathop{\arg\max}\limits_{\theta}J(\theta) = \mathop{\arg\max}\limits_{\theta}\mathbb{E}_{\tau \sim \pi_{\theta}}R(\tau)=\mathop{\arg\max}\limits_{\theta}\sum_{\tau}P(\tau;\theta)R(\tau)</script><p>我们把 $J(\theta)$ 看成是轨迹 $\tau$ 的期望奖励。每条轨迹的概率可以展开表示为：</p><script type="math/tex; mode=display">P(\tau|\theta) = \prod_{t=0}^T P(s_{t+1}|s_t, a_t) \, \cdot \, \pi_{\theta}(a_t | s_t)</script><p>为了求得 $\theta$ , 我们对 $\theta$ 求导，推导如下：</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}J(\theta) &= \sum_{\tau}\nabla_{\theta}P(\tau;\theta)R(\theta) \\&= \sum_{\tau} P(\tau;\theta) \frac{\nabla_{\theta}P(\tau;\theta)}{P(\tau;\theta)} R(\tau) \\&= \sum_{\tau} P(\tau;\theta) \nabla_{\theta}\text{log}P(\tau;\theta)R(\tau) \\&= \mathbb{E}_{\tau \sim \pi_{\theta}} \nabla_{\theta}\text{log}P(\tau;\theta)R(\tau)\end{aligned}</script><p>这里有一步巧妙的变换，将 $\nabla_{\theta}P(\tau;\theta)$ 变成了 $P(\tau;\theta) \nabla_{\theta}\text{log}P(\tau;\theta)$，log形式允许我们将连乘展开进行进一步推导。</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}\text{log}P(\tau;\theta) &= \nabla_{\theta}\sum_{t=0}^T\text{log}P(s_{t+1}|s_t, a_t) + \nabla_{\theta}\sum_{t=0}^T\text{log}\pi_{\theta}(a_t|s_t) \\&= \nabla_{\theta}\sum_{t=0}^T\text{log}\pi_{\theta}(a_t|s_t)\end{aligned}</script><p>将数据带回，我们可以得到奖励函数的最终形式</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}J(\theta) &= \mathbb{E}_{\tau \sim \pi_{\theta}} [\nabla_{\theta}\sum_{t=0}^T\text{log}\pi_{\theta}(a_t|s_t)R(\tau)] \\&= \mathbb{E}_{\tau \sim \pi_{\theta}} [\sum_{t=0}^T\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)R(\tau)]\end{aligned}</script><p>最后，对于最外层的期望，我们用多次采样模拟。假设采了 $m$ 次</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}J(\theta) &\approx \frac{1}{m}\sum_{i=1}^mR(\tau^{(i)})[\sum_{t^{(i)}=0}^{T^{(i)}} \nabla_{\theta}\text{log}\pi_{\theta}(a_{t^{(i)}}|s_{t^{(i)}})]\end{aligned}</script><p>但是采样非常昂贵，所以实际上我们可能只用Monte Carlo采样一次。甚至采样出来的样本还要被多次使用。</p><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>对于之前推导的结果，我们可以简单的积分回去:</p><script type="math/tex; mode=display">\nabla_{\theta}J(\theta) = \mathbb{E}_{\tau \sim \pi_{\theta}} [\sum_{t=0}^T\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)A(s_t, a_t)]</script><script type="math/tex; mode=display">J(\theta) = \mathbb{E}_{\tau \sim \pi_{\theta}} [\sum_{t=0}^T\text{log}\pi_{\theta}(a_t|s_t)A(s_t, a_t)]</script><p>常用的梯度下降用的是Loss，而这里是reward，所以给reward取个负号就是loss了。</p><blockquote><p>上式比较具体，讨论公式时也常用简单版：$J(\theta)=\mathbb{E}_{\tau \sim \pi_{\theta}}\text{log}P(\tau;\theta)R(\tau)$</p><p>对于LLM而言，$\pi_{\theta}(a_t|s_t)$ 就等于 $P(t_i|t_{&lt;i},\theta)$</p><p>还有一点就是，不要迷信Loss的绝对值大小，因为理论上你可以给Loss加上一个任意常数 $c$ 而不影响它的梯度。只需要关注合理的部分的loss即可。</p></blockquote><h1 id="Advantage-amp-Reward"><a href="#Advantage-amp-Reward" class="headerlink" title="Advantage &amp; Reward"></a>Advantage &amp; Reward</h1><p>比起整条轨迹 $\tau$ 获得一个稀疏的奖励 $R(\tau)$，采用优势函数 $A(s,a)$ 是更被广泛采用的算法，定义如下：</p><script type="math/tex; mode=display">A(s,a)=Q(s,a) - V(s)</script><p>其中，$Q(s,a)$ 是状态动作值函数，表示在当前状态 $s$ 下采取动作 $a$ 的期望奖励；$V(s)$ 是状态值函数，表示当前状态 $s$ 后续的平均收益</p><p>现在采用最多的策略是广义优势估计（Generalized Advantage Estimation）。</p><p>P.S. GRPO又回到了使用稀疏奖励</p><h2 id="Baseline-Adjust"><a href="#Baseline-Adjust" class="headerlink" title="Baseline Adjust"></a>Baseline Adjust</h2><p>先来严谨理解一下优势函数的选择</p><p>直接使用回报 $Q$ 可能导致方差过大，可以证明减去一个基线 $V(s_t)$，即在 $s_t$ 状态下的平均收益，可以保证梯度无偏而方差减小。</p><script type="math/tex; mode=display">\mathbb{E}_{\tau}[\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)\cdot V(s_t)] = \mathbb{E}_{s_t}[\mathbb{E}_{a_t \sim \pi_{\theta}(\cdot|s_t)}[\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)\cdot V(s_t)| s_t]]</script><p>视 $s_t$ 为不变数，则</p><script type="math/tex; mode=display">\mathbb{E}_{a_t \sim \pi_{\theta}(\cdot|s_t)}[\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)\cdot V(s_t)| s_t] = V(s_t) \cdot \mathbb{E}_{a_t}[\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)|s_t]</script><p>仅看第二项，有</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{a_t\sim \pi_{\theta}}[\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)|s_t] &= \int \pi_{\theta}(a_t|s_t)\cdot \frac{\nabla_{\theta}\pi_{\theta}(a_t|s_t)}{\pi_{\theta}(a_t|s_t)} da_t \\&= \nabla_{\theta} \int \pi_{\theta}(a_t|s_t)da_t \\&= \nabla_{\theta}1 \\&= 0\end{aligned}</script><p>所以是无偏的。条件是，value function与 $a_t$ 无关，才可以在第二步做一个分离。</p><p>$V(s_t)$ 取作 $\mathbb{E}_{a_t}[Q(s_t, a_t)]$ 是一个比较自然的想法，因此回报又被称为优势函数 $A(s_t, a_t) = Q(s_t, a_t) - V(s_t)$。或者还有像GAE中采用TD error</p><h2 id="Generalized-Advantage-Estimation"><a href="#Generalized-Advantage-Estimation" class="headerlink" title="Generalized Advantage Estimation"></a>Generalized Advantage Estimation</h2><h3 id="状态值函数-V-s"><a href="#状态值函数-V-s" class="headerlink" title="状态值函数 $V(s)$"></a>状态值函数 $V(s)$</h3><p>对于每条 $\tau$，我们可以应用 critic model 给出一个 value，在LLM里就是对rollout出来的数据再forward一次得到的logits。</p><h3 id="状态动作值函数-Q-s-a"><a href="#状态动作值函数-Q-s-a" class="headerlink" title="状态动作值函数 $Q(s,a)$"></a>状态动作值函数 $Q(s,a)$</h3><p>状态动作值的取值为 $r_t+\gamma \cdot V(s_{t+1})$</p><p>直观理解就是，动作 $a_t$ 对是否拿到reward $r_t$ 有贡献，同时我们还期望下一步的value要尽量大。</p><p>由于 $V$ 是我们用 critic model 打分得到的logits，这里的 $V(s_{t+1})$ 实际上已经隐含了上一步取了 $a_t$ 的条件，甚至可以说在LLM里 $s_{t+1}$ 就是 $a_t$，因此 $Q$ 确实可以看作是 $s$ 与 $a$ 的函数。</p><h3 id="广义优势估计-GAE"><a href="#广义优势估计-GAE" class="headerlink" title="广义优势估计 GAE"></a>广义优势估计 GAE</h3><p>令 $\delta_t=r_t+\gamma \cdot V(s_{t+1}) - V(s_t)$，这一项被称为TD误差</p><p>然后，$A_t^\text{GAE}=\delta_t+\gamma\lambda\cdot A_{t+1}^\text{GAE}$</p><p>最后计算得到的奖励记为 $R_t=A_t+V(s_t)$</p><ul><li><p>$\lambda$ 的作用是控制优势估计的步数。当 $\lambda=0$ 时，退化为仅用当前一步的 advantage；当 $\lambda=1$ 时，退化为使用无穷步的随步长衰减的 advantage 之和。</p></li><li><p>$\gamma$ 就是随step衰减，被称为 reward-to-go</p></li><li><p>我还有一个很朴素的疑问暂时没有想明白，TD error 为什么只取一步？为什么不能是 $\delta_t = r_t + \gamma \cdot V(s_{t+1}) + \gamma^2 \cdot V(s_{t+2})- V(s_t)$。虽然可能很简单，比如说 $V(s_{t+2})$ 涉及另一次环境交互了，但我还是希望能得到一个数学上的解释。等我理解贝尔曼算子的性质后会再来补充这部分。肯定有一个原因是要保证 $A_t^{\text{GAE}}$ 收敛，不能随着 $n$ 发散</p></li><li><p>并且，在LLM中，我觉得 $\delta_t$ 并不适合代表 $s_t$ 状态下选择动作（token） $a_t$ 的价值，因为 critic model 的 token level 的 value 方差太大，$V(s_{t+1})$ 并不能准确反映真正的价值。我举个例子，”I love eat appl”，那下一个词说 “e” 的概率很高，$V(s_{t+1})$ 非常大，但是这个合适吗？它适合作为基线吗？上面的无偏性证明是在期望的情况下。哪怕PPO batch size开的非常大，也没法估计这个位置取不同 $a_t$ 的期望，因为整条轨迹都不一样，所以必然是有偏的（而且我觉得偏的很大）。</p></li></ul><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>在Verl中这部分逻辑的代码实现为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    lastgaelam = <span class="number">0</span></span><br><span class="line">    advantages_reversed = []</span><br><span class="line">    gen_len = token_level_rewards.shape[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(gen_len)):</span><br><span class="line">        nextvalues = values[:, t + <span class="number">1</span>] <span class="keyword">if</span> t &lt; gen_len - <span class="number">1</span> <span class="keyword">else</span> <span class="number">0.0</span></span><br><span class="line">        delta = token_level_rewards[:, t] + gamma * nextvalues - values[:, t]</span><br><span class="line">        lastgaelam = delta + gamma * lam * lastgaelam</span><br><span class="line">        advantages_reversed.append(lastgaelam)</span><br><span class="line">    advantages = torch.stack(advantages_reversed[::-<span class="number">1</span>], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    returns = advantages + values</span><br><span class="line">    advantages = verl_F.masked_whiten(advantages, eos_mask)</span><br><span class="line"><span class="keyword">return</span> advantages, returns</span><br></pre></td></tr></table></figure><p>显然，我们可以倒序计算来处理TD error的后向依赖关系。</p><h1 id="KL-Loss-Constraint"><a href="#KL-Loss-Constraint" class="headerlink" title="KL Loss Constraint"></a>KL Loss Constraint</h1><p>简单的使用 $\Delta\theta = \alpha\nabla_{\theta}J(\theta)$，模型可能会崩掉，需要增加限制。对于语言模型而言，这个限制就是输出的KL散度。</p><script type="math/tex; mode=display">\mathcal{D}_{KL}(\pi_{\theta}||\pi_{\theta+\Delta\theta}) = \int_{x} \pi_{\theta}(x)\text{log}\frac{\pi_{\theta}(x)}{\pi_{\theta+\Delta\theta}(x)}dx</script><blockquote><p>特别注意，KL散度是非对称的，需要分析一下。我们假设分布 $P$ 是已知的，$Q$ 是待优化的 \<br>1°) 正向KL散度：$\mathcal{D}_{KL}(P||Q) = \int_{x} P(x)\text{log}\frac{P(x)}{Q(x)}dx$ \<br>当 $P(x)$ 偏大时，KL散度会比较大，所以会更关注在 $P(x)$ 较大的地方，$Q(x)$也要尽量大，这样才能让KL散度偏小。因此，分布会尽可能覆盖所有的概率峰。\<br>2°) 反向KL散度：$\mathcal{D}_{KL}(Q||P) = \int_{x} Q(x)\text{log}\frac{Q(x)}{P(x)}dx$ \<br>这时恰好相反，当 $P(x)$ 偏小的时候，KL散度会非常大，所以会更关注在 $P(x)$ 较小的地方，$Q(x)$ 一定要很小，这会导致最后的分布集中在单个峰上，避免跨越峰之间的低概率区域。\<br>总结一下，正向KL散度能比较均衡地贴合原始分布。而反向KL散度比较极端，会坍缩到少数合理分布。\<br>参考：<a href="https://blog.csdn.net/mch2869253130/article/details/108998463">https://blog.csdn.net/mch2869253130/article/details/108998463</a></p></blockquote><p>所以，我们要选择一个能最大化 $J(\theta)$ 的变分 $\Delta\theta$，同时又要保证输出分布不要漂移太多，写成数学形式是：</p><script type="math/tex; mode=display">\Delta\theta^* = \mathop{\arg\max}\limits_{\mathcal{D}_{KL}(\pi_{\theta}||\pi_{\theta+\Delta\theta}) \leq \epsilon}J(\theta+\Delta\theta)</script><p>利用凸优化理论中的拉格朗日松弛（虽然我已经忘了，依稀记得还有什么KKT条件），可以将约束加入优化目标中作为惩罚项</p><script type="math/tex; mode=display">\Delta\theta^* = \mathop{\arg\max}\limits_{\Delta\theta}J(\theta+\Delta\theta)-\lambda (\mathcal{D}_{KL}(\pi_{\theta} || \pi_{\theta+\Delta\theta})-\epsilon)</script><p>$\lambda\epsilon$ 这一项可以忽略，它不影响梯度的方向只影响梯度的大小，等价于调节学习率的大小，因为 $\alpha \Delta \theta^{\ast} = \alpha’ (\Delta \theta^{\ast} - \lambda \epsilon )$</p><h1 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h1><p>假设我们想估计 $f(x)$ 的期望，$x\sim p(x)$，则 $E_{x\sim p}[f(x)] \approx \frac{1}{N}\sum_{i=1}^Nf(x^i)$</p><p>但是如果 $p(x)$ 不可采样，我们可以用另一个可采样的分布 $q(x)$ 来近似采样。</p><script type="math/tex; mode=display">E_{x\sim p}[f(x)] = \int f(x)p(x)dx=\int f(x)\frac{p(x)}{q(x)}q(x)dx = E_{x \sim q} [f(x) \frac{p(x)}{q(x)}]</script><p>其中 $\frac{p(x)}{q(x)}$ 被称为 importance weight</p><p>虽然期望 $E_{x\sim p}[f(x)]=E_{x\sim q}[f(x)\frac{p(x)}{q(x)}]$ 构成了一个无偏估计，但是考虑对应的方差：</p><script type="math/tex; mode=display">\text{Var}_{x\sim p}[f(x)]=E_{x\sim p}[f(x)^2]-(E_{x\sim p}[f(x)])^2</script><script type="math/tex; mode=display">\begin{aligned}\text{Var}_{x\sim q}[f(x)\frac{p(x)}{q(x)}] &= E_{x\sim q}[(f(x)\frac{p(x)}{q(x)})^2]-(E_{x\sim q}[f(x)\frac{p(x)}{q(x)}])^2 \\&= E_{x\sim p}[f(x)^2\frac{p(x)}{q(x)}]-(E_{x\sim q}[f(x)])^2\end{aligned}</script><p>可以发现，当 $q(x)$ 和 $p(x)$ 相差很大的时候，重要性权重 $\frac{p(x)}{q(x)}$ 就会偏离1，进而导致方差差异变大。因此，重要性采样在采样不充分的时候会逐渐失真。</p><p>之前也说过，采样很昂贵。一条数据采出来可能被训练多次。那在训过一次之后，这条数据就不能看作是由当前的分布 $\pi_{\theta}$ 采出来的了，而是过去的分布 $\pi_{\theta’}$ 采样的结果。</p><p>有了重要性采样，我们可以先off-policy地用 $\pi_{\theta’}$ 采样很多样本，然后再进行训练：</p><script type="math/tex; mode=display">\begin{aligned}J(\theta) &=\mathbb{E}_{\tau \sim \pi_{\theta}}[\text{log}P(\tau;\theta)R(\tau)] \\&=\mathbb{E}_{\tau \sim \pi_{\theta'}}[\frac{\pi_{\theta}}{\pi_{\theta'}}\text{log}P(\tau;\theta)R(\tau)]\end{aligned}</script><p>你可能会想问 $\frac{\pi_{\theta}}{\pi_{\theta’}}$ 怎么算，让我们展开来理解一下具体的意思。</p><script type="math/tex; mode=display">\begin{aligned}J(\theta) &= \mathbb{E}_{\tau \sim \pi_{\theta}} [\sum_{t=0}^T\text{log}\pi_{\theta}(a_t|s_t)A(s_t, a_t)] \\&= \mathbb{E}_{\tau \sim \pi_{\theta'}} [\sum_{t=0}^T\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}\text{log}\pi_{\theta}(a_t|s_t)A(s_t, a_t)]\end{aligned}</script><p>这样就清楚多了，这两个值显然都是可求的。再进一步，我们回到梯度形式</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta}J(\theta) &= \mathbb{E}_{\tau \sim \pi_{\theta'}} [\sum_{t=0}^T\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}\nabla_{\theta}\text{log}\pi_{\theta}(a_t|s_t)A(s_t, a_t)] \\&= \mathbb{E}_{\tau \sim \pi_{\theta'}} [\sum_{t=0}^T\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}\frac{\nabla_{\theta}\pi_{\theta}(a_t|s_t)}{\pi_{\theta}(a_t|s_t)}A(s_t, a_t)] \\&= \mathbb{E}_{\tau \sim \pi_{\theta'}} [\sum_{t=0}^T\frac{\nabla_{\theta}\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}A(s_t, a_t)] \\J(\theta) &= \mathbb{E}_{\tau \sim \pi_{\theta'}} [\sum_{t=0}^T\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}A(s_t, a_t)]\end{aligned}</script><p>太Amazing了。我们可以进一步，把采样分解到每个时间步，得到 </p><script type="math/tex; mode=display">J(\theta) = \mathbb{E}_{(s_t, a_t) \sim \pi_{\theta'}} [\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta'}(a_t|s_t)}A(s_t, a_t)]</script><h1 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h1><p>TODO</p><h2 id="PPO-penalty"><a href="#PPO-penalty" class="headerlink" title="PPO penalty"></a>PPO penalty</h2><p>给reward添加一个 per token 的KL control，我没搞明白它数学上的正当性是哪里来的。不过，可以简单当成对reward的一个修正，只做了一点点改变就拿到reward肯定比做了很多改变才拿到reward好；做了很多改变还拿不到reward的策略更是要狠狠惩罚。</p><script type="math/tex; mode=display">r_t = r_t - \beta \text{log} \frac{\pi_{\theta}}{\pi_{\theta'}}</script><p>参考策略可以是自己，也可以是sft启动后的ref model，不过现在都不这么做了。而且从后者角度理解的话就会觉得有点奇怪，让模型去学ref model，可能是找一条更平滑的接近？</p><h2 id="PPO-Clip"><a href="#PPO-Clip" class="headerlink" title="PPO Clip"></a>PPO Clip</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>【Proximal Policy Optimization (PPO) 算法理解：从策略梯度开始】<a href="https://zhuanlan.zhihu.com/p/614115887">https://zhuanlan.zhihu.com/p/614115887</a></p><p>【从Importance Sampling到PPO】<a href="https://zhuanlan.zhihu.com/p/388707220">https://zhuanlan.zhihu.com/p/388707220</a></p><p>【Why does the “reward to go” trick in policy gradient methods work?】<a href="https://ai.stackexchange.com/questions/9614/why-does-the-reward-to-go-trick-in-policy-gradient-methods-work">https://ai.stackexchange.com/questions/9614/why-does-the-reward-to-go-trick-in-policy-gradient-methods-work</a></p>]]></content>
      
      
      <categories>
          
          <category> Reinforcement Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>恢复更新通知 &amp; 2025plan</title>
      <link href="/posts/10021.html"/>
      <url>/posts/10021.html</url>
      
        <content type="html"><![CDATA[<p>恢复更新！恢复更新！</p><p>有一个个人博客却不写点什么实在是太可惜了。</p><p>过去的一年发生了很多事情，不论是于我还是于我正在投入的领域。</p><p>但是我却没能留下什么东西。</p><p>过去半年在Shanghai AI Lab实习，感觉自己Engineering和Research的能力都有所提高了。</p><p>现在的话，感觉能写下点有用的东西吧~</p>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.824 Distributed System Lab2</title>
      <link href="/posts/10023.html"/>
      <url>/posts/10023.html</url>
      
        <content type="html"><![CDATA[<p>Lab Page：<a href="http://nil.csail.mit.edu/6.824/2022/labs/lab-raft.html">http://nil.csail.mit.edu/6.824/2022/labs/lab-raft.html</a></p><h1 id="Lab概述"><a href="#Lab概述" class="headerlink" title="Lab概述"></a>Lab概述</h1><p>本次lab需要实现共识算法raft。Lab2A我看应该是只需要做出election就可以，一步一步来吧。</p><h1 id="Raft知识点"><a href="#Raft知识点" class="headerlink" title="Raft知识点"></a>Raft知识点</h1><p>网课讲的有些慢哈哈，我直接看博客学习了：<a href="https://zhuanlan.zhihu.com/p/404315977">https://zhuanlan.zhihu.com/p/404315977</a></p><p>在Raft中，节点的状态一共三种，follower，candidate和leader，每个节点在加入时都会默认成为follower。</p><p>follower并不主动发出消息，它所做的操作如下：</p><ul><li><p>收到leader的heartbeat，维持follower状态。如果之前没识别到leader或识别了别的leader，则更新。</p></li><li><p>如果一段时间electionTime内没有收到heartbeat，则认为leader已经嘎了，将自己的任期term加1，成为candidate，并向其它成员发起投票请求。</p></li><li><p>接收到别的candidate的投票请求，依据先来后到原则，只给一个candidate投票。candidate的term以及日志index必须大于自己，否则不会投票。（这边我暂时不是很确定是大于还是大于等于）（会不会有自己的任期是3，有一个任期为4的candidate的request过来之后，又有一个任期为5的candidate的request。这个时候应该还是要投票吧？所以一张票的限制应该是以任期为单位的？）</p></li><li><p>接收到客户端的请求后，转发给leader。（这边也有一个问题，对于新加入的节点，它还没认识到集群中的leader，这里的请求是直接丢弃还是按下不表）</p></li></ul><p>candidate是一种临时状态，它所做的操作如下：</p><ul><li><p>向其它follower发起请求，需要传递自己的任期号term和日志进度index。</p></li><li><p>如果收到了多数成员的赞成票，则自己成为leader（因为一个follower最多投一次票，看上去多数赞成票只能有一个，但是不同节点维护的peer状态可能产生偏差，导致对“多数”产生误解，生成两个甚至多个leader。raft对这一问题的要求是，一个term内只能有leader。（所以具体怎么控制的呢？））</p></li><li><p>如果收到了别的leader的heartbeat，则转变回follower状态。（那如果在另一个leader的heartbeat到达前，自己也变成了leader怎么办？（有时候就是有这么巧合））</p></li><li><p>感觉我对Term的理解不太对哈哈。除了上面的情况，如果收到了一个reply请求携带的term比自己大。说明选举已经进行到下一阶段，已经产生了下一代的共识的leader，自己就该转变回follower状态。</p></li><li><p>candidate有一个随机的选举时限，超过时限还没胜出则宣布失败，重新变回follower。随机是为了避免陷入某种选票瓜分的死局。（随机多少也要具体调整）</p></li></ul><p>leader我们暂时不考虑它处理客户端请求的问题，只考虑它在选举过程中的操作：</p><ul><li>定期向其它节点发送heartbeat</li></ul><p>以上，可以看见还是有很多疑惑的点的，还有没写出来的比如peer列表怎么维护等等，写lab的过程中就会慢慢想明白的吧。</p><p>接下来应该就是看代码了。这次我希望能够看得仔细一点吧，因为后面还有2B，2C，2D是承接Lab2A进行下去的。</p><h1 id="基础代码框架"><a href="#基础代码框架" class="headerlink" title="基础代码框架"></a>基础代码框架</h1><p>还是上来一头雾水，总之要写的代码在raft/raft.go里</p><p>最基础的一个节点应该就是这个raft结构体：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Raft <span class="keyword">struct</span> &#123;</span><br><span class="line">mu        sync.Mutex          <span class="comment">// Lock to protect shared access to this peer&#x27;s state</span></span><br><span class="line">peers     []*labrpc.ClientEnd <span class="comment">// RPC end points of all peers</span></span><br><span class="line">persister *Persister          <span class="comment">// Object to hold this peer&#x27;s persisted state</span></span><br><span class="line">me        <span class="type">int</span>                 <span class="comment">// this peer&#x27;s index into peers[]</span></span><br><span class="line">dead      <span class="type">int32</span>               <span class="comment">// set by Kill()</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先去看一下 <code>*Persister</code> 是个什么东西。</p><p>还是不太明白go语言的import逻辑。 <code>Persister</code>是定义在同属package raft下的 persister.go 中的结构体，定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Persister <span class="keyword">struct</span> &#123;</span><br><span class="line">mu        sync.Mutex</span><br><span class="line">raftstate []<span class="type">byte</span></span><br><span class="line">snapshot  []<span class="type">byte</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好吧，论文里介绍了什么是persister。总之就是，persister表示的是一个节点要存的持久化状态。至于持久化状态有什么呢？在论文的figure2里有。</p><p>我不是很懂为什么这里还要加一个锁？嘛，暂时没想到会冲突的情况。以后操作一个节点时内部还会遇到冲突吗。哦，也合理，因为以后可能会有往本地存储写Persister的时候，不可能同时允许Raft过程修改Persister。所以Persister这次Lab2A应该用不到吧。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://i.072333.xyz/file/ff8a7f3f738c21a47a0b2.png" style="width:600px;"/></div></div><h2 id="rpc参数与Make函数"><a href="#rpc参数与Make函数" class="headerlink" title="rpc参数与Make函数"></a>rpc参数与Make函数</h2><p>根据Hint4，我们先来补全requestVote，按照图示的内容。记得RPC的参数要是大写字母开头，Lab1里踩过坑了。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://i.072333.xyz/file/1783f5b4bc63fd53158b4.png" style="width:600px;"/></div></div><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> RequestVoteArgs <span class="keyword">struct</span> &#123;</span><br><span class="line">Term         <span class="type">int</span>  <span class="comment">// candidate’s term</span></span><br><span class="line">CandidateId  <span class="type">int</span>  <span class="comment">// candidate requesting vote</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">type</span> RequestVoteReply <span class="keyword">struct</span> &#123;</span><br><span class="line">Term         <span class="type">int</span>   </span><br><span class="line">VoteGranted  <span class="type">bool</span>  <span class="comment">// 表示是否收到投票 </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后就是 <code>Make()</code> 函数的作用是初始化一个raft节点，要理清需要做的事。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Make</span><span class="params">(peers []*labrpc.ClientEnd, me <span class="type">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">persister *Persister, applyCh <span class="keyword">chan</span> ApplyMsg)</span></span> *Raft &#123;</span><br><span class="line">rf := &amp;Raft&#123;&#125;  <span class="comment">// rf是一个指针</span></span><br><span class="line">rf.peers = peers  <span class="comment">// 在go中，指针指向成员变量不需要使用-&gt;</span></span><br><span class="line">rf.persister = persister</span><br><span class="line">rf.me = me</span><br><span class="line"></span><br><span class="line"><span class="comment">// Your initialization code here (2A, 2B, 2C).</span></span><br><span class="line"></span><br><span class="line">rf.state = Follower</span><br><span class="line">rf.leaderId = <span class="number">-1</span>  <span class="comment">// 表示还没有leader</span></span><br><span class="line"><span class="keyword">go</span> rf.StartElection()</span><br><span class="line"></span><br><span class="line"><span class="comment">// initialize from state persisted before a crash</span></span><br><span class="line">rf.readPersist(persister.ReadRaftState())</span><br><span class="line"></span><br><span class="line"><span class="comment">// start ticker goroutine to start elections</span></span><br><span class="line"><span class="keyword">go</span> rf.ticker()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> rf</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先是需要将节点的状态设为follower，不妨给raft节点加上一个state属性。可以定义一个const映射，来增强代码的可读性。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    Follower = <span class="number">0</span></span><br><span class="line">    Candidate = <span class="number">1</span></span><br><span class="line">    Leader = <span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这边，应该把选举过程重新go一个进程。选举是需要定期发起的（除非收到leader的heartbeat），不妨设置成无限循环，每150ms发起一次（之后会调整）。</p><p>记录下开始的时间startTime，等待150ms。使用一个lastReceiveTime属性，记录在这150ms内，rf是否收到了heartbeat（可能还有别的操作，后续补充）。如果收到了，那么就不会发起选举。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> StartElection() &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">electionTimeout := rand.Intn(<span class="number">150</span>)</span><br><span class="line">startTime := time.Now()</span><br><span class="line">        time.Sleep(time.Duration(electionTimeout) * time.Millisecond) <span class="comment">// 每150s一次</span></span><br><span class="line">        rf.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> atomic.LoadInt32(&amp;rf.dead) == Dead &#123;  <span class="comment">// 加一个节点是否挂了的判断。如果Kill()一个节点，rf.dead就会被设为1</span></span><br><span class="line">            rf.mu.Unlock()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line"><span class="keyword">if</span> rf.lastReceiveTime &gt; startTime &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> rf.state != Leader &#123;</span><br><span class="line">rf.convertToCandidate()</span><br><span class="line">args := RequestVoteArgs&#123;</span><br><span class="line">Term:         rf.currentTerm,</span><br><span class="line">CandidateId:  rf.me,</span><br><span class="line">&#125;</span><br><span class="line">numVote := <span class="number">1</span>    <span class="comment">// 收到的选票数</span></span><br><span class="line"><span class="comment">// 开始向每个节点发送投票请求。</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(rf.peers); i++ &#123;</span><br><span class="line"><span class="keyword">if</span> i == rf.me &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(peerId <span class="type">int</span>)</span></span> &#123;  <span class="comment">// 这里必须单独go一个进程，因为rpc需要时间</span></span><br><span class="line">replay := RequestVoteReply&#123;&#125;</span><br><span class="line">ok := sendRequestVote(i, args, reply)  </span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">rf.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> replay.Term &gt; rf.currentTerm &#123;</span><br><span class="line">rf.convertToFollower(replay.Term)  <span class="comment">// 同步到该节点的任期</span></span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> replay.VoteGranted &#123;</span><br><span class="line">numVote++</span><br><span class="line"><span class="keyword">if</span> numVote &gt; <span class="built_in">len</span>(rf.peers)/<span class="number">2</span> &amp;&amp; rf.state == Candidate &#123;</span><br><span class="line">rf.convertToLeader()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">rf.mu.Unlock()</span><br><span class="line">&#125; (i)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">rf.mu.Unlock()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有一步转变状态可以做一定的封装增强可读性：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> convertFollower(newTerm <span class="type">int</span>) &#123;</span><br><span class="line">    rf.state = Follower</span><br><span class="line">rf.currentTerm = newTerm</span><br><span class="line">    rf.votedFor = <span class="number">-1</span></span><br><span class="line">rf.lastReceiveTime = time.Now()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> convertToCandidate() &#123;</span><br><span class="line">    rf.state = Candidate</span><br><span class="line">    rf.currentTerm++       <span class="comment">// 增加自己的任期</span></span><br><span class="line">    rf.votedFor = rf.me    <span class="comment">// 投票给自己</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> convertToLeader() &#123;</span><br><span class="line">    rf.state = Leader</span><br><span class="line">rf.leaderId = rf.me</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="sendRequestVote"><a href="#sendRequestVote" class="headerlink" title="sendRequestVote()"></a>sendRequestVote()</h2><p>这里，我们的RPC请求由 <code>sendRequestVote</code> 封装了 <code>RequestVote</code>，还要实现一下。</p><p>整理好args和reply的参数即可。强调一下任期这一概念，本身就是通过节点间的共识推进的，所以落后就代表着某个节点错过了一次的leader统筹，低任期无条件向高任期的节点投降。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(rf *Raft)</span></span> RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123;</span><br><span class="line"><span class="comment">// Your code here (2A, 2B).</span></span><br><span class="line">rf.mu.Lock()</span><br><span class="line">reply.Term = rf.currentTerm</span><br><span class="line"><span class="keyword">if</span> args.Term &lt; rf.currentTerm &#123;</span><br><span class="line">        reply.VoteGranted = <span class="literal">false</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">if</span> args.Term &gt; rf.currentTerm &#123;  <span class="comment">// 如果别人的任期更大，那自己必不可能竞争过，直接投降变为follower</span></span><br><span class="line">            rf.convertToFollower(args.Term)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> rf.votedFor == <span class="number">-1</span> &#123;</span><br><span class="line">            rf.votedFor = args.CandidateId</span><br><span class="line">            reply.VoteGranted = <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">rf.mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="测试框架逻辑"><a href="#测试框架逻辑" class="headerlink" title="测试框架逻辑"></a>测试框架逻辑</h1><p>只能说go的调用确实比较复杂，还是python用太多了。</p><p>啊首先要解释一下，我们编译运行的是 <code>go test -run 2A</code>，这是go的test框架的约定，意思是，它会执行当前文件夹下的一个以 “_test” 结尾的go文件中的所有 “以Test开头，以2A结尾” 的函数。很神奇吧</p><p>我们简单看一下 <code>test_test.go</code> 中的 <code>TestInitialElection2A</code>函数</p><p>它会调用 <code>config.go</code> 中的 <code>make_config</code> 函数，来初始化节点状态保存到cfg变量中。</p><p>在 <code>make_config</code> 中，主要一步是 <code>start1</code> ，作用是初始化一个raft节点，其中就调用了我们在 <code>raft.go</code> 中写的 <code>Make</code> 函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rf := Make(ends, i, cfg.saved[i], applyCh)</span><br><span class="line">cfg.mu.Lock()</span><br><span class="line">cfg.rafts[i] = rf</span><br><span class="line">cfg.mu.Unlock()</span><br></pre></td></tr></table></figure><p>嗯，后面等会再看。</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Lab </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MIT 6.824 Distributed System Lab1</title>
      <link href="/posts/10022.html"/>
      <url>/posts/10022.html</url>
      
        <content type="html"><![CDATA[<p>Lab page: <a href="http://nil.csail.mit.edu/6.824/2022/labs/lab-mr.html">http://nil.csail.mit.edu/6.824/2022/labs/lab-mr.html</a></p><h1 id="Lab概述"><a href="#Lab概述" class="headerlink" title="Lab概述"></a>Lab概述</h1><p>正好这学期正好学校里要上”并行分布式系统”, 也有同学推荐我去学习这门MIT的课程，遂做一些尝试。</p><p>本次Lab1主要是实现一个简单的MapReduce框架，完成Coordinator和Worker的设计，实现一个Word Count程序。</p><p>全课程Lab主要采用go语言来实现，学习go语言语法也是开始本次Lab的第一步。</p><p>以下所有内容仅为个人记录所用，请依照课程要求独立完成Lab实验。</p><p>以上。记录一下本次的Lab1的实现思路。</p><h1 id="一、安装go环境"><a href="#一、安装go环境" class="headerlink" title="一、安装go环境"></a>一、安装go环境</h1><p>上来首先先安装一下以前没用过的go环境。我是在实验室linux服务器上试的，windows系统就不太清楚了。。</p><p>首先下载go的安装包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://go.dev/dl/go1.17.6.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>然后，将其解压到 $HOME/local 下</p><p>之后需要将go命令加到PATH中</p><p>一种方法是 <code>export PATH=$PATH:$HOME/local/go/bin</code> ，但是这样是暂时的，下次启动就没有了</p><p>解决办法就是把这句话加到 .bashrc 中的最后即可</p><p>顺便使用 <code>echo -e $PATH | tr &quot;:&quot; &quot;\n&quot;</code> 可以查看当前的PATH</p><h1 id="二、下载Lab框架"><a href="#二、下载Lab框架" class="headerlink" title="二、下载Lab框架"></a>二、下载Lab框架</h1><p>下载一下Lab的文件，看看有什么东西</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone git://g.csail.mit.edu/6.824-golabs-2022 6.824</span><br></pre></td></tr></table></figure><p>官方提供了一个sequential的MapReduce实现（src/main/mrsequential.go），我们可以先试着跑起来这个。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd 6.824/src/main</span><br><span class="line">go build -race -buildmode=plugin ../mrapps/wc.go</span><br><span class="line">rm mr-out*</span><br><span class="line">go run -race mrsequential.go wc.so pg*.txt</span><br><span class="line">more mr-out-0</span><br></pre></td></tr></table></figure><p>第一次用go可能还是比较懵的，简单介绍一下各步都做了什么。</p><p>go build就是编译go文件，以*.so的形式保存（我不知道说编译成为可执行文件准不准确）</p><p><code>-race</code> 表示启用竞争检测，以避免可能的冲突</p><p><code>-buildmode=plugin</code> 则表示将其编译为plugin，在 <code>mrsequential.go</code> 中，我们可以看到这一插件的用法（下面会介绍）</p><p><code>rm mr-out*</code> 则是删除之前可能的输出文件，保证新一次的输出不会受到影响</p><p><code>go run -race mrsequential.go wc.so pg*.txt</code> go run 就是运行，同样开启竞争检测。这次我们要传入wc.so中的函数，以及运行Word Count需要的所有文件名</p><p>最后，输出结果</p><p>注意在 <code>wc.so</code> 中是有 <code>import &quot;6.824/mr&quot;</code>（也就是需要我们编写的部分，所以记得每次写完测试时都要重新编译wc.so）</p><h2 id="如何使用plugin"><a href="#如何使用plugin" class="headerlink" title="如何使用plugin"></a>如何使用plugin</h2><p>首先需要 <code>import &quot;plugin&quot;</code></p><p>然后打开.so文件，读取其中的函数 <code>p, err := plugin.Open(filename)</code> ，其中filename是在命令行中传递的参数，也就是.so文件的名称</p><p>然后就可以使用 <code>xmapf, err := p.Lookup(FuncName)</code> 来调用定义在.so文件中的function了，比如说调用map函数： <code>xmapf, err := p.Lookup(&quot;Map&quot;)</code></p><p>初次读进来的xmapf似乎是一种独特的类型，还需要转换该函数的形式，设置正确的形参和返回值类型</p><p>例：<code>mapf := xmapf.(func(string, string) []mr.KeyValue)</code> </p><h2 id="mrapps"><a href="#mrapps" class="headerlink" title="mrapps"></a>mrapps</h2><p>可以看到，mrapps文件夹下的各个文件都包含一个map函数和一个reduce函数，不同的函数实现可以让程序实现不同的功能，包括但不限于Word Count</p><h1 id="三、Start"><a href="#三、Start" class="headerlink" title="三、Start"></a>三、Start</h1><p>一开始肯定是很懵的，总之先试着看懂文件的结构。可以参照 <code>mrsequential.go</code> 的逻辑，这个是非常容易理解的。</p><p>第一步就是用mapf函数把文件拆成intermediate，然后将其按照键值排序，我们就把这个作为第一步。</p><p>当然在这之前，worker还需要向coordinator请求一个任务，因此还需要我们发送rpc请求，在<code>mr/worker.go</code>中，给我们展示了如何发送rpc请求，可以参考一下。简单来说就是调call函数，有三个参数，第一个是指定使用coordinator的哪个函数，第二个是传过去的参数，第三个是希望收到的回复。</p><p>暂时还不知道怎么设计，一步一步慢慢来，假设我们coordinator有一个handler函数，我们需要向其请求一个map任务。</p><p>这边有一个我不是很清楚的点，因为看论文，是需要将文件拆分成一个一个块的。这里我们就直接把文件名返回给worker，让worker去做读取这件事。</p><p>参考CallExample()<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// worker.go/func Worker</span></span><br><span class="line"><span class="comment">// ask for a job</span></span><br><span class="line">ok := call(<span class="string">&quot;Coordinator.Handler&quot;</span>, &amp;args, &amp;reply)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line">  <span class="comment">// reply.Y should be 100.</span></span><br><span class="line">  fmt.Printf(<span class="string">&quot;call success, Job name: %s\n&quot;</span>, reply.Filename)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  fmt.Printf(<span class="string">&quot;call failed!\n&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里要考虑的就是怎么设计reply。因为Worker有可能做map，有可能做reduce，所以首先需要的就是返回任务的类型，然后还有需要处理的文件名称。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rpc.go</span></span><br><span class="line"><span class="keyword">type</span> RPCReply <span class="keyword">struct</span> &#123;</span><br><span class="line">JobType <span class="type">string</span></span><br><span class="line">Filename <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后考虑Coordinator这边，Coordinator应该需要知道，自己要给worker分配什么任务，包括任务类型和任务内容。这就需要Coordinator维护一个任务列表，以及一个任务状态。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Coordinator <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Your definitions here.</span></span><br><span class="line">FilenameList []<span class="type">string</span></span><br><span class="line">JobType <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Coordinator初始化的时候，它就应该拥有一个map任务列表，且当前的任务状态是”map”</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MakeCoordinator</span><span class="params">(files []<span class="type">string</span>, nReduce <span class="type">int</span>)</span></span> *Coordinator &#123;</span><br><span class="line">c := Coordinator&#123;</span><br><span class="line">JobType: <span class="string">&quot;map&quot;</span>,  <span class="comment">// 一开始做map操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Your code here.</span></span><br><span class="line"><span class="keyword">for</span> _, filename := <span class="keyword">range</span> files &#123;</span><br><span class="line">c.FilenameList = <span class="built_in">append</span>(c.FilenameList, filename)</span><br><span class="line">fmt.Printf(<span class="string">&quot;我读取了文件:%s\n&quot;</span>, filename)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">c.server()  <span class="comment">// 注意这会创建一个新的go routine，导致可能的race</span></span><br><span class="line"><span class="keyword">return</span> &amp;c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>race问题之后会说明，此处暂时略过。然后就是具体的Handler()函数，在接收到请求后将任务发还给worker即可。如果map任务发完了就将状态改为”reduce”</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Coordinator)</span></span> Handler(args *ExampleArgs, reply *RPCReply) <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.JobType == <span class="string">&quot;map&quot;</span> &#123;</span><br><span class="line">reply.JobType = <span class="string">&quot;map&quot;</span></span><br><span class="line">reply.Filename = c.FilenameList[<span class="number">0</span>]</span><br><span class="line">c.FilenameList = c.FilenameList[<span class="number">1</span>:]  <span class="comment">// 关于这一步的性能问题，可以参见 https://zhuanlan.zhihu.com/p/430888116</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(c.FilenameList) == <span class="number">0</span> &#123;</span><br><span class="line">c.JobType = <span class="string">&quot;reduce&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;not implemented yet\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在只是简单地测试一下rpc是否正确，启动一下看看。需要开两个terminal</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 第一个terminal</span><br><span class="line">go build -race -buildmode=plugin ../mrapps/wc.go</span><br><span class="line">rm mr-out*</span><br><span class="line">go run -race mrcoordinator.go pg-*.txt</span><br><span class="line"></span><br><span class="line">// 第二个terminal</span><br><span class="line">go run -race mrworker.go wc.so</span><br></pre></td></tr></table></figure><p>如果顺利的话，worker应该正确接收到了一个文件的map任务</p><p>不过，coordinator这边会被race检测器检测到问题。检查mrcoordinator.go文件，它需要不断地检查 m.Done()来判断Coordinator是否完成了所有的mapreduce任务；而我们在coordinator.go中，因为启动了server会创建一个新的go routine，这其中又在不断地修改我们的Coordinator的状态，这其中就有可能产生冲突。</p><p>一个办法就是给需要访问Coordinator状态的地方加上锁，锁的用法在MIT Lecture2的Crawler.go中有介绍。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Coordinator <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">mu      sync.Mutex  <span class="comment">// 加一个锁来维护</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Coordinator)</span></span> Handler(args *ExampleArgs, reply *RPCReply) <span class="type">error</span> &#123;</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> c.JobType == <span class="string">&quot;map&quot;</span> &#123;</span><br><span class="line">reply.JobType = <span class="string">&quot;map&quot;</span></span><br><span class="line">reply.Filename = c.FilenameList[<span class="number">0</span>]</span><br><span class="line">c.FilenameList = c.FilenameList[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(c.FilenameList) == <span class="number">0</span> &#123;</span><br><span class="line">c.JobType = <span class="string">&quot;reduce&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;not implemented yet\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">c.mu.Unlock()</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Coordinator)</span></span> Done() <span class="type">bool</span> &#123;</span><br><span class="line">ret := <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Your code here.</span></span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(c.FilenameList) == <span class="number">0</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;map completed\n&quot;</span>)</span><br><span class="line">ret = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line">c.mu.Unlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> ret</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再次启动可以发现没有race问题了。</p><p>当然以上仅是最简单的情况。我们可以以此为基础，整理一下我们接下来要做的事：</p><ul><li><p>worker在收到map任务后的处理逻辑，需要应用map function，然后按键排序，最后写入到一个文件中。</p></li><li><p>完成任务后应当给Coordinator一个反馈，表示已经完成了任务，这样Coordinator可以将intermediate文件加入到它的reduce任务列表中。这要求Coordinator在分配任务的时候分配一个工作id，以唯一指示。</p></li><li><p>worker还需要能够处理reduce任务，逻辑同 <code>mrsequential.go</code></p></li></ul><p>至此，思路已经很清晰了，无非是一边熟悉go语言一边完成Lab。</p><h1 id="四、map任务"><a href="#四、map任务" class="headerlink" title="四、map任务"></a>四、map任务</h1><p>把逻辑优化一下，整一个专门的WorkerMap()函数来做这件事。需要传什么参数写着写着就知道了，对应修改结构体即可。</p><p>一个神奇的点是我发现自己发送的nReduce字段无法被worker接受到，最后才发现，原来RPC只发送字段名以大写字母开头的结构体字段，这一点Hints里也提到了。根据chatgpt说小写字母开头的是私有字段，在其他包中是无法访问的。</p><p>读文件，map，sort，和之前一样</p><p>随后，根据Lab的Hints，为了避免程序写到一半中断，出现一个文件里面内容不全的情况，我们需要使用临时文件，待完全写入后再将其命名为目标文件。这样能保证保存下来的文件内容是全的。包括写入文件也需要使用Hints中提到的 <code>encoding/json</code></p><p>所以我们创建nReduce个临时文件，以及对应的json encoder</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create temporary files and json encoder</span></span><br><span class="line"><span class="keyword">var</span> tempFiles []*os.File</span><br><span class="line"><span class="keyword">var</span> fileEncs []*json.Encoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; nReduce; i++&#123;</span><br><span class="line">  <span class="comment">// tmp files</span></span><br><span class="line">  tmpFile, err := ioutil.TempFile(<span class="string">&quot;.&quot;</span>, <span class="string">&quot;temp-intermediate-*&quot;</span>)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123; </span><br><span class="line">    fmt.Printf(<span class="string">&quot;Failed to create temporary file %d: %v\n&quot;</span>, i, err) </span><br><span class="line">    <span class="keyword">continue</span></span><br><span class="line">  &#125;</span><br><span class="line">  fmt.Printf(<span class="string">&quot;Create temporary file %d: %s\n&quot;</span>, i+<span class="number">1</span>, tmpFile.Name())</span><br><span class="line">  tempFiles = <span class="built_in">append</span>(tempFiles, tmpFile)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// json encoder</span></span><br><span class="line">  enc := json.NewEncoder(tmpFile)  <span class="comment">// 和对应文件输出流绑定</span></span><br><span class="line">  fileEncs = <span class="built_in">append</span>(fileEncs, enc)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我一开始写的是ioutil.TempFile(“”, “temp-intermediate-*”)，结果报错：invalid cross-device link，估计直接保存到服务器的tmp目录下去了？可能是跟我们实验室服务器的硬盘配置有关，把临时文件设到当前目录下就可以解决了。</p><p>然后在保存的时候，每个键值对具体保存到哪个文件，需要使用给出的ihash()函数进行映射，而不是按顺序存储</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// save the intermediate</span></span><br><span class="line">total_len := <span class="built_in">len</span>(intermediate)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; total_len; i++&#123;</span><br><span class="line">index := ihash(intermediate[i].Key) % nReduce</span><br><span class="line">enc := fileEncs[index]</span><br><span class="line">err := enc.Encode(&amp;intermediate[i])</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;json encode error\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，把临时文件重新命名保存为正式文件，保证删除临时文件。保存的中间intermediate文件名为”map-{JobId}-{i}”</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// rename temporary files to formal files</span></span><br><span class="line"><span class="keyword">for</span> i, file := <span class="keyword">range</span> tempFiles &#123;</span><br><span class="line">oname := fmt.Sprintf(<span class="string">&quot;map-%d-%d&quot;</span>, JobId, i)</span><br><span class="line">err = os.Rename(file.Name(), oname)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">           fmt.Printf(<span class="string">&quot;Failed to rename temporary file %d: %v\n&quot;</span>, i, err)</span><br><span class="line">       &#125;</span><br><span class="line">file.Close()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// delete temporary files</span></span><br><span class="line"><span class="keyword">for</span> _, file := <span class="keyword">range</span> tempFiles &#123;</span><br><span class="line"><span class="keyword">defer</span> os.Remove(file.Name())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只能说在尝试创建临时文件的时候遇到了各种各样的问题，，最后这是一个我个人可行的方法。</p><h1 id="五、轮询-amp-优化逻辑"><a href="#五、轮询-amp-优化逻辑" class="headerlink" title="五、轮询 &amp; 优化逻辑"></a>五、轮询 &amp; 优化逻辑</h1><p>正确到这里，我们启动coordinator进程后，每启动一个worker进程，它就会向coordinator发送一次rpc请求，得到一个任务以及对应的文件名，读取后将其分解为中间文件并保存。当然，我们希望worker能够持续的工作而不是做一次之后就停止，因此加一个循环是合理的。</p><p>再简单地加完循环后，我们会发现在coordinator的设计上还存在许多问题。首先，我们把取任务和完成任务的逻辑写在同一个handler接口里，这是不对的，这样直到派出去的任务完成返回前，coordinator的任务清单都不会更新。</p><p>比较容易想到的思路是，拆成两个分配任务和完成任务的接口函数，前者将任务列表中的任务提取到一个临时任务列表中。而完成任务接口收到信息后，就将其从临时任务列表删除，否则，若超时（即有可能派出去的任务没能被完成，worker中断了或是怎么），就将该任务再放回任务列表，交给其它worker工作</p><p>开写，简单地贴一些代码吧。比如说现在worker向coordinator传的arg需要包含jobid和完成情况。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Coordinator)</span></span> JobDone(args *RPCArgs, reply *RPCReply) <span class="type">error</span> &#123;</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> args.DoneSituation == <span class="number">0</span> &#123;</span><br><span class="line">c.FilenameList = <span class="built_in">append</span>(c.FilenameList, c.TempMissionMap[args.JobId])</span><br><span class="line"><span class="built_in">delete</span>(c.TempMissionMap, args.JobId)</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> args.DoneSituation == <span class="number">1</span> &#123;</span><br><span class="line"><span class="built_in">delete</span>(c.TempMissionMap, args.JobId)</span><br><span class="line">c.ReduceList = <span class="built_in">append</span>(c.ReduceList, args.JobId)</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(c.FilenameList) == <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(c.TempMissionMap) == <span class="number">0</span> &#123;</span><br><span class="line">c.JobType = <span class="string">&quot;reduce&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">c.mu.Unlock()</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后worker这边加个循环，简单地设了一个超时检测（处理worker崩溃的情况）（实际上这个超时检测是完全错误，非常难蚌，之后测试的时候我才反应过来）</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">ok := call(<span class="string">&quot;Coordinator.JobAssign&quot;</span>, &amp;args, &amp;reply)</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;call success, Job name: %s, Job id: %d\n&quot;</span>, reply.Filename, reply.JobId)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;call failed!\n&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> reply.JobType == <span class="string">&quot;map&quot;</span> &#123;</span><br><span class="line">startTime := time.Now()</span><br><span class="line">WorkerMap(reply.Filename, reply.NReduce, reply.JobId, mapf)</span><br><span class="line">elapsedTime := time.Since(startTime)</span><br><span class="line"><span class="keyword">if</span> elapsedTime &gt;= <span class="number">5</span> * time.Second &#123;  <span class="comment">// 设置超时时间为5s</span></span><br><span class="line">args.JobId = reply.JobId</span><br><span class="line">args.DoneSituation = <span class="number">0</span></span><br><span class="line">call(<span class="string">&quot;Coordinator.JobDone&quot;</span>, &amp;args, &amp;reply)  <span class="comment">// 没有处理返回值</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">args.JobId = reply.JobId</span><br><span class="line">args.DoneSituation = <span class="number">1</span></span><br><span class="line">call(<span class="string">&quot;Coordinator.JobDone&quot;</span>, &amp;args, &amp;reply)</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> reply.JobType == <span class="string">&quot;reduce&quot;</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;map job has done\n&quot;</span>)</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="六、Reduce"><a href="#六、Reduce" class="headerlink" title="六、Reduce"></a>六、Reduce</h1><p>参考sequential，一样写reduce的代码。</p><p>到这边应该已经驾轻就熟了，主要就是传什么参数让worker能定位到文件。注意一次reduce任务处理的是所有名称为map-{0~filenums}-reduceid的，所以首先rpc参数中需要包含filenums, 以及本次reduce任务的id</p><p>还是有问题的，遇到了一个有意思的问题，就是第一次reduce任务的JobId获取的不对，让我debug一下。</p><p>结果发现coordinator那边给的是正确的，但是worker这边接收的是错的，我直接问号。</p><p>最后反应过来去看lab页面中的hints，原来调用rpc请求的时候，每次传的reply都要清空，否则会有奇怪的错误。清空完以后就ok了。</p><p>随便贴一些我觉得重要的代码吧，记得把nReduce个文件中的键值对kva提取整合到intermediate，要做一次排序</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WorkerReduce</span><span class="params">(ReduceId <span class="type">int</span>, nReduce <span class="type">int</span>, JobId <span class="type">int</span>, Filenums <span class="type">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">reducef <span class="keyword">func</span>(<span class="type">string</span>, []<span class="type">string</span>)</span></span> <span class="type">string</span>) &#123;</span><br><span class="line"><span class="comment">// 读取的文件格式： map-&#123;0~Filenums-1&#125;-&#123;ReduceId&#125;</span></span><br><span class="line"></span><br><span class="line">intermediate := []KeyValue&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> iter := <span class="number">0</span>; iter&lt;Filenums; iter++ &#123;</span><br><span class="line">fileName := fmt.Sprintf(<span class="string">&quot;map-%s-%s&quot;</span>, strconv.Itoa(iter), strconv.Itoa(ReduceId))</span><br><span class="line">file, err := os.Open(fileName)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">&quot;cannot open %v&quot;</span>, fileName)</span><br><span class="line">&#125;</span><br><span class="line">kva := []KeyValue&#123;&#125;</span><br><span class="line"></span><br><span class="line">dec := json.NewDecoder(file)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">var</span> kv KeyValue</span><br><span class="line"><span class="keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">kva = <span class="built_in">append</span>(kva, kv)  <span class="comment">// 提取得到该文件中的所有键值对</span></span><br><span class="line">&#125;</span><br><span class="line">intermediate = <span class="built_in">append</span>(intermediate, kva...)</span><br><span class="line">file.Close()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">oname := fmt.Sprintf(<span class="string">&quot;mr-out-%s&quot;</span>, strconv.Itoa(ReduceId))</span><br><span class="line">ofile, _ := os.Create(oname)</span><br><span class="line"></span><br><span class="line">sort.Sort(ByKey(intermediate))</span><br><span class="line"></span><br><span class="line">i := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i &lt; <span class="built_in">len</span>(intermediate) &#123;</span><br><span class="line">j := i + <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> j &lt; <span class="built_in">len</span>(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key &#123;</span><br><span class="line">j++</span><br><span class="line">&#125;</span><br><span class="line">values := []<span class="type">string</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> k := i; k &lt; j; k++ &#123;</span><br><span class="line">values = <span class="built_in">append</span>(values, intermediate[k].Value)</span><br><span class="line">&#125;</span><br><span class="line">output := reducef(intermediate[i].Key, values)</span><br><span class="line"></span><br><span class="line"><span class="comment">// this is the correct format for each line of Reduce output.</span></span><br><span class="line">fmt.Fprintf(ofile, <span class="string">&quot;%v %v\n&quot;</span>, intermediate[i].Key, output)</span><br><span class="line"></span><br><span class="line">i = j</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ofile.Close()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>随后测试输出：<code>cat mr-out-* | sort | more</code></p><p>但是非常奇怪的是，好像sort失效了，没有正确按照字典序排？？？数量是对的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a 13382</span><br><span class="line">A 509</span><br><span class="line">Ab 3</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这个问题太奇怪了，一通询问GPT后，它告诉我可以指定<code>export LC_COLLATE=C</code>，结果居然就对了，，不知道原来这个环境变量值是什么。我很担心一会儿测试的时候结果能不能对。</p><p>为了让程序正常退出，就在最后给worker发送一个”Done”消息，然后Coordinator这边我就简单粗暴地等一会儿，再退出（以免worker最后一次请求”Done”消息前Coordinator已经退出）。只能说不太严谨，出问题再看吧。</p><h1 id="七、最后的Debug"><a href="#七、最后的Debug" class="headerlink" title="七、最后的Debug"></a>七、最后的Debug</h1><p>运行一下测试看看，结果如下：<code>bash test-mr.sh</code></p><div class="table-container"><table><thead><tr><th>测试</th><th>结果</th><th>报错信息</th></tr></thead><tbody><tr><td>wc test</td><td>FAIL</td><td>sort: cannot read: ‘mr-out*’</td></tr><tr><td>indexer test</td><td>PASS</td><td>/</td></tr><tr><td>map parallelism test</td><td>PASS</td><td>/</td></tr><tr><td>reduce parallelism test</td><td>PASS</td><td>BUT：call failed!dialing:dial unix /var/tmp/824-mr-3149: connect: connection refused</td></tr><tr><td>job count test</td><td>PASS</td><td>/</td></tr><tr><td>early exit test</td><td>FAIL</td><td>output changed after first worker exited</td></tr><tr><td>crash test</td><td>FAIL</td><td>crash output is not the same as mr-correct-crash.txt</td></tr></tbody></table></div><p>总之就是非常惨烈，只能再debug一下了。</p><h2 id="wc-test"><a href="#wc-test" class="headerlink" title="wc test"></a>wc test</h2><p>看了报错信息是因为map阶段报错了，取任务的时候取了空列表。这时我才反应过来，我要等到取了最后一个任务的worker返回才会改变coordinator的状态，但是此时其它worker还会取任务，这就会报错了。</p><p>所以在worker取空集的情况下，我先加一个判断，如果已经空了，就返回一个sleep信息，让worker休息1s，这样就能正确等到Coordinator状态改变了。</p><p>然而，在多次测试的时候遇到了有些map任务丢了的情况？再debug一下，感觉可能是超时时间的问题，程序是不会出错的，只不过有可能有的任务做的慢了点，超时时间开大就可以了。</p><h2 id="early-exit-test"><a href="#early-exit-test" class="headerlink" title="early-exit test"></a>early-exit test</h2><p>看一下bash文件能知道这一项测试的测试逻辑：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># a process has exited. this means that the output should be finalized</span></span><br><span class="line"><span class="comment"># otherwise, either a worker or the coordinator exited early</span></span><br><span class="line"><span class="built_in">sort</span> mr-out* | grep . &gt; mr-wc-all-initial</span><br><span class="line"></span><br><span class="line"><span class="comment"># wait for remaining workers and coordinator to exit.</span></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># compare initial and final outputs</span></span><br><span class="line"><span class="built_in">sort</span> mr-out* | grep . &gt; mr-wc-all-final</span><br></pre></td></tr></table></figure><p>简单来说就是应该是一个进程退出就应该说明整个任务完成了</p><p>经过debug，我发现自己出了一个很逆天的bug，Coordinator在每次给完任务后会go一个新的判断函数，如果过了一定时间，这个任务还没完成，就判定worker出错了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(jobID <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line"><span class="keyword">if</span> _, ok := c.TempMissionMap[jobID]; ok &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;%d map job 超时\n&quot;</span>, jobID)</span><br><span class="line">c.FilenameList = <span class="built_in">append</span>(c.FilenameList, c.TempMissionMap[jobID])</span><br><span class="line"><span class="built_in">delete</span>(c.TempMissionMap, jobID)</span><br><span class="line">&#125;</span><br><span class="line">&#125;(reply.JobId)</span><br></pre></td></tr></table></figure><p>然而，我因为偷懒，所以把map任务的临时列表和reduce任务的临时列表用的是一个。结果！map任务时发起的判断函数，竟然在reduce阶段造成了问题，误删了任务。。很难蚌。</p><p>重新给reduce任务单独开一个列表就通过了。</p><h2 id="crash-test"><a href="#crash-test" class="headerlink" title="crash test"></a>crash test</h2><p>我发现是我对超时检测的理解出了问题。超时检测应该是在coordinator端进行的，否则worker端crash了，根本就不会触发那边的超时检测，传一个错误信息回来什么的。我那个超时就很呆，完全没有一点作用，应该删掉的。</p><p>利用我们之前的临时任务列表，我们需要再写一个周期执行的函数，判断它们距任务发布时间过去多久了。</p><p>或者，一个比较好的设计是，发送一个rpc请求后，它会发起另一个函数，比如说10s后是否接收到回复。</p><p>是否接收到回复我们只要看临时任务列表中对应的任务有没有被删去就可以了，复用一下结构</p><p>将类似以下的函数插在coordinator的rpc回复之后就可以了。它会在10s后检测有没有被正确删去，如果没有，那就说明这个worker爆了，把任务再返回任务列表。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(jobID <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line"><span class="keyword">if</span> _, ok := c.TempMissionMap[jobID]; ok &#123;</span><br><span class="line">c.FilenameList = <span class="built_in">append</span>(c.FilenameList, c.TempMissionMap[jobID])</span><br><span class="line"><span class="built_in">delete</span>(c.TempMissionMap, jobID)</span><br><span class="line">&#125;</span><br><span class="line">&#125;(reply.JobId)</span><br></pre></td></tr></table></figure><p>但是还是不对，我debug后发现是文件命名的问题，，我在map阶段对中间文件的命名是 <code>map-&#123;JobId&#125;-&#123;0~nReduce-1&#125;</code> ，而reduce的时候读的文件名却是 <code>map-&#123;0~Filenums-1&#125;-&#123;ReduceId&#125;</code>。</p><p>感觉就记录一下map成功的jobid，然后传给reduce？或者其实应该使用通配符，直接去匹配 <code>map-*-&#123;ReduceId&#125;</code> ，这样肯定更好，问问gpt有没有这种方法。</p><p>gpt提供了一个库方法 <code>path/filepath</code> ，可以使用 <code>files, err := filepath.Glob(pattern)</code> 去匹配，修改完后通过测试。</p><p>最后还有两个小小的问题：</p><p>一个是测试的bash脚本中，每做完一项任务就会把生成的文件 mr-* 删了，但是我的map文件命名的是map-X-Y，导致删不掉就会影响下次的结果。把中间文件名换了就可以了。</p><p>还有就是crash-test，可以看到它会让程序随机delay一段时间，可能长达10s，所以我们的超时检测时间需要开的长一点。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> rr.Int64() &lt; <span class="number">660</span> &#123;</span><br><span class="line"><span class="comment">// delay for a while.</span></span><br><span class="line">maxms := big.NewInt(<span class="number">10</span> * <span class="number">1000</span>)</span><br><span class="line">ms, _ := crand.Int(crand.Reader, maxms)</span><br><span class="line">time.Sleep(time.Duration(ms.Int64()) * time.Millisecond)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="八、复盘"><a href="#八、复盘" class="headerlink" title="八、复盘"></a>八、复盘</h1><p>最后展示一下通过截图吧：</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://i.072333.xyz/file/67b3d2132f8b5e49a1b68.png" style="width:400px;"/></div></div><p>虽然是很不容易地做完了，但是感觉还是有很多做的不太好的地方。</p><p>现在想想感觉应该维护一个worker状态的，每个worker也分配一个worker ID，这样便于管理。也不用临时任务列表了，直接维护worker列表就可以了（同时记录每个worker分配的任务）。唉，只能说开始做的时候还是太仓促了。</p><h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><p>论文链接：<a href="http://research.google.com/archive/mapreduce-osdi04.pdf">http://research.google.com/archive/mapreduce-osdi04.pdf</a></p><p>代码链接：后续会放到我的github上</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Distributed System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed System </tag>
            
            <tag> Lab </tag>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FDU Computer Graphics pj2</title>
      <link href="/posts/10020.html"/>
      <url>/posts/10020.html</url>
      
        <content type="html"><![CDATA[<div class="note success simple"><p>薪火相传</p></div><p>距离有点久远了，唉可惜自己比较懒，没能在做完作业后立马补一篇博客。现在差不多都忘啦，结果pj3还要用webgl，只好先复习一下pj2自己学的东西。也许会稍微记录一下重要步骤。。</p><p>有需要的同学可以拉到最后直接看完整js代码。</p><h1 id="项目说明"><a href="#项目说明" class="headerlink" title="项目说明"></a>项目说明</h1><p>用webgl画一个颜色渐变多边形，需要实现顶点拖动，旋转动画，绘制网格等功能</p><h1 id="完整代码-javascript"><a href="#完整代码-javascript" class="headerlink" title="完整代码(javascript)"></a>完整代码(javascript)</h1><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 顶点着色器</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">VSHADER_SOURCE</span> = </span><br><span class="line">    <span class="string">&#x27;attribute vec4 a_Position;\n&#x27;</span> + <span class="comment">// attribute 变量</span></span><br><span class="line">    <span class="string">&#x27;uniform mat4 u_ModelMatrix;\n&#x27;</span> + <span class="comment">//变换矩阵</span></span><br><span class="line">    <span class="string">&#x27;attribute vec4 a_Color;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;varying vec4 v_Color;\n&#x27;</span> + <span class="comment">// varying 变量</span></span><br><span class="line">    <span class="string">&#x27;uniform int u_RenderMode;\n&#x27;</span> + <span class="comment">// 新增 uniform 变量，用于区分绘制模式(图形or边框线)</span></span><br><span class="line">    <span class="string">&#x27;void main() &#123;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;    gl_Position = u_ModelMatrix * a_Position;\n&#x27;</span> + <span class="comment">// 设置顶点坐标</span></span><br><span class="line">    <span class="string">&#x27;    if(u_RenderMode == 0) &#123;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;        v_Color = a_Color;\n&#x27;</span> +  <span class="comment">// 传递给片元着色器</span></span><br><span class="line">    <span class="string">&#x27;    &#125;\n&#x27;</span> + </span><br><span class="line">    <span class="string">&#x27;    else &#123;\n&#x27;</span>+</span><br><span class="line">    <span class="string">&#x27;        v_Color = vec4(1.0, 0.0, 0.0, 1.0);\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;    &#125;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;&#125;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 片元着色器</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">FSHADER_SOURCE</span> =</span><br><span class="line">    <span class="string">&#x27;precision mediump float;\n&#x27;</span> + <span class="comment">// 精度</span></span><br><span class="line">    <span class="string">&#x27;varying vec4 v_Color;\n&#x27;</span> +    <span class="comment">// 接收varying变量</span></span><br><span class="line">    <span class="string">&#x27;void main() &#123;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;  gl_FragColor = v_Color;\n&#x27;</span> +</span><br><span class="line">    <span class="string">&#x27;&#125;\n&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 旋转速度（度/秒）</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">ANGLE_STEP</span> = <span class="number">45.0</span>;</span><br><span class="line"><span class="comment">// 缩放速度</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">SCALE_SPEED</span> = <span class="number">0.2</span>;</span><br><span class="line"><span class="comment">// 缩放方向（变大or变小）</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">SCALE_DIRECTON</span> = -<span class="number">1</span>;</span><br><span class="line"><span class="comment">// 是否开启动画</span></span><br><span class="line"><span class="keyword">var</span> <span class="variable constant_">ANIMATION</span> = <span class="literal">false</span>;</span><br><span class="line"><span class="comment">// 避免动画开始的瞬移 </span></span><br><span class="line"><span class="keyword">var</span> init = <span class="literal">false</span>;</span><br><span class="line"><span class="comment">// 判断是否正拖动点</span></span><br><span class="line"><span class="keyword">var</span> isDragging = <span class="literal">false</span>;</span><br><span class="line"><span class="comment">// 当前正在拖动的点</span></span><br><span class="line"><span class="keyword">var</span> <span class="title class_">DraggingVertex</span> = -<span class="number">1</span>;</span><br><span class="line"><span class="comment">// 是否显示边框</span></span><br><span class="line"><span class="keyword">var</span> frame = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 三角形当前的旋转角度</span></span><br><span class="line"><span class="keyword">var</span> currentAngle = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">var</span> currentScale = <span class="number">1.0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">main</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> canvas = <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&quot;webgl&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span>(!canvas) &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Fail to load canvas&quot;</span>); <span class="keyword">return</span> <span class="literal">false</span>;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置画布大小</span></span><br><span class="line">    canvas.<span class="title function_">setAttribute</span>(<span class="string">&quot;width&quot;</span>, canvasSize.<span class="property">maxX</span>);</span><br><span class="line">    canvas.<span class="title function_">setAttribute</span>(<span class="string">&quot;height&quot;</span>, canvasSize.<span class="property">maxY</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将canvas坐标转换为webgl坐标</span></span><br><span class="line">    <span class="keyword">var</span> rect = canvas.<span class="title function_">getBoundingClientRect</span>();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>, len = vertex_pos.<span class="property">length</span>; i&lt;len; i++) &#123;</span><br><span class="line">        vertex_pos[i][<span class="number">0</span>] = ((vertex_pos[i][<span class="number">0</span>] - rect.<span class="property">left</span>) - canvas.<span class="property">width</span> / <span class="number">2</span>) / (canvas.<span class="property">width</span> / <span class="number">2</span>);</span><br><span class="line">        vertex_pos[i][<span class="number">1</span>] = (canvas.<span class="property">height</span> / <span class="number">2</span> - (vertex_pos[i][<span class="number">1</span>] - rect.<span class="property">top</span>)) / (canvas.<span class="property">height</span> / <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 获取webgl对象</span></span><br><span class="line">    <span class="keyword">var</span> gl = <span class="title function_">getWebGLContext</span>(canvas);</span><br><span class="line">    <span class="keyword">if</span>(!gl) &#123; <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Fail to get the rendering context for WebGL&quot;</span>); <span class="keyword">return</span> <span class="literal">false</span>;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化着色器</span></span><br><span class="line">    <span class="keyword">var</span> shader_main = <span class="title function_">initShaders</span>(gl, <span class="variable constant_">VSHADER_SOURCE</span>, <span class="variable constant_">FSHADER_SOURCE</span>);</span><br><span class="line">    <span class="keyword">if</span> (!shader_main) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to intialize shaders.&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建缓冲区对象</span></span><br><span class="line">    <span class="keyword">var</span> n = <span class="title function_">initVertexBuffers</span>(gl, canvas, rect);</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to set the positions of the vertices&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置背景色</span></span><br><span class="line">    gl.<span class="title function_">clearColor</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取渲染模式uniform变量</span></span><br><span class="line">    <span class="keyword">var</span> u_RenderMode = gl.<span class="title function_">getUniformLocation</span>(gl.<span class="property">program</span>, <span class="string">&#x27;u_RenderMode&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (!u_RenderMode) &#123; </span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to get the storage location of u_RenderMode&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取旋转矩阵uniform变量</span></span><br><span class="line">    <span class="keyword">var</span> u_ModelMatrix = gl.<span class="title function_">getUniformLocation</span>(gl.<span class="property">program</span>, <span class="string">&#x27;u_ModelMatrix&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (!u_ModelMatrix) &#123; </span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to get the storage location of u_ModelMatrix&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建旋转矩阵</span></span><br><span class="line">    <span class="keyword">var</span> modelMatrix = <span class="keyword">new</span> <span class="title class_">Matrix4</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 动画效果</span></span><br><span class="line">    <span class="keyword">var</span> tick = <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="keyword">var</span> currentStage = <span class="title function_">animate</span>(currentAngle, currentScale);</span><br><span class="line">        currentAngle = currentStage[<span class="number">0</span>];  <span class="comment">// 更新旋转角度</span></span><br><span class="line">        currentScale = currentStage[<span class="number">1</span>];  <span class="comment">// 更新缩放大小</span></span><br><span class="line"></span><br><span class="line">        <span class="title function_">draw</span>(gl, n, currentAngle, currentScale, modelMatrix, u_ModelMatrix, u_RenderMode);   <span class="comment">// 渲染图形</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="variable constant_">ANIMATION</span>)</span><br><span class="line">            <span class="title function_">requestAnimationFrame</span>(tick, canvas); <span class="comment">// 请求再次调用tick</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="title function_">draw</span>(gl, n, currentAngle, currentScale, modelMatrix, u_ModelMatrix, u_RenderMode);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册键盘点击事件</span></span><br><span class="line">    <span class="variable language_">document</span>.<span class="title function_">addEventListener</span>(<span class="string">&quot;keydown&quot;</span>, <span class="keyword">function</span>(<span class="params">event</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (event.<span class="property">key</span> === <span class="string">&quot;t&quot;</span> || event.<span class="property">key</span> === <span class="string">&quot;T&quot;</span>) &#123; <span class="comment">// 开始/暂停动画</span></span><br><span class="line">            <span class="variable constant_">ANIMATION</span> = !<span class="variable constant_">ANIMATION</span>;</span><br><span class="line">            <span class="keyword">if</span>(<span class="variable constant_">ANIMATION</span>) &#123;</span><br><span class="line">                init = <span class="literal">true</span>;</span><br><span class="line">                <span class="title function_">tick</span>(); <span class="comment">// 调用 tick 函数</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (event.<span class="property">key</span> === <span class="string">&quot;e&quot;</span> || event.<span class="property">key</span> === <span class="string">&quot;E&quot;</span>) &#123; <span class="comment">// 复位</span></span><br><span class="line">            <span class="variable constant_">ANIMATION</span> = <span class="literal">false</span>;</span><br><span class="line">            currentAngle = <span class="number">0.0</span>;</span><br><span class="line">            currentScale = <span class="number">1.0</span>;</span><br><span class="line">            init = <span class="literal">true</span>;</span><br><span class="line">            <span class="title function_">tick</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (event.<span class="property">key</span> === <span class="string">&quot;b&quot;</span> || event.<span class="property">key</span> === <span class="string">&quot;B&quot;</span>) &#123; <span class="comment">// 显示边框</span></span><br><span class="line">            frame = !frame;</span><br><span class="line">            init = <span class="literal">true</span>;</span><br><span class="line">            <span class="title function_">tick</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注册鼠标点击事件</span></span><br><span class="line">    canvas.<span class="property">onmousedown</span> = <span class="keyword">function</span>(<span class="params">ev</span>)&#123; </span><br><span class="line">        isDragging = <span class="literal">true</span>;</span><br><span class="line">        <span class="title function_">click</span>(ev, gl, canvas, </span><br><span class="line">            currentAngle, currentScale,  <span class="comment">// 当前的状态，为了确定当前的点的位置</span></span><br><span class="line">            modelMatrix, u_ModelMatrix,</span><br><span class="line">            rect); </span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    canvas.<span class="property">onmousemove</span> = <span class="keyword">function</span>(<span class="params">ev</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!isDragging) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable constant_">ANIMATION</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">var</span> x = <span class="title function_">toW</span>(ev.<span class="property">clientX</span>, <span class="number">0</span>, canvas, rect); <span class="comment">// 鼠标x坐标</span></span><br><span class="line">        <span class="keyword">var</span> y = <span class="title function_">toW</span>(ev.<span class="property">clientY</span>, <span class="number">1</span>, canvas, rect); <span class="comment">// 鼠标y坐标</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 得到旋转矩阵</span></span><br><span class="line">        modelMatrix.<span class="title function_">setRotate</span>(currentAngle, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">        modelMatrix.<span class="title function_">scale</span>(currentScale, currentScale, currentScale);</span><br><span class="line">        <span class="comment">// 求逆</span></span><br><span class="line">        modelMatrix = modelMatrix.<span class="title function_">invert</span>();</span><br><span class="line">        <span class="comment">// 更新点（注意需要更新旋转前的坐标）</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="title class_">DraggingVertex</span>!=-<span class="number">1</span>)&#123;</span><br><span class="line">            vertex_pos[<span class="title class_">DraggingVertex</span>][<span class="number">0</span>] = x * modelMatrix.<span class="property">elements</span>[<span class="number">0</span>] + y * modelMatrix.<span class="property">elements</span>[<span class="number">4</span>] + modelMatrix.<span class="property">elements</span>[<span class="number">12</span>];</span><br><span class="line">            vertex_pos[<span class="title class_">DraggingVertex</span>][<span class="number">1</span>] = x * modelMatrix.<span class="property">elements</span>[<span class="number">1</span>] + y * modelMatrix.<span class="property">elements</span>[<span class="number">5</span>] + modelMatrix.<span class="property">elements</span>[<span class="number">13</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 重新创建缓冲区对象</span></span><br><span class="line">        <span class="keyword">var</span> n = <span class="title function_">initVertexBuffers</span>(gl, canvas, rect);</span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to set the positions of the vertices&#x27;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="title function_">draw</span>(gl, n, currentAngle, currentScale, modelMatrix, u_ModelMatrix, u_RenderMode);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    canvas.<span class="property">onmouseup</span> = <span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line">        isDragging = <span class="literal">false</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">initVertexBuffers</span>(<span class="params">gl, canvas, rect</span>) &#123;</span><br><span class="line">    <span class="comment">// 创建缓冲区对象</span></span><br><span class="line">    <span class="keyword">var</span> vertexBuffer = gl.<span class="title function_">createBuffer</span>();</span><br><span class="line">    <span class="keyword">if</span>(!vertexBuffer) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to create the buffer object&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将缓冲区对象绑定到目标</span></span><br><span class="line">    gl.<span class="title function_">bindBuffer</span>(gl.<span class="property">ARRAY_BUFFER</span>, vertexBuffer);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向缓冲区对象中写入数据</span></span><br><span class="line">    <span class="keyword">var</span> n = <span class="number">4</span> * polygon.<span class="property">length</span>; <span class="comment">// 点的个数</span></span><br><span class="line">    <span class="keyword">var</span> vertices = <span class="keyword">new</span> <span class="title class_">Float32Array</span>(n * <span class="number">5</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">var</span> offset = <span class="number">0</span>; <span class="comment">// 偏移用于将每个四边形的顶点数据写入数组</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>, len = polygon.<span class="property">length</span>; i&lt;len; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">var</span> j=<span class="number">0</span>; j&lt;<span class="number">4</span>; j++) &#123;</span><br><span class="line">            vertices[offset++] = vertex_pos[polygon[i][j]][<span class="number">0</span>];</span><br><span class="line">            vertices[offset++] = vertex_pos[polygon[i][j]][<span class="number">1</span>];</span><br><span class="line">            vertices[offset++] = vertex_color[polygon[i][j]][<span class="number">0</span>]/<span class="number">255</span>;</span><br><span class="line">            vertices[offset++] = vertex_color[polygon[i][j]][<span class="number">1</span>]/<span class="number">255</span>;</span><br><span class="line">            vertices[offset++] = vertex_color[polygon[i][j]][<span class="number">2</span>]/<span class="number">255</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向缓冲区写入数据</span></span><br><span class="line">    gl.<span class="title function_">bufferData</span>(gl.<span class="property">ARRAY_BUFFER</span>, vertices, gl.<span class="property">STATIC_DRAW</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> <span class="variable constant_">FSIZE</span> = vertices.<span class="property">BYTES_PER_ELEMENT</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取坐标attribute变量</span></span><br><span class="line">    <span class="keyword">var</span> a_Position = gl.<span class="title function_">getAttribLocation</span>(gl.<span class="property">program</span>, <span class="string">&#x27;a_Position&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (a_Position &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to get the storage location of a_Position&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将缓冲区对象分配给a_position变量</span></span><br><span class="line">    gl.<span class="title function_">vertexAttribPointer</span>(a_Position, <span class="number">2</span>, gl.<span class="property">FLOAT</span>, <span class="literal">false</span>, <span class="variable constant_">FSIZE</span> * <span class="number">5</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 连接a_Position变量与分配给它的缓冲区对象</span></span><br><span class="line">    gl.<span class="title function_">enableVertexAttribArray</span>(a_Position);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取颜色attribute变量</span></span><br><span class="line">    <span class="keyword">var</span> a_Color = gl.<span class="title function_">getAttribLocation</span>(gl.<span class="property">program</span>, <span class="string">&#x27;a_Color&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span>(a_Color &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;Failed to get the storage location of a_Color&#x27;</span>);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    gl.<span class="title function_">vertexAttribPointer</span>(a_Color, <span class="number">3</span>, gl.<span class="property">FLOAT</span>, <span class="literal">false</span>, <span class="variable constant_">FSIZE</span> * <span class="number">5</span>, <span class="variable constant_">FSIZE</span> * <span class="number">2</span>);</span><br><span class="line">    gl.<span class="title function_">enableVertexAttribArray</span>(a_Color); </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 解绑缓冲区</span></span><br><span class="line">    gl.<span class="title function_">bindBuffer</span>(gl.<span class="property">ARRAY_BUFFER</span>, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">draw</span>(<span class="params">gl, n, currentAngle, currentScale, modelMatrix, u_ModelMatrix, u_RenderMode</span>) &#123;</span><br><span class="line">    <span class="comment">// 计算旋转矩阵</span></span><br><span class="line">    modelMatrix.<span class="title function_">setRotate</span>(currentAngle, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    modelMatrix.<span class="title function_">scale</span>(currentScale, currentScale, currentScale);</span><br><span class="line">    <span class="comment">// 把旋转矩阵传给渲染器</span></span><br><span class="line">    gl.<span class="title function_">uniformMatrix4fv</span>(u_ModelMatrix, <span class="literal">false</span>, modelMatrix.<span class="property">elements</span>);</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 清除canvas</span></span><br><span class="line">    gl.<span class="title function_">clear</span>(gl.<span class="property">COLOR_BUFFER_BIT</span>);</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 画出图形</span></span><br><span class="line">    gl.<span class="title function_">uniform1i</span>(u_RenderMode, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>; i&lt;<span class="number">16</span>; i+=<span class="number">4</span>) &#123;</span><br><span class="line">        gl.<span class="title function_">drawArrays</span>(gl.<span class="property">TRIANGLE_FAN</span>, i, <span class="number">4</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(frame) &#123;</span><br><span class="line">        gl.<span class="title function_">uniform1i</span>(u_RenderMode, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>; i&lt;<span class="number">16</span>; i+=<span class="number">4</span>) &#123;</span><br><span class="line">            gl.<span class="title function_">drawArrays</span>(gl.<span class="property">LINE_LOOP</span>, i, <span class="number">3</span>);</span><br><span class="line">            gl.<span class="title function_">drawArrays</span>(gl.<span class="property">LINE_LOOP</span>, i, <span class="number">4</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 上次调用tick函数的时间</span></span><br><span class="line"><span class="keyword">var</span> g_last = <span class="title class_">Date</span>.<span class="title function_">now</span>();</span><br><span class="line"><span class="keyword">function</span> <span class="title function_">animate</span>(<span class="params">angle, scale</span>) &#123;</span><br><span class="line">    <span class="comment">// 计算时间差距</span></span><br><span class="line">    <span class="keyword">var</span> now = <span class="title class_">Date</span>.<span class="title function_">now</span>();</span><br><span class="line">    <span class="keyword">var</span> elapsed;</span><br><span class="line">    <span class="keyword">if</span>(!init) &#123;</span><br><span class="line">        elapsed = now - g_last;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        elapsed = <span class="number">0</span>;</span><br><span class="line">        init = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    g_last = now;</span><br><span class="line">    <span class="comment">// 根据时间间隔调整新角度</span></span><br><span class="line">    <span class="keyword">var</span> newAngle = (angle + (<span class="variable constant_">ANGLE_STEP</span> * elapsed) / <span class="number">1000.0</span>) % <span class="number">360</span>;</span><br><span class="line">    <span class="comment">// 根据时间间隔调整新缩放比例</span></span><br><span class="line">    <span class="keyword">var</span> update = scale + <span class="variable constant_">SCALE_DIRECTON</span> * (<span class="variable constant_">SCALE_SPEED</span> * elapsed) / <span class="number">1000.0</span>;</span><br><span class="line">    <span class="keyword">var</span> newSize;</span><br><span class="line">    <span class="keyword">if</span>(update &lt; <span class="number">0.2</span>) &#123;</span><br><span class="line">        <span class="variable constant_">SCALE_DIRECTON</span> *= -<span class="number">1</span>;</span><br><span class="line">        newSize = <span class="number">0.4</span> - update;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(update &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="variable constant_">SCALE_DIRECTON</span> *= -<span class="number">1</span>;</span><br><span class="line">        newSize = <span class="number">2</span> - update;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        newSize = update;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> [newAngle, newSize];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">click</span>(<span class="params">ev, gl, canvas, currentAngle, currentScale, modelMatrix, u_ModelMatrix, rect</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> x = <span class="title function_">toW</span>(ev.<span class="property">clientX</span>, <span class="number">0</span>, canvas, rect); <span class="comment">// 鼠标x坐标</span></span><br><span class="line">    <span class="keyword">var</span> y = <span class="title function_">toW</span>(ev.<span class="property">clientY</span>, <span class="number">1</span>, canvas, rect); <span class="comment">// 鼠标y坐标</span></span><br><span class="line">    <span class="comment">// 计算旋转矩阵</span></span><br><span class="line">    modelMatrix.<span class="title function_">setRotate</span>(currentAngle, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    modelMatrix.<span class="title function_">scale</span>(currentScale, currentScale, currentScale);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> vertex_X;</span><br><span class="line">    <span class="keyword">var</span> vertex_Y;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> min_length = <span class="number">0.001</span>;</span><br><span class="line">    <span class="keyword">var</span> min_vertex = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i=<span class="number">0</span>, len = vertex_pos.<span class="property">length</span>; i&lt;len; i++) &#123;</span><br><span class="line">        vertex_X = vertex_pos[i][<span class="number">0</span>] * modelMatrix.<span class="property">elements</span>[<span class="number">0</span>] + vertex_pos[i][<span class="number">1</span>] * modelMatrix.<span class="property">elements</span>[<span class="number">4</span>] + modelMatrix.<span class="property">elements</span>[<span class="number">12</span>];</span><br><span class="line">        vertex_Y = vertex_pos[i][<span class="number">0</span>] * modelMatrix.<span class="property">elements</span>[<span class="number">1</span>] + vertex_pos[i][<span class="number">1</span>] * modelMatrix.<span class="property">elements</span>[<span class="number">5</span>] + modelMatrix.<span class="property">elements</span>[<span class="number">13</span>];</span><br><span class="line">        <span class="keyword">if</span>((x - vertex_X)**<span class="number">2</span> + (y - vertex_Y)**<span class="number">2</span> &lt; min_length) &#123;</span><br><span class="line">            min_vertex = i;</span><br><span class="line">            min_length = (x - vertex_X)**<span class="number">2</span> + (y - vertex_Y)**<span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title class_">DraggingVertex</span> = min_vertex;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">toW</span>(<span class="params">co, XorY, canvas, rect</span>)&#123; <span class="comment">// 变换至Webgl坐标</span></span><br><span class="line">    <span class="keyword">if</span>(!<span class="title class_">XorY</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> ((co - rect.<span class="property">left</span>) - canvas.<span class="property">width</span> / <span class="number">2</span>) / (canvas.<span class="property">width</span> / <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (canvas.<span class="property">height</span> / <span class="number">2</span> - (co - rect.<span class="property">top</span>)) / (canvas.<span class="property">height</span> / <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Computer Graphics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Computer Graphics </tag>
            
            <tag> Study </tag>
            
            <tag> Homework </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mininet安装全指南</title>
      <link href="/posts/10019.html"/>
      <url>/posts/10019.html</url>
      
        <content type="html"><![CDATA[<p>该说不说，对我们学校大部分课程的Lab都非常失望，连简单的实验文档都写不好，还需要学生自己摸索怎么做，浪费我那么多时间。</p><p>记录一下自己在安装mininet过程中遇到的问题，非常非常多，希望能帮到后来的同学。</p><p>应该会有很多图，希望都能加载出来。</p><h1 id="安装虚拟机"><a href="#安装虚拟机" class="headerlink" title="安装虚拟机"></a>安装虚拟机</h1><p>本次mininet需要用到图形界面，WSL本人试过了并不支持，无奈只能转向VirtualBox进行实验。</p><p>去VirtualBox官网下载即可：<a href="https://www.virtualbox.org/wiki/Downloads">https://www.virtualbox.org/wiki/Downloads</a></p><p>我是windows系统，直接点windows host下载即可。下载完后安装。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/11/22/d847fbc3124ed53e25aed79901f8ed26.jpeg" style="width:400px;"/></div></div><p>下载完后打开应该是这样：（我因为已经建好了所以列表里会有一个Ubuntu，原始状态应该是空的）</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picst.sunbangyan.cn/2023/11/22/d3b4657d59d70bc5d2ca1999fae0005f.jpeg" style="width:800px;"/></div></div><p>这个时候我们需要先去下载一个Ubuntu镜像，在 <a href="https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/20.04/">https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/20.04/</a> 这里即可下载，选择 ubuntu-20.04.6-desktop-amd64.iso</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/11/22/a259e2bfd08beb71fad51b4c18bc3768.jpeg" style="width:400px;"/></div></div><p>下载完后我们回到VirtualBox，点击右上方蓝色的新建</p><p>进去以后界面如下，设置一个名称（Ubuntu就可以），文件夹在想要的位置自己建一个，然后虚拟光盘选择我们刚才下载的文件。下一步</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/11/22/415d13eb9426abb55c23cdbbd4bf05f6.jpeg" style="width:800px;"/></div></div><p>下一步自己设置用户名和密码（请记住）。然后下面这个增强功能要勾选！（截图中没有选上）</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdl.sunbangyan.cn/2023/11/22/04cb6d27ce0073cd853d42217eab62fd.jpeg" style="width:800px;"/></div></div><p>之后是分配内存和空间，默认即可（感觉空间不用那么多）</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdl.sunbangyan.cn/2023/11/22/0b60d8486932d0d87d22fadfcdd0de05.jpeg" style="width:400px;"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdl.sunbangyan.cn/2023/11/22/0b8f435b83c5e52744ddcb9eabe106a5.jpeg" style="width:400px;"/></div></div><p>然后它就会开始初始化系统，等待一段时间即可。</p><h1 id="配置Ubuntu"><a href="#配置Ubuntu" class="headerlink" title="配置Ubuntu"></a>配置Ubuntu</h1><h2 id="呼出命令行"><a href="#呼出命令行" class="headerlink" title="呼出命令行"></a>呼出命令行</h2><p>随后就可以进入Ubuntu界面，那么，该如何呼出命令行呢？</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdl.sunbangyan.cn/2023/11/22/146af73c4b003f2be0f83e70a8ae9032.jpeg" style="width:400px;"/></div></div><p>按下键盘上的windows键，输入terminal即可。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdm.sunbangyan.cn/2023/11/22/a4718c0bb76ea6a428a0bb204e805c9e.jpeg" style="width:400px;"/></div></div><p>但是你会发现只有一行terminal的文字出现在左上角，随后无事发生。这里就是我遇到的第一个坑了。解决方法参考：<a href="https://www.cnblogs.com/lifuqiang/articles/17167367.html">https://www.cnblogs.com/lifuqiang/articles/17167367.html</a></p><p>我们首先输入CTRL + ALT + F3，然后会要求我们登录，用户名输入root，密码输入自己之前设的那个</p><p>随后，依次输入命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/default</span><br><span class="line">sudo nano locale</span><br></pre></td></tr></table></figure><p>打开一个配置文件，将第一行改为 <code>LANG=en_US.UTF-8</code></p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picst.sunbangyan.cn/2023/11/22/37e17dd85531240de5b51dc37f3c1a6c.jpeg" style="width:800px;"/></div></div><p>按 CTRL+X，然后 Y，回车，然后再enter退出编辑</p><p>随后，再输入命令 <code>sudo locale-gen --purge</code>， 配置我们刚刚修改的设置</p><p>然后输入命令 <code>reboot</code> 重启虚拟机，现在我们就可以windows键打开搜索，输入terminal然后启动了。（原来乱码的日期也恢复了）</p><h2 id="给用户sudo权限"><a href="#给用户sudo权限" class="headerlink" title="给用户sudo权限"></a>给用户sudo权限</h2><p>参考：<a href="https://blog.csdn.net/Moelimoe/article/details/105292219">https://blog.csdn.net/Moelimoe/article/details/105292219</a></p><p>目前你创建的用户是没有超级权限的，而mininet的使用又必须要超级权限，之后会遇到各种问题。干脆直接给用户超级权限好了。</p><p>首先打开命令行，<code>su root</code> 进入root用户，然后输入命令 <code>sudo adduser &lt;user_id&gt; sudo</code> ，填入自己的用户名即可，之后你的账号就有sudo权限了，操作也不用进root。</p><h1 id="配置mininet"><a href="#配置mininet" class="headerlink" title="配置mininet"></a>配置mininet</h1><h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><p>刚配好的环境什么也没有，git也需要安装，命令行输入 <code>sudo apt install git</code></p><p>然后 <code>git clone https://gitee.com/derekwin/mininet.git</code> ，原仓库下载会卡住，并且有一些怪问题，这边我们利用别人的镜像源（参考：<a href="https://zhuanlan.zhihu.com/p/576832894）">https://zhuanlan.zhihu.com/p/576832894）</a></p><h2 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h2><p>想不到吧，pip也没有，我们还需要先安装pip，否则之后会报错。</p><p>命令： <code>sudo apt-get install python3-pip</code></p><h2 id="安装mininet"><a href="#安装mininet" class="headerlink" title="安装mininet"></a>安装mininet</h2><p>随后，我们需要输入命令 <code>PYTHON=python3 mininet/util/install.sh -a</code>，指定python3是因为较新版本的ubuntu默认只有python3环境，且没有/usr/bin/python，之后安装时会报错。</p><p>这步有可能因为网络问题卡住而获取失败，我的建议是多试几次。没什么办法。</p><p>安装过程比较长，需要等待</p><p>出现Enjoy Mininet!就是成功了</p><p>之后再输入一行命令 <code>sudo apt-get install mininet</code>，一切大功告成。</p><h2 id="下载iperf3"><a href="#下载iperf3" class="headerlink" title="下载iperf3"></a>下载iperf3</h2><p>后续实验还需要两个小插件，我们输入 <code>sudo apt-get install iperf3</code> 安装</p><p>还有一个iperf3-plotter，但是助教给的git根本download不下来（<code>git clone git://github.com/ekfoury/iperf3_plotter.git</code>），很难蚌。</p><p>可以直接去 <a href="https://github.com/ekfoury/iperf3_plotter.git">https://github.com/ekfoury/iperf3_plotter.git</a> 下载压缩包，解压</p><p>随后我们回到VirtualBox的管理页面，在我们配置的Ubuntu环境下，我们首先需要修改一下设置。修改设置需要在关闭虚拟机的情况下启动</p><p>在”设置-&gt;存储”中，我们需要对空的”控制器:IDE”下添加一个盘，点击右侧的”属性-&gt;分配光驱”右边的那个小图标，选择”选择虚拟盘”，找到VirtualBox安装时自带的一个虚拟盘即可</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/11/22/e57a184a662d19a18808481cca0bc9f3.jpeg" style="width:800px;"/></div></div><p>之后退回管理页面，我们需要先启动虚拟机。然后我们就可以在右下角输入用户名密码登录，并且传文件。左边是windows下的文件系统，右边是ubuntu中的。我们选择需要的文件，点击中间的图标中下面那个，就可以把文件传到虚拟机中了。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/11/22/99c0d3389c8071cdf4d9ab1cee89cd2a.jpeg" style="width:800px;"/></div></div><p>随后在虚拟系统中命令行进入文件夹iperf3_plotter-master，然后 <code>sudo make</code>，就可以了</p><h1 id="END"><a href="#END" class="headerlink" title="END"></a>END</h1><p>之后的实验部分比较简单，就不另外记录了，引导也还可以。</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Computer Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Notes </tag>
            
            <tag> Computer Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FDU Operating System Lab4</title>
      <link href="/posts/10018.html"/>
      <url>/posts/10018.html</url>
      
        <content type="html"><![CDATA[<h1 id="RISC-V-实验"><a href="#RISC-V-实验" class="headerlink" title="RISC-V 实验:"></a>RISC-V 实验:</h1><h3 id="1-Which-registers-contain-arguments-to-functions-For-example-which-register-holds-13-in-main’s-call-to-printf"><a href="#1-Which-registers-contain-arguments-to-functions-For-example-which-register-holds-13-in-main’s-call-to-printf" class="headerlink" title="1. Which registers contain arguments to functions? For example, which register holds 13 in main’s call to printf?"></a>1. Which registers contain arguments to functions? For example, which register holds 13 in main’s call to printf?</h3><p>在推荐阅读材料《Calling Convention》中，有提到：</p><p>“The RISC-V calling convention passes arguments in registers when possible. Up to eight integer registers, a0–a7, and up to eight floating-point registers, fa0–fa7, are used for this purpose.” </p><p>所以，向函数传递参数的寄存器是 <code>a0-a7</code> 和 <code>fa0-fa7</code>. 在调用 printf 的时候，13 被放在了寄存器 a2 中 <code>(24: 4635 li a2,13)</code></p><h3 id="2-Where-is-the-call-to-function-f-in-the-assembly-code-for-main-Where-is-the-call-to-g-Hint-the-compiler-may-inline-functions"><a href="#2-Where-is-the-call-to-function-f-in-the-assembly-code-for-main-Where-is-the-call-to-g-Hint-the-compiler-may-inline-functions" class="headerlink" title="2. Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)"></a>2. Where is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)</h3><p><code>main</code> 函数应该是在 <code>printf</code> 中调用了函数 <code>f</code>，但是通过查看汇编代码，我们发现本应调用函数 <code>f</code> 的地方，<code>main</code> 函数直接读取了参数 12 <code>(24: 45b1 li a1,12)</code>，可以想到是函数 f 和函数 g 太简单了，直接被编译器优化掉了。</p><h3 id="3-At-what-address-is-the-function-printf-located"><a href="#3-At-what-address-is-the-function-printf-located" class="headerlink" title="3. At what address is the function printf located?"></a>3. At what address is the function printf located?</h3><p>由<code>(34:61a080e7 jalr 1562(ra) # 64a &lt;printf&gt;)</code>这句，应该是在 <code>0x64a</code> 的位置，其中 <code>ra</code> 是上一行使用 <code>(30: 00000097 auipc ra,0x0)</code> 获取的这行代码的地址 <code>0x30</code>，然后 <code>jalr</code> 的目标地址就是 1562(十进制) + 0x30 = 0x64a，我们把代码往下翻到 <code>0x64a</code> 的地方，也确实是 <code>printf</code> 函数的起始地址。</p><h3 id="4-What-value-is-in-the-register-ra-just-after-the-jalr-to-printf-in-main"><a href="#4-What-value-is-in-the-register-ra-just-after-the-jalr-to-printf-in-main" class="headerlink" title="4. What value is in the register ra just after the jalr to printf in main?"></a>4. What value is in the register ra just after the jalr to printf in main?</h3><p>参考阅读材料：</p><p>“The indirect jump instruction JALR (jump and link register) uses the I-type encoding. The target address is obtained by adding the sign-extended 12-bit I-immediate to the register rs1, then setting the least-significant bit of the result to zero. The address of the instruction following the jump (pc+4) is written to register rd.Register x0 can be used as the destination if the result is not required.” </p><p>所以，应该 ra 里存的是 pc+4，也就是 <code>0x38</code></p><h3 id="5-Run-the-following-code-unsigned-int-i-0x00646c72-printf-“H-x-Wo-s”-57616-amp-i"><a href="#5-Run-the-following-code-unsigned-int-i-0x00646c72-printf-“H-x-Wo-s”-57616-amp-i" class="headerlink" title="5. Run the following code. unsigned int i = 0x00646c72; printf(“H%x Wo%s”, 57616, &amp;i)"></a>5. Run the following code. unsigned int i = 0x00646c72; printf(“H%x Wo%s”, 57616, &amp;i)</h3><p>输出：HE110 World</p><p>前面这个%x 是以 16 进制输出 57616(十进制)，就是 E110；后面因为 risc-v 采用 little-endian 存<br>储数据，所以输出的时候是 <code>72, 6c, 64, 00</code>，对应的字符就是 <code>r l d \0</code>，如果是 big-endian, i 就应该<br>是 <code>0x726c6400</code>，<code>57616</code> 不用变。</p><h3 id="6-In-the-following-code-what-is-going-to-be-printed-after-‘y-’-note-the-answer-is-not-a-specific-value-Why-does-this-happen-printf-“x-d-y-d”-3"><a href="#6-In-the-following-code-what-is-going-to-be-printed-after-‘y-’-note-the-answer-is-not-a-specific-value-Why-does-this-happen-printf-“x-d-y-d”-3" class="headerlink" title="6. In the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen?  printf(“x=%d y=%d”, 3);"></a>6. In the following code, what is going to be printed after ‘y=’? (note: the answer is not a specific value.) Why does this happen?  printf(“x=%d y=%d”, 3);</h3><p>输出：x=3 y=8229</p><p>前面一个正常输出 3，y 这个没传参数，会输出一个奇怪的值。看汇编码的话，printf(“x=%d y=%d”, 3) 会比 printf(“x=%d y=%d”, 3, 4) 少一句 <code>li a2,4</code>，其余汇编码都是一样的。我猜就是没传参数的话，y 也会输出 a2 寄存器里的内容，只不过寄存器里就是一个不确定的值了。</p><h1 id="BACKTRACE实验"><a href="#BACKTRACE实验" class="headerlink" title="BACKTRACE实验"></a>BACKTRACE实验</h1><p>backtrace函数的目的是递归读取每个函数调用栈，依次打印返回地址</p><p>我们先来看一下本次的测试程序 <code>/user/bttest</code> ，比较朴素，就调用了一个sleep()的system call</p><p>所以我们要在 <code>kernel/defs.h</code> 头文件中注册backtrace函数的原型，以便sys_sleep函数可以调用</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// printf.c</span></span><br><span class="line"><span class="type">void</span>            <span class="title function_">printf</span><span class="params">(<span class="type">char</span>*, ...)</span>;</span><br><span class="line"><span class="type">void</span>            <span class="title function_">panic</span><span class="params">(<span class="type">char</span>*)</span> __<span class="title function_">attribute__</span><span class="params">((<span class="keyword">noreturn</span>))</span>;</span><br><span class="line"><span class="type">void</span>            <span class="title function_">printfinit</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"><span class="type">void</span>            <span class="title function_">backtrace</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure><p>进一步按照提示，在 <code>kernel/riscv.h</code> 添加如下函数获取s0寄存器中保存的fp的值</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">inline</span> uint64 <span class="title function_">r_fp</span><span class="params">()</span> &#123;</span><br><span class="line">  uint64 x;</span><br><span class="line">  <span class="keyword">asm</span> <span class="title function_">volatile</span><span class="params">(<span class="string">&quot;mv %0, s0&quot;</span> : <span class="string">&quot;=r&quot;</span> (x) )</span>;</span><br><span class="line">  <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>kernel/sysproc.c</code> 的sys_sleep()中调用backtrace()</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">uint64</span><br><span class="line"><span class="title function_">sys_sleep</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> n;</span><br><span class="line">  uint ticks0;</span><br><span class="line"></span><br><span class="line">  backtrace();</span><br><span class="line"></span><br><span class="line">  argint(<span class="number">0</span>, &amp;n);</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="backtrace函数实现"><a href="#backtrace函数实现" class="headerlink" title="backtrace函数实现"></a>backtrace函数实现</h2><p>我们可以先看 <a href="https://pdos.csail.mit.edu/6.1810/2022/lec/l-riscv.txt">https://pdos.csail.mit.edu/6.1810/2022/lec/l-riscv.txt</a> 中对函数调用栈的结构的介绍</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Stack</span><br><span class="line">                   .</span><br><span class="line">                   .</span><br><span class="line">      +-&gt;          .</span><br><span class="line">      |   +-----------------+   |</span><br><span class="line">      |   | return address  |   |</span><br><span class="line">      |   |   previous fp ------+</span><br><span class="line">      |   | saved registers |</span><br><span class="line">      |   | local variables |</span><br><span class="line">      |   |       ...       | &lt;-+</span><br><span class="line">      |   +-----------------+   |</span><br><span class="line">      |   | return address  |   |</span><br><span class="line">      +------ previous fp   |   |</span><br><span class="line">          | saved registers |   |</span><br><span class="line">          | local variables |   |</span><br><span class="line">      +-&gt; |       ...       |   |</span><br><span class="line">      |   +-----------------+   |</span><br><span class="line">      |   | return address  |   |</span><br><span class="line">      |   |   previous fp ------+</span><br><span class="line">      |   | saved registers |</span><br><span class="line">      |   | local variables |</span><br><span class="line">      |   |       ...       | &lt;-+</span><br><span class="line">      |   +-----------------+   |</span><br><span class="line">      |   | return address  |   |</span><br><span class="line">      +------ previous fp   |   |</span><br><span class="line">          | saved registers |   |</span><br><span class="line">          | local variables |   |</span><br><span class="line">  $fp --&gt; |       ...       |   |</span><br><span class="line">          +-----------------+   |</span><br><span class="line">          | return address  |   |</span><br><span class="line">          |   previous fp ------+</span><br><span class="line">          | saved registers |</span><br><span class="line">  $sp --&gt; | local variables |</span><br><span class="line">          +-----------------+</span><br></pre></td></tr></table></figure><p>每个函数使用一个栈帧，栈从高地址向低地址生长。由图，我们可以明白，每个栈帧的起始地址由fp给出（通过 <code>r_fp()</code> 获取），fp-8 就是返回地址，fp-16 就是前一个函数的栈帧的fp。</p><p>所以我们只要递归地打印信息就可以了，至于终止条件，根据提示我们可以参看 <code>kernel/riscv.h</code> 中的PGROUNDUP(fp)或PGROUNDDOWN(fp)函数</p><p>多个函数的栈帧都在同一个页面中，无论fp指针指向哪个函数的栈帧，PGROUNDUP(fp) 和 PGROUNDDOWN(fp)都是固定不变的，且有PGROUNDUP(fp) - PGROUNDDOWN(fp) = PGSIZE。而当 fp 指向当前页的起始地址时，会有PGROUNDUP(fp) = PGROUNDDOWN(fp)，此时循环终止。</p><p>在 <code>kernel/printf.c</code> 中<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> </span><br><span class="line"><span class="title function_">backtrace</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;barcktrace:\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">  uint64 ra, fp = r_fp();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span>(PGROUNDUP(fp) - PGROUNDDOWN(fp) == PGSIZE)</span><br><span class="line">  &#123;</span><br><span class="line">    ra = *((uint64*)(fp - <span class="number">8</span>));</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%p\n&quot;</span>, ra);</span><br><span class="line">    fp = *((uint64*)(fp - <span class="number">16</span>));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在调用完bttest后退出qemu，执行addr2line -e kernel/kernel，查看返回地址在代码中的位置</p><p>执行命令：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">addr2line -e kernel/kernel</span><br><span class="line"><span class="number">0</span>x000000008000212c</span><br><span class="line"><span class="number">0</span>x000000008000201e</span><br><span class="line"><span class="number">0</span>x0000000080001d14</span><br></pre></td></tr></table></figure></p><p>得到结果：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/root/Desktop/xv6-labs-<span class="number">2022</span>/kernel/sysproc.c:<span class="number">59</span></span><br><span class="line">/root/Desktop/xv6-labs-<span class="number">2022</span>/kernel/syscall.c:<span class="number">141</span></span><br><span class="line">/root/Desktop/xv6-labs-<span class="number">2022</span>/kernel/trap.c:<span class="number">76</span></span><br></pre></td></tr></table></figure></p><h1 id="Alarm实验"><a href="#Alarm实验" class="headerlink" title="Alarm实验"></a>Alarm实验</h1><p>首先我们需要一些准备工作，添加两个系统调用 <code>sys_sigalarm</code> 和 <code>sys_sigreturn</code> ，可以参看Lab2的操作</p><p>修改一下Makefile文件来编译alarmtest.c</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">UPROGS=\</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">$U/_zombie\</span><br><span class="line">    $U/_alarmtest\</span><br></pre></td></tr></table></figure><p>在 <code>user/user.h</code> 中添加系统调用声明</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// system calls</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sigalarm</span><span class="params">(<span class="type">int</span> ticks, <span class="type">void</span> (*handler)())</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">sigreturn</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure><p>在 <code>kernel/syscall.h</code> 中，添加两个宏定义</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> SYS_sigalarm 22</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SYS_sigreturn 23</span></span><br></pre></td></tr></table></figure><p>在 <code>kernel/syscall.c</code> 指定系统调用的主体函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> uint64 <span class="title function_">sys_sigalarm</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"><span class="keyword">extern</span> uint64 <span class="title function_">sys_sigreturn</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="title function_">uint64</span> <span class="params">(*syscalls[])</span><span class="params">(<span class="type">void</span>)</span> = &#123;</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">[SYS_sigalarm] sys_sigalarm,</span><br><span class="line">[SYS_sigreturn] sys_sigreturn,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>user/usys.pl</code> 中添加系统调用的存根</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">entry(<span class="string">&quot;sigalarm&quot;</span>);</span><br><span class="line">entry(<span class="string">&quot;sigreturn&quot;</span>);</span><br></pre></td></tr></table></figure><p>以上就做完函数调用的准备了，接下来，先实现 <code>sys_sigalarm()</code> 函数</p><p>修改 <code>kernel/proc.h</code> 中的proc结构体，添加sigalarm的两个参数(时间间隔n、调用函数fn)，还需要记录从上次调用sigalarm后经过的时间间隔ticks</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> n; <span class="comment">// the alarm interval</span></span><br><span class="line"><span class="type">int</span> ticks;</span><br><span class="line">uint64 fn; <span class="comment">// the pointer to the handler function</span></span><br></pre></td></tr></table></figure><p>在 <code>kernel/proc.c</code> 中的allocproc()函数中初始化新加的参数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">found:</span><br><span class="line">  p-&gt;pid = allocpid();</span><br><span class="line">  p-&gt;state = USED;</span><br><span class="line">  p-&gt;n = <span class="number">0</span>;</span><br><span class="line">  p-&gt;ticks = <span class="number">0</span>;</span><br><span class="line">  p-&gt;fn = <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>在 <code>kernel/sysproc.c</code> 中实现 <code>sys_sigalarm()</code> 函数(暂时 <code>sys_sigreturn</code> 只返回0)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">uint64</span><br><span class="line"><span class="title function_">sys_sigalarm</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  <span class="type">int</span> n;</span><br><span class="line">  uint64 fn;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">p</span> =</span> myproc();</span><br><span class="line"></span><br><span class="line">  argint(<span class="number">0</span>,&amp;n);</span><br><span class="line">  argaddr(<span class="number">1</span>,&amp;fn);</span><br><span class="line"></span><br><span class="line">  p-&gt;n = n;</span><br><span class="line">  p-&gt;fn = fn;</span><br><span class="line">  p-&gt;ticks = <span class="number">0</span>;  </span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">uint64</span><br><span class="line"><span class="title function_">sys_sigreturn</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>修改 <code>kernel/trap.c</code> 对时间中断的处理，如果是时钟中断（which_dev==2），就增加记录的中断数。如果中断数到达指定间隔，就将处理函数fn的指针传给epc，以执行处理函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(which_dev == <span class="number">2</span>) </span><br><span class="line">&#123;</span><br><span class="line">  p-&gt;ticks++;</span><br><span class="line">  <span class="keyword">if</span>(p-&gt;ticks == p-&gt;n) &#123;</span><br><span class="line">    p-&gt;trapframe-&gt;epc = p-&gt;fn; </span><br><span class="line">    p-&gt;ticks = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  yield();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="实现sys-sigreturn"><a href="#实现sys-sigreturn" class="headerlink" title="实现sys_sigreturn"></a>实现sys_sigreturn</h2><p>这个函数调用要求我们在时钟中断返回后，能够回到原来的状态。</p><p>根据hint，我们需要在sys_sigalarm()中保存中断时的寄存器值</p><p>所以，在 <code>kernel/proc.h</code> 中的proc结构体加上相关信息，不妨直接设置一个备份的trapframe（包含所有寄存器的值）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">trapframe</span> *<span class="title">backup</span>;</span>    <span class="comment">// Save registers</span></span><br><span class="line"><span class="type">int</span> cur_fn;                  <span class="comment">// Prevent repetitive calls to the handler function(test2 要用)</span></span><br></pre></td></tr></table></figure><p>这样，在调用sigreturn时，我们只需要把backup复制回原来的trapframe即可，同时设cur_fn为0表示时钟中断处理函数结束；hint4也提醒我们要把返回值设为a0的值。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">uint64 </span><br><span class="line"><span class="title function_">sys_sigreturn</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span>* <span class="title">p</span> =</span> myproc();</span><br><span class="line">  *p-&gt;trapframe = *p-&gt;backup;</span><br><span class="line">  p-&gt;cur_fn = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">return</span> p-&gt;backup-&gt;a0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后对应的时钟中断处理函数，加一个 <code>if(p-&gt;cur_fn == 0)</code> 判断不会重复调用，还有就是复制原来的trapframe。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(which_dev == <span class="number">2</span>) </span><br><span class="line">&#123;</span><br><span class="line">  p-&gt;ticks++;</span><br><span class="line">  <span class="keyword">if</span>(p-&gt;ticks == p-&gt;n &amp;&amp; p-&gt;cur_fn == <span class="number">0</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    *p-&gt;backup = *p-&gt;trapframe;</span><br><span class="line">    p-&gt;trapframe-&gt;epc = p-&gt;fn;</span><br><span class="line">    p-&gt;ticks = <span class="number">0</span>;</span><br><span class="line">    p-&gt;cur_fn = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  yield();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其它还有一些细节部分，该分配内存和释放内存的地方，参考原本有的部分</p><p>在 <code>kernel/proc.c</code> 的 <code>allocproc</code> 中，给新加的两个变量分配内存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">p-&gt;cur_fn = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>((p-&gt;backup = (<span class="keyword">struct</span> trapframe *)kalloc()) == <span class="number">0</span>)&#123;</span><br><span class="line">  freeproc(p);</span><br><span class="line">  release(&amp;p-&gt;lock);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>freeproc</code> 中释放内存：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(p-&gt;backup) </span><br><span class="line">  kfree((<span class="type">void</span>*) p-&gt;backup);</span><br><span class="line">p-&gt;backup = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">p-&gt;n = <span class="number">0</span>;</span><br><span class="line">p-&gt;ticks = <span class="number">0</span>;</span><br><span class="line">p-&gt;fn = <span class="number">0</span>;</span><br><span class="line">p-&gt;cur_fn = <span class="number">0</span>;</span><br><span class="line">p-&gt;state = UNUSED;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Operating System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Notes </tag>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记（三） LSTM</title>
      <link href="/posts/10012.html"/>
      <url>/posts/10012.html</url>
      
        <content type="html"><![CDATA[<p>参考：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a> ，写得非常详细，有精致的图例和清楚的公式，建议先阅读该篇文章</p><p class='p left logo large'>基本概念</p><p>LSTM，长短期记忆神经网络，它克服了RNN难以记录长期信息的特点。</p><p>举个例子，“天上红色的是__”，RNN可以一定程度上利用“天上”、“红色”等信息来预测当前应填的单词，可能是“太阳”。</p><p>但是，如果有效信息相隔非常远，例如：“我是一个中国人，……，我会说___，英语和日语”，这些久远的信息很难留存在RNN的hidden state中。</p><p>LSTM在结构上做出了改进，如下图所示。它包含两种hidden state，一个是上方的$C_t$，它代表着模型的记忆，在训练过程中改动较少，一个是下方的$h_t$，代表着输入内容的抽象信息（？也许，其实没有这么明确的物理意义，只是我期望可以这么认为）。它们通过一些方式互相影响并更新，下面一一介绍。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/10/18/a1e155b0ed13694af1700b3c732024b9.png" style="width:800px;"/></div></div><p class='p left logo large'>网络结构</p><h1 id="遗忘门"><a href="#遗忘门" class="headerlink" title="遗忘门"></a>遗忘门</h1><p>LSTM的第一步是决定要让长期记忆$C_{t-1}$去遗忘什么。它拼接当前输入$x_t$和上一时刻的状态$h_{t-1}$，并送入sigmoid层，得到一个介于0与1之间的输出向量。随后，和$C_{t-1}$做Hadamard积。如果sigmoid层对应输出越接近0，则对应信息遗忘得越多，反之则继续记忆。</p><p>形象化的理解可能就是，用当前状态去判断哪些记忆不再适用了，比如说之前还一直在谈论A，现在突然转到谈论B了，一些有关A的信息就不再需要了。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdm.sunbangyan.cn/2023/10/19/9e11a5f3e9ea43fa9bb0538dbcc869e5.png" style="width:800px;"/></div></div><h1 id="输入门"><a href="#输入门" class="headerlink" title="输入门"></a>输入门</h1><p>第二步是决定要让$C_{t-1}$记住什么。当前输入首先会经过一个sigmoid层得到$i_t$，这决定了接下来哪些信息是有必要被记住的。实际上的更新向量$\tilde{C_t}$是通过tanh激活函数得到的，至于为什么选tanh，我找到了一些说法：（来自：<a href="https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm）">https://stackoverflow.com/questions/40761185/what-is-the-intuition-of-using-tanh-in-lstm）</a></p><ul><li><p>为了防止梯度消失问题，我们需要一个二次导数在大范围内不为0的函数，而tanh函数可以满足这一点</p></li><li><p>为了便于凸优化，我们需要一个单调函数</p></li><li><p>tanh函数一般收敛的更快</p></li><li><p>tanh函数的求导占用系统的资源更少</p></li></ul><p>随后，$i_t$与$\tilde{C_t}$相乘，得到正式的update内容。</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picdm.sunbangyan.cn/2023/10/19/59ab5d4957ad6e60f3984257d96245f5.png" style="width:800px;"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picst.sunbangyan.cn/2023/10/19/65e1a37f0d9e047776f1a0b0f6e228c7.png" style="width:800px;"/></div></div><h1 id="输出门"><a href="#输出门" class="headerlink" title="输出门"></a>输出门</h1><p>我们要决定输出什么内容。总之就是输入经过一个sigmoid层，加上记忆$C_{t}$的影响（经过tanh），</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picss.sunbangyan.cn/2023/10/19/a3243ac1c491e8b184bc8912621828af.png" style="width:800px;"/></div></div><p class='p left logo large'>代码</p><h1 id="自己实现"><a href="#自己实现" class="headerlink" title="自己实现"></a>自己实现</h1><p>先不用PyTorch定义好的LSTM，直接根据网络结构一步步从头搭建一个</p><p>注意到原来公式中有一步拼接$h_{t-1}$和$x_t$的操作，然后和权重矩阵$W$相乘。由线性代数知识，我们完全可以把$W \cdot [h_{t-1},x_t]$ 变成 $U \cdot x_t + V \cdot h_{t-1}$</p><p>这样，原来LSTM中的三个sigmoid层，一个tanh层的公式就应该是：</p><script type="math/tex; mode=display">\begin{equation}\left\{    \begin{array}{ll}      f_t &= \sigma(U_f \cdot x_t + V_f \cdot h_{t-1} + b_f) \\          i_t &= \sigma(U_i \cdot x_t + V_i \cdot h_{t-1} + b_i) \\      \tilde{C_t} &= \sigma(U_c \cdot x_t + V_c \cdot h_{t-1} + b_c) \\      o_t &= \sigma(U_o \cdot x_t + V_o \cdot h_{t-1} + b_o)    \end{array}\right. \notag\end{equation}</script><p>现在需要理清楚一下维度：</p><p>输入 $x$ 应该是 [batch_size, sequence_len(时间序列长度), feature_size]</p><p>这样 $x_t$ 就是 [feature_size]， 同理 $h_t$ 是 [hidden_size]</p><p>所以需要训练的参数为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">myLstm</span>(nn.Module):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_sz, hidden_sz</span>):</span><br><span class="line">    <span class="built_in">super</span>().__init__()</span><br><span class="line">    self.input_size = input_sz</span><br><span class="line">    self.hidden_size = hidden_sz</span><br><span class="line"></span><br><span class="line">    <span class="comment">#f_t</span></span><br><span class="line">    self.U_f = nn.Parameter(torch.Tensor(input_sz, hidden_sz))</span><br><span class="line">    self.V_f = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))</span><br><span class="line">    self.b_f = nn.Parameter(torch.Tensor(hidden_sz))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#i_t</span></span><br><span class="line">    self.U_i = nn.Parameter(torch.Tensor(input_sz,hidden_sz))</span><br><span class="line">    self.V_i = nn.Parameter(torch.Tensor(hidden_sz,hidden_sz))</span><br><span class="line">    self.b_i = nn.parameter(torch.Tensor(hidden_sz))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#c_t</span></span><br><span class="line">    self.U_c = nn.Parameter(torch.Tensor(input_sz, hidden_sz))</span><br><span class="line">    self.V_c = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))</span><br><span class="line">    self.b_c = nn.Parameter(torch.Tensor(hidden_sz))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#o_t</span></span><br><span class="line">    self.U_o = nn.Parameter(torch.Tensor(input_sz, hidden_sz))</span><br><span class="line">    self.V_o = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))</span><br><span class="line">    self.b_o = nn.Parameter(torch.Tensor(hidden_sz))</span><br></pre></td></tr></table></figure><p>前向传播定义如下：</p><p>在训练时，某些样本在时间上可能是连续的，而有些是不相干的，有时我们需要权重进行预测。我们可以通过参数init_states来决定是否要继承上次的最终输出$h_t$和$c_t$，还是直接重新初始化。</p><p>随后，遍历时间步，在整个时间序列遍历完后再更新权重。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, init_states=<span class="literal">None</span></span>):</span><br><span class="line">    batch_size,seq_sz,_=x.size()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> init_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">      h_t,c_t=(</span><br><span class="line">          torch.zeros(batch_size, self.hidden_size).to(x.device),</span><br><span class="line">          torch.zeros(batch_size, self.hidden_size).to(x.device)</span><br><span class="line">      )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      h_t, c_t = init_states</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_sz):</span><br><span class="line">      x_t = x[:, t, :]</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 和nn.parameter计算时，自动处理x的batch这一维度</span></span><br><span class="line">      i_t = torch.sigmoid(x_t @ self.U_i + h_t @ self.V_i + self.b_i)</span><br><span class="line">      f_t = torch.sigmoid(x_t @ self.U_f + h_t @ self.V_f + self.b_f)</span><br><span class="line">      g_t = torch.tanh(x_t @ self.U_c + h_t @ self.V_c + self.b_c)</span><br><span class="line">      o_t = torch.sigmoid(x_t @ self.U_o + h_t @ self.V_o + self.b_o)</span><br><span class="line">      c_t = f_t * c_t + i_t * g_t</span><br><span class="line">      h_t = o_t * torch.tanh(c_t)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h_t, c_t</span><br></pre></td></tr></table></figure><p>这样，我们能得到最后一次输出的权重。比如说要预测接下来16个时间步的内容，我们就可以利用这些数据，进一步在模型中forward，得到新的输出 $y_{pred}$，和真实的 $y$ 计算误差。</p><h1 id="进一步优化"><a href="#进一步优化" class="headerlink" title="进一步优化"></a>进一步优化</h1><p>注意到四个门的计算都是互相并行的，我们可以用一次矩阵运算来加速操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomLSTM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_sz, hidden_sz</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.input_sz = input_sz</span><br><span class="line">        self.hidden_size = hidden_sz</span><br><span class="line">        self.W = nn.Parameter(torch.Tensor(input_sz, hidden_sz * <span class="number">4</span>))</span><br><span class="line">        self.U = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz * <span class="number">4</span>))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(hidden_sz * <span class="number">4</span>))</span><br><span class="line">        self.init_weights()</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 初始化模型权重</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        stdv = <span class="number">1.0</span> / math.sqrt(self.hidden_size)</span><br><span class="line">        <span class="keyword">for</span> weight <span class="keyword">in</span> self.parameters():</span><br><span class="line">            weight.data.uniform_(-stdv, stdv)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, </span></span><br><span class="line"><span class="params">                init_states=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Assumes x is of shape (batch, sequence, feature)&quot;&quot;&quot;</span></span><br><span class="line">        bs, seq_sz, _ = x.size()</span><br><span class="line">        hidden_seq = []</span><br><span class="line">        <span class="keyword">if</span> init_states <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            h_t, c_t = (torch.zeros(bs, self.hidden_size).to(x.device), </span><br><span class="line">                        torch.zeros(bs, self.hidden_size).to(x.device))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            h_t, c_t = init_states</span><br><span class="line"> </span><br><span class="line">        HS = self.hidden_size</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(seq_sz):</span><br><span class="line">            x_t = x[:, t, :]</span><br><span class="line">            <span class="comment"># batch the computations into a single matrix multiplication</span></span><br><span class="line">            gates = x_t @ self.W + h_t @ self.U + self.bias</span><br><span class="line">            i_t, f_t, g_t, o_t = (</span><br><span class="line">                torch.sigmoid(gates[:, :HS]), <span class="comment"># input</span></span><br><span class="line">                torch.sigmoid(gates[:, HS:HS*<span class="number">2</span>]), <span class="comment"># forget</span></span><br><span class="line">                torch.tanh(gates[:, HS*<span class="number">2</span>:HS*<span class="number">3</span>]),</span><br><span class="line">                torch.sigmoid(gates[:, HS*<span class="number">3</span>:]), <span class="comment"># output</span></span><br><span class="line">            )</span><br><span class="line">            c_t = f_t * c_t + i_t * g_t</span><br><span class="line">            h_t = o_t * torch.tanh(c_t)</span><br><span class="line">            hidden_seq.append(h_t.unsqueeze(<span class="number">0</span>))</span><br><span class="line">        hidden_seq = torch.cat(hidden_seq, dim=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># reshape from shape (sequence, batch, feature) to (batch, sequence, feature)</span></span><br><span class="line">        hidden_seq = hidden_seq.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous()</span><br><span class="line">        <span class="keyword">return</span> hidden_seq, (h_t, c_t)</span><br></pre></td></tr></table></figure><p>我也不太清楚算出每一步的 hidden_seq 有什么用，为什么只存 $h_t$ 而不存 $C_t$ ？</p><p>问了 ChatGPT，它是这么回答 hidden_seq 的作用的：</p><ul><li><p>序列分类：如果你的任务是对整个序列进行分类，你可以使用 hidden_seq 中的最后一个时间步的隐藏状态 h_t 或者对整个序列的隐藏状态进行池化操作（例如平均池化或最大池化），然后将其传递给分类器进行分类预测。</p></li><li><p>序列标注：在自然语言处理中，你可以使用 hidden_seq 来生成每个时间步的标注结果，例如词性标注或命名实体识别。</p></li><li><p>序列生成：如果你的任务是生成新的序列，如文本生成，你可以使用 hidden_seq 作为生成器的输入，以生成接下来的序列内容。</p></li><li><p>注意力机制：hidden_seq 可用于计算注意力权重，以确定序列中不同时间步的重要性，然后对序列的不同部分进行加权汇总。</p></li><li><p>可视化和分析：hidden_seq 可以用于可视化和分析模型在输入序列上的学习过程。你可以查看隐藏状态的变化，了解模型如何处理不同时间步的信息。</p></li></ul><p>嗯，暂时还不理解。</p><h1 id="PyTorch-API"><a href="#PyTorch-API" class="headerlink" title="PyTorch API"></a>PyTorch API</h1><p>也可以直接调PyTorch的API，会方便很多</p><p>我们用 <a href="https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb">https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb</a> 中的例子来实践一下</p><p>十年飞机客流量数据：<a href="https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/data.csv">https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/data.csv</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">data_csv = pd.read_csv(<span class="string">&#x27;./data.csv&#x27;</span>, usecols=[<span class="number">1</span>])</span><br><span class="line">plt.plot(data_csv)</span><br></pre></td></tr></table></figure><p>数据如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picst.sunbangyan.cn/2023/10/19/ad2d62c0b67d9370b1e9fb4571081b17.png" style="width:800px;"/></div></div><p>我们的任务目标是通过前几个月的客流量数据去预测后几个月的客流量数据。比如说我们要用前两个月的数据去预测后一个月的数据。</p><p>首先进行数据处理，除掉空数据（虽然这个数据集里好像没有），然后执行归一化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据预处理</span></span><br><span class="line">data_csv = data_csv.dropna()</span><br><span class="line">dataset = data_csv.values</span><br><span class="line">dataset = dataset.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">max_value = np.<span class="built_in">max</span>(dataset)</span><br><span class="line">min_value = np.<span class="built_in">min</span>(dataset)</span><br><span class="line">scalar = max_value - min_value</span><br><span class="line">dataset = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x / scalar, dataset))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">dataset, look_back=<span class="number">2</span></span>):</span><br><span class="line">    dataX, dataY = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dataset) - look_back):</span><br><span class="line">        a = dataset[i:(i + look_back)]</span><br><span class="line">        dataX.append(a)</span><br><span class="line">        dataY.append(dataset[i + look_back])</span><br><span class="line">    <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建好输入输出</span></span><br><span class="line">data_X, data_Y = create_dataset(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集，70% 作为训练集</span></span><br><span class="line">train_size = <span class="built_in">int</span>(<span class="built_in">len</span>(data_X) * <span class="number">0.7</span>)</span><br><span class="line">test_size = <span class="built_in">len</span>(data_X) - train_size</span><br><span class="line">train_X = data_X[:train_size]</span><br><span class="line">train_Y = data_Y[:train_size]</span><br><span class="line">test_X = data_X[train_size:]</span><br><span class="line">test_Y = data_Y[train_size:]</span><br></pre></td></tr></table></figure><p>看下网络的定义，先来介绍一下 <code>nn.LSTM</code> 的参数：</p><ul><li>input_size – 输入的特征维度</li><li>hidden_size – 隐状态的特征维度</li><li>num_layers – 堆叠LSTM的层数</li><li>batch_first – 如果为True，那么输入和输出Tensor的形状为(batch, seq, feature)，默认为false，是(seq, batch, feature)</li><li>bidirectional – 是否双向传播，默认为False</li></ul><p>LSTM输出: output, (h_n, c_n)</p><p>output (seq_len, batch, hidden_size <em> num_directions):LSTM的输出序列，对于每个时间步，它包含了每个样本的隐藏状态。<br>h_n (num_layers </em> num_directions, batch, hidden_size):保存着LSTM最后一个时间步的隐状态<br>c_n (num_layers * num_directions, batch, hidden_size):保存着LSTM最后一个时间步的细胞状态</p><p>其中 h_n 应该就是 output[-1] （最后一项）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例</span></span><br><span class="line">lstm = nn.LSTM(<span class="number">10</span>, <span class="number">512</span>, <span class="number">2</span>, bidirectional=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>所以，我们要把输入的数据先做一下维度变换：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">train_X = train_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">train_Y = train_Y.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">test_X = test_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">train_x = torch.from_numpy(train_X)</span><br><span class="line">train_y = torch.from_numpy(train_Y)</span><br><span class="line">test_x = torch.from_numpy(test_X)</span><br></pre></td></tr></table></figure><p>然后我们定义模型，开始训练。</p><p>注意最后一层线性层，我们需要把当前的输出hidden_size转化成我们需要的output_size。</p><p>线性层一般接收一个二维输入，忽略第一维的batch_size，转换hidden_size，不过因为前面一层是LSTM的输出，所以是三维的，我们不妨把batch_size和seq_len先“拼起来”，毕竟我们的目的只是想把隐藏层输出转化为目标输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">lstm_reg</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size=<span class="number">1</span>, num_layers=<span class="number">2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.lstm = nn.LSTM(input_size, hidden_size, num_layers) <span class="comment"># lstm</span></span><br><span class="line">        self.reg = nn.Linear(hidden_size, output_size) <span class="comment"># 回归</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x, _ = self.lstm(x) <span class="comment"># (seq, batch, hidden)</span></span><br><span class="line">        s, b, h = x.shape</span><br><span class="line">        x = x.view(s*b, h) <span class="comment"># 转换成线性层的输入格式</span></span><br><span class="line">        x = self.reg(x)</span><br><span class="line">        x = x.view(s, b, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = lstm_reg(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    var_x = Variable(train_x)</span><br><span class="line">    var_y = Variable(train_y)</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    out = model(var_x)</span><br><span class="line">    loss = criterion(out, var_y)</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    if (e + 1) % 100 == 0: # 每 100 次输出结果</span></span><br><span class="line"><span class="string">        print(&#x27;Epoch: &#123;&#125;, Loss: &#123;:.5f&#125;&#x27;.format(e + 1, loss.data[0]))</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Step:&#x27;</span>, <span class="string">&#x27;%04d&#x27;</span> % (step + <span class="number">1</span>), <span class="string">&#x27;cost =&#x27;</span>, <span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(loss))</span><br></pre></td></tr></table></figure><p>训练好之后，我们就可以去做预测了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">net = net.<span class="built_in">eval</span>() <span class="comment"># 转换成测试模式</span></span><br><span class="line"></span><br><span class="line">data_X = data_X.reshape(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">data_X = torch.from_numpy(data_X)</span><br><span class="line">var_data = Variable(data_X)</span><br><span class="line">pred_test = net(var_data) <span class="comment"># 测试集的预测结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改变输出的格式</span></span><br><span class="line">pred_test = pred_test.view(-<span class="number">1</span>).data.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画出实际结果和预测的结果</span></span><br><span class="line">plt.plot(pred_test, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">plt.plot(dataset, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;real&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;best&#x27;</span>)</span><br></pre></td></tr></table></figure><p>结果如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://picst.sunbangyan.cn/2023/10/19/04bdfe4d9588f5405fd426ac51d32979.png" style="width:800px;"/></div></div><p class='p left logo large'>参考链接</p><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><p><a href="https://zhuanlan.zhihu.com/p/451985132">https://zhuanlan.zhihu.com/p/451985132</a></p><p><a href="https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb">https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/blob/master/chapter5_RNN/time-series/lstm-time-series.ipynb</a></p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记（二） CNN</title>
      <link href="/posts/10011.html"/>
      <url>/posts/10011.html</url>
      
        <content type="html"><![CDATA[<p>这次来用PyTorch实现一下CNN卷积神经网络, 数据我们采用 MNIST 这个手写数字识别的数据库, 完成一个多分类任务（判断是哪个数字）</p><p>不清楚PyTorch基本用法请移步 <a href="https://anti-entrophic.github.io/posts/10010.html">https://anti-entrophic.github.io/posts/10010.html</a></p><p class='p left logo large'>概述</p><p>最简单的CNN的结构是 “-&gt;卷积层-&gt;激活函数-&gt;池化层-&gt;线性层”，这里先简单介绍一下，后面会配合代码详细描述。</p><p>卷积层目标就是训练若干个卷积核，期望这些卷积核能够学到图像的某些特征。图像的各个通道会通过各个卷积核，得到卷积操作后的结果，然后经过ReLU激活函数。</p><p>池化层就如下图，目的是为了给图像降维，减少参数，并且期望能够捕捉一些关键特征，忽略不重要的细节</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://pic1.zhimg.com/80/v2-6091b01b4e85b1c23f3b7cf9f1496c90_1440w.webp" style="width:400px;"/></div></div><p>最后压缩维度后经过一个线性层，得到最终结果的概率分布，然后利用交叉熵损失函数来进行优化。</p><p>更详细的：<a href="https://zhuanlan.zhihu.com/p/630695553">https://zhuanlan.zhihu.com/p/630695553</a></p><p class='p left logo large'>数据</p><p>我们可以很方便的通过 <code>torchvision</code> 这个包下载到 MNIST 这个数据库</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">train_data = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">&#x27;./MNIST/&#x27;</span>,</span><br><span class="line">    train = <span class="literal">True</span>,</span><br><span class="line">    transform = torchvision.transforms.ToTensor(),</span><br><span class="line">    download = <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.MNIST(root=<span class="string">&#x27;./MNIST/&#x27;</span>, train=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>这样下载下来一个是训练集，一个是验证集。并且下载下来就是 <code>torch.utils.data.Dataset</code> 类，可以很好地适配 PyTorch 中常用的 Dataloader</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_loader = Data.DataLoader(</span><br><span class="line">    dataset = train_data,</span><br><span class="line">    batch_size = <span class="number">50</span>,</span><br><span class="line">    shuffle = <span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>Dataloader</code> 可以很方便地完成将数据组成batch，随机取样等操作。</p><p>可以简单看一下 MNIST 这个数据集，每张图片的大小都是 28*28，训练样本有60000个，测试样本有10000个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_data.data.shape)</span><br><span class="line"><span class="built_in">print</span>(test_data.data.shape)</span><br><span class="line"><span class="comment"># -----output-----</span></span><br><span class="line"><span class="comment"># torch.Size([60000, 28, 28])</span></span><br><span class="line"><span class="comment"># torch.Size([10000, 28, 28])</span></span><br></pre></td></tr></table></figure><p class='p left logo large'>网络结构</p><p>卷积层的输入是三维的，第一维是图像的通道数。</p><p>这个 <code>nn.Conv2d</code> ，<code>in_channels</code>就是输入图像的通道数，灰度图像就是1，RGB图像就是3。<code>output_channels</code>就是卷积核数，也是输出图像的通道数。</p><p>如果<code>in_channels</code>是3的话，那对每个卷积核，都是对3个通道各自卷积，然后加起来，会得到16个卷积后的通道，最后合在一起。</p><p><code>kernel_size</code> 就是卷积核的大小，<code>stride</code> 是卷积核移动的步长，<code>padding</code> 是周围补0，控制卷积后图像的大小。</p><p><code>ReLU()</code> 就激活一下，不过我有点疑惑的是，卷积操作完之后，会不会某些点的intensity超过255？因为这在图像中应该是不可能的情况，但是好像直接就没有处理；小于0的话经过ReLU()可以调回来。</p><p><code>nn.MaxPool2d</code> 就是一个池化层，如文章开头图片所示，取2x2格中的最大值。</p><p>最终第一层的维度变化为 (batch_size, 1, 28, 28) -&gt; (batch_size, 16, 14, 14)</p><p>第二层的维度变化为 (batch_size, 16, 14, 14) -&gt; (batch_size, 32, 7, 7)</p><p>线性层的维度变化为 -&gt; (batch, 32<em>7</em>7) -&gt; (batch, 10)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__() <span class="comment"># 在Python3中，不再需要显式地传递参数，会自动地识别当前类及其继承的父类，所以写super().__init__()更好</span></span><br><span class="line"></span><br><span class="line">        self.convl = nn.Sequential(</span><br><span class="line">            nn.Conv2d(</span><br><span class="line">                in_channels=<span class="number">1</span>,</span><br><span class="line">                out_channels=<span class="number">16</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>,</span><br><span class="line">                stride=<span class="number">1</span>,</span><br><span class="line">                padding=<span class="number">2</span></span><br><span class="line">            ),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(</span><br><span class="line">                kernel_size=<span class="number">2</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(</span><br><span class="line">                in_channels=<span class="number">16</span>,</span><br><span class="line">                out_channels=<span class="number">32</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>,</span><br><span class="line">                stride=<span class="number">1</span>,</span><br><span class="line">                padding=<span class="number">2</span></span><br><span class="line">            ),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(</span><br><span class="line">                kernel_size=<span class="number">2</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.out = nn.Linear(<span class="number">32</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.convl(x) <span class="comment"># (batch_size, 1, 28, 28) -&gt; (batch_size, 16, 14, 14)</span></span><br><span class="line">        x = self.conv2(x) <span class="comment"># (batch_size, 16, 14, 14) -&gt; (batch_size, 32, 7, 7)</span></span><br><span class="line">        x = x.view(x.shape[<span class="number">0</span>], -<span class="number">1</span>) <span class="comment"># (batch, 32*7*7)</span></span><br><span class="line">        x = self.out(x) <span class="comment"># (batch, 10)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p class='p left logo large'>网络训练</p><p>对于分类的概率分布，损失函数用交叉熵损失，原因我在其它文章中也提到过，详细链接：<a href="https://zhuanlan.zhihu.com/p/115277553">https://zhuanlan.zhihu.com/p/115277553</a></p><p>优化器没有用SGD而是Adam，不知道具体会有什么差异</p><p>只训练一个epoch</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = CNN()</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> step,(batch_x,batch_y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        pred_y = model(batch_x)</span><br><span class="line">        loss = criterion(pred_y, batch_y)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Step:&#x27;</span>, <span class="string">&#x27;%04d&#x27;</span> % (step + <span class="number">1</span>), <span class="string">&#x27;cost =&#x27;</span>, <span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(loss))</span><br><span class="line">        </span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure><p class='p left logo large'>结果</p><p>看一下结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这步unsqueeze让test_data从(10000,28,28)-&gt;(10000,1,28,28)，适配CNN的输入</span></span><br><span class="line">test_x = torch.unsqueeze(test_data.data,dim=<span class="number">1</span>).<span class="built_in">float</span>()[:<span class="number">2000</span>] </span><br><span class="line"><span class="comment"># 取出前2000个验证样本的标签</span></span><br><span class="line">test_y = test_data.targets[:<span class="number">2000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简单试一下前20个的输出结果</span></span><br><span class="line">test_output = model(test_x[:<span class="number">20</span>])</span><br><span class="line"><span class="comment"># 这里，test_output的维度是(20,10)，torch.max会返回两个值，一个是value，一个是index，index就代表着分类为哪个数字</span></span><br><span class="line"><span class="comment"># torch.max(_, 1) 表示沿着test_output的第1维也就是10这一维去找最大值，找的就是每一个概率分布中的最大值</span></span><br><span class="line">pred_y = torch.<span class="built_in">max</span>(test_output, <span class="number">1</span>)[<span class="number">1</span>].numpy()</span><br><span class="line"><span class="built_in">print</span>(pred_y, <span class="string">&#x27;prediction number&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(test_y[:<span class="number">20</span>].numpy(),<span class="string">&#x27;real number&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----output-----</span></span><br><span class="line"><span class="comment"># [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] prediction number</span></span><br><span class="line"><span class="comment"># [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4] real number</span></span><br></pre></td></tr></table></figure><p class='p left logo large'>总结</p><p>只是最简单的CNN吧，不过结果确实挺好，网络就真的学到特征了。也没去试过换一下优化器啊激活函数会有什么效果，只是学一下基础知识顺便学习PyTorch用法吧</p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记（一） 基础</title>
      <link href="/posts/10010.html"/>
      <url>/posts/10010.html</url>
      
        <content type="html"><![CDATA[<p>先尝试写一个简单的线性计算，用神经网络拟合学习。</p><p class='p left logo large'>数据生成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 给定权重矩阵</span></span><br><span class="line">W = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.4</span>],[<span class="number">0.5</span>,<span class="number">0.6</span>],[<span class="number">0.6</span>,<span class="number">0.2</span>]])</span><br><span class="line"></span><br><span class="line">num_samples = <span class="number">100</span></span><br><span class="line">input_dim = <span class="number">3</span></span><br><span class="line">x = torch.rand((num_samples, input_dim))</span><br><span class="line"></span><br><span class="line">y = torch.matmul(W.t(), x.t()).t()</span><br></pre></td></tr></table></figure><p>一会儿我们用这些数据取拟合权重矩阵 $W$</p><p class='p left logo large'>定义网络</p><p>pytorch中的自定义神经网络类需要继承 <code>nn.Module</code> ，并且调用父类的构造函数 <code>__init__()</code> 来完成一些参数和方法的初始化。</p><p>最简单的网络我们只需定义网络中的层结构，如这里我加了一层线性层。以及前向传播的 <code>forward</code> 函数即可。</p><p>如果需要自定义损失函数等，会在之后的文章中介绍。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Simple_nn</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Simple_nn, self).__init__()</span><br><span class="line">        self.W = nn.Linear(input_dim, output_dim, bias=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># X : [batch_size, input_dim]</span></span><br><span class="line">        <span class="comment"># 在forward中的X还是带有batch_size这一维度的，不过在经过链接层的时候，pytorch会自动处理批次，不用显式考虑。</span></span><br><span class="line">        output = self.W(X)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p class='p left logo large'>进行训练</p><p>训练需要数据，我们把数据以batch的形式送进网络进行训练。目前我们不涉及dataset，dataloader的使用。</p><p>先写一个随机取batch的函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">4</span> <span class="comment"># mini-batch size</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_batch</span>():</span><br><span class="line">    random_x = torch.zeros((batch_size, input_dim))</span><br><span class="line">    random_y = torch.zeros((batch_size, output_dim))</span><br><span class="line">    <span class="comment"># 定义一个随机抽取batch</span></span><br><span class="line">    random_index = np.random.choice(<span class="built_in">range</span>(<span class="built_in">len</span>(x)), batch_size, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, index <span class="keyword">in</span> <span class="built_in">enumerate</span>(random_index):</span><br><span class="line">        random_x[i] = x[index]</span><br><span class="line">        random_y[i] = y[index]</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">return</span> random_x, random_y</span><br></pre></td></tr></table></figure><p>然后写一个训练函数</p><p>pytorch封装了很多操作，比如说反向传播 <code>backward</code> 是不需要自己写的，只需要调用 <code>loss.backward()</code> 即可</p><p>随后，调用 <code>torch.optim</code> 中被称为优化器的工具就可以更新参数</p><p>像这里的 <code>optim.SGD</code> 就是随机梯度下降的参数更新方法。</p><p>注意，模型直到 <code>optimizer.step()</code> 这步才正式更新模型参数。这两步的分离是为了提供更大的灵活性，比如可以多次调用 <code>loss.backward()</code>累积梯度，然后在特定时刻执行一次 <code>optimizer.step()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = Simple_nn()</span><br><span class="line"><span class="comment"># 定义损失函数 </span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5000</span>):</span><br><span class="line">    input_batch, output_batch = random_batch()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 清除梯度缓存</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    output_pred = model(input_batch)</span><br><span class="line">    <span class="comment"># 计算损失函数</span></span><br><span class="line">    loss = criterion(output_pred, output_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch:&#x27;</span>, <span class="string">&#x27;%04d&#x27;</span> % (epoch + <span class="number">1</span>), <span class="string">&#x27;cost =&#x27;</span>, <span class="string">&#x27;&#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(loss))</span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.W.weight.t())</span><br></pre></td></tr></table></figure><p>最后得到输出，和我们一开始定义的 $W$ 是很接近的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.2985, 0.4066],</span><br><span class="line">        [0.5058, 0.5921],</span><br><span class="line">        [0.5955, 0.2015]], grad_fn=&lt;TBackward0&gt;)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Neural Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nunjucks Error expected variable end解决办法</title>
      <link href="/posts/10009.html"/>
      <url>/posts/10009.html</url>
      
        <content type="html"><![CDATA[<p>在文章中写latex代码的时候，可能会遇到报错：Nunjucks Error expected variable end</p><p>比如下面这段</p><figure class="highlight latex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">$</span><span class="built_in">$</span></span><br><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">    <span class="keyword">\begin</span>&#123;array&#125;&#123;ll&#125;</span><br><span class="line">        p(w<span class="built_in">_</span>j|w<span class="built_in">_</span>i) <span class="built_in">&amp;</span>= y<span class="built_in">_</span>j <span class="keyword">\\</span></span><br><span class="line">                   <span class="built_in">&amp;</span>= <span class="keyword">\frac</span>&#123;e<span class="built_in">^</span>&#123;u<span class="built_in">_</span>j&#125;&#125;&#123;<span class="keyword">\sum</span><span class="built_in">_</span>&#123;k <span class="keyword">\in</span> V&#125; e<span class="built_in">^</span>&#123;u<span class="built_in">_</span>k&#125;&#125;   <span class="keyword">\\</span></span><br><span class="line">                   <span class="built_in">&amp;</span>= <span class="keyword">\frac</span>&#123; e<span class="built_in">^</span>&#123;&#123;W&#x27;<span class="built_in">_</span>j&#125;<span class="built_in">^</span>T <span class="keyword">\cdot</span> W<span class="built_in">_</span>I&#125; &#125; &#123;<span class="keyword">\sum</span><span class="built_in">_</span>&#123;k <span class="keyword">\in</span> V&#125; e<span class="built_in">^</span>&#123; &#123;W&#x27;<span class="built_in">_</span>k&#125;<span class="built_in">^</span>T <span class="keyword">\cdot</span> W<span class="built_in">_</span>I&#125; &#125; <span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\end</span>&#123;array&#125; <span class="keyword">\notag</span></span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br><span class="line"><span class="built_in">$</span><span class="built_in">$</span></span><br></pre></td></tr></table></figure><p>查阅资料后是因为，Hexo使用Nunjucks渲染帖子，用 <code>&#123; &#123; &#125; &#125;</code> 或 <code>&#123;% %&#125;</code> 包装的内容将被解析，并可能导致问题。</p><p>可以使用下列标签包裹敏感字段，避免被Nunjucks错误解析。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;% raw %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% endraw%&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo &amp; Butterfly tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo &amp; Butterfly tutorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Word2Vec</title>
      <link href="/posts/10008.html"/>
      <url>/posts/10008.html</url>
      
        <content type="html"><![CDATA[<div class="note success simple"><p>最好的学习方法就是把知识讲给别人听</p></div><p>开个新坑，努力！封面图也换上对我意义非凡的 Chtholly</p><p class='p left logo large'>基本概念</p><p>基本概念懒得写了。</p><p>Word2Vec是Google的Mikolov在2013年提出的一种词向量的表征形式。不同于稀疏的one-hot编码，对样本空间的利用率只有坐标轴上可怜的几个点; word embedding 就可以以更少的维度表示词语，更高效地利用样本空间，并可使单词的向量表征具有一定几何意义。</p><p class='p left logo large'>网络结构</p><p>Word2Vec一共给出了两种网络结构，CBOW和Skip-gram</p><h1 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h1><p>CBOW的任务简单来说就是，给定某个单词 $w_t$ 的上下文 $w_{t-2}, w_{t-1}, w_{t+1}, w_{t+2}$，去估计中间这个单词应该是什么，也就是要计算 $p(w_t | w_{t-2}, w_{t-2}, w_{t-2}, w_{t-2})$，词向量是这一任务的一项产物。</p><h2 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h2><p>我们先考虑较为简单的一个单词的情况，即计算 $p(w_t|w_{I})$</p><p>CBOW模型的输入是一个one-hot向量，考虑当前有一个长度为|V|的词表，不妨设 $w_{oI}$ 是词表中的第 $I$ 个词的one-hot表示（和 $w_{t+1}$ 这种原来句子中的空间位置关系作区别），也即只有第 $I$ 个元素是1</p><div class="img-wrap"><div class="img-bg"><img class="img" src="https://pic2.zhimg.com/80/v2-ca4c641f4f3c9a44e43260c04c0161d1_1440w.webp" alt="CBOW模型示例，图源知乎" style="width:400px;"/></div><span class="image-caption">CBOW模型示例，图源知乎</span></div><p>CBOW仅有一个隐层，设输入层到隐层的权重为 $W$，输入层到输出层的权重为 $W’$，隐层神经元个数为 $N$, $W_i$ 表示 $W$ 的第 $i$ 行，${W’_j}$ 表示 $W’$ 的第 $j$ 列。</p><p>因为input是one-hot向量，可以知道隐层的输入 $h$ 应该等于 $W$ 的第 $I$ 行 $W_I$ ，$h$ 的维度是 $N \times 1$。</p><p>CBOW的设计中省略了隐藏层的非线性激活函数，仅仅是做了一个加权组合。</p><p>随后经过权重 $W’$ ，得到一个向量$u$，其中 $u_i = {W’_i}^T \cdot W_I$ ，并进行一次softmax归一化得到结果 $y$</p><p>输出结果是一个 $V \times 1$ 的向量，每一个元素 $y_i$ 表示了预测词为词表中第 $i$ 个词的概率。</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>对于一个输入 $w_{oi}$，我们已知它的输出应该是 $w_{oj}$，也就是说我们应该最大化目标函数$p(w_{oj}|w_{oi})$, 即 $y_j$</p>$$\begin{equation}    \begin{array}{ll}        p(w_{oj}|w_{oi}) &= y_j \\                   &= \frac{e^{u_j}}{\sum_{k \in V} e^{u_k}}   \\                   &= \frac{ e^{{W'_j}^T \cdot W_I} } {\sum_{k \in V} e^{ {W'_k}^T \cdot W_I} } \\    \end{array} \notag\end{equation}$$<p>我们对其取对数,则</p><script type="math/tex; mode=display">log \; p(w_{oj}|w_{oi}) = {W'_j}^T \cdot W_I - log{\sum_{k \in V} {W'_k}^T \cdot W_I}</script><p>损失函数就是目标函数取负就可以了。</p><p>如果有多个输入，仅需在第一步的时候，对各个输入均经过相同的权重矩阵 $W$ ，最后隐藏层输入 $h$ 平均即可。</p><p>（关于对这步多个输入求和平均，我一开始也有些困惑，感觉会不会对效果产生什么影响。不过如果是单个输入的话，可能不同输入之间的影响抵消的影响会比较大。作者应该也是实验过了现在的结果好？不懂。然后模型也抛弃了和中心词相隔距离的参数。）</p><p>考虑上下文窗口长度为 $c$（前后各 $c$ 个总共 $2c$ 个），我们要求的损失函数就是：</p><script type="math/tex; mode=display">\sum_{-c \leq j \leq c, j \neq 0}log \; p(w_t|w_{t+j});</script><p>这个其实可以直接用交叉熵损失函数算，原因在：<a href="https://zhuanlan.zhihu.com/p/115277553">https://zhuanlan.zhihu.com/p/115277553</a> ，写得特别好！值得我重新开一篇博文记录一下。 </p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>作者很厉害，那个时候没有Tensorflow、PyTorch这种深度学习框架，整个代码是C语言完成的并且所有梯度都是手算的。</p><p>其实用上深度学习框架后网络非常简单，损失函数用 <code>criterion = nn.CrossEntropyLoss()</code> 就可以了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Word2Vec</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Word2Vec, self).__init__()</span><br><span class="line">        <span class="comment"># 输入层到隐层权重矩阵</span></span><br><span class="line">        self.W = nn.Linear(voc_size, embedding_size, bias=<span class="literal">False</span>) <span class="comment"># voc_size &gt; embedding_size Weight</span></span><br><span class="line">        <span class="comment"># 隐层到输出层权重矩阵</span></span><br><span class="line">        self.WT = nn.Linear(embedding_size, voc_size, bias=<span class="literal">False</span>) <span class="comment"># embedding_size &gt; voc_size Weight</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># X : [batch_size, voc_size]</span></span><br><span class="line">        hidden_layer = self.W(X) <span class="comment"># hidden_layer : [batch_size, embedding_size]</span></span><br><span class="line">        output_layer = self.WT(hidden_layer) <span class="comment"># output_layer : [batch_size, voc_size]</span></span><br><span class="line">        <span class="keyword">return</span> output_layer</span><br></pre></td></tr></table></figure><h1 id="skip-gram"><a href="#skip-gram" class="headerlink" title="skip-gram"></a>skip-gram</h1><p>说实话我觉得就是CBOW倒过来，，，形式也是一样的。</p><p class='p left logo large'>效率优化</p><h1 id="hierarchical-softmax"><a href="#hierarchical-softmax" class="headerlink" title="hierarchical softmax"></a>hierarchical softmax</h1><p>TODO</p><p class='p left logo large'>参考链接</p><p><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</a> 超级保姆级教程<br><a href="https://adoni.github.io/2017/11/08/word2vec-pytorch/">https://adoni.github.io/2017/11/08/word2vec-pytorch/</a> </p>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络 Wireshark的使用</title>
      <link href="/posts/10007.html"/>
      <url>/posts/10007.html</url>
      
        <content type="html"><![CDATA[<p>随便写写</p><p>Wireshark是网络包分析工具，主要作用是在接囗实时捕捉网络包，并详细显示包的协议信息。</p><ul><li><p>可以捕捉多种网络接囗类型的包，包括无线局域网接囗。</p></li><li><p>可以支持多种协议的解码，如TCP，DNS等。</p></li></ul><h1 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h1><p>Wireshark的过滤器分为捕获过滤器和显示过滤器</p><ul><li><p>前者需要在捕捉前设置好，决定捕捉什么包</p></li><li><p>后者在捕获过程中及结束后可以随时修改，只是显示捕获结果符合要求的包</p></li></ul><h1 id="捕获过滤器语法"><a href="#捕获过滤器语法" class="headerlink" title="捕获过滤器语法"></a>捕获过滤器语法</h1><p>这里很全：<a href="https://blog.csdn.net/qq_39720249/article/details/128157288">https://blog.csdn.net/qq_39720249/article/details/128157288</a></p><h2 id="基于协议过滤"><a href="#基于协议过滤" class="headerlink" title="基于协议过滤"></a>基于协议过滤</h2><ul><li>例：只捕获端口为80的tcp数据包</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcp port 80</span><br></pre></td></tr></table></figure><h2 id="基于方向过滤"><a href="#基于方向过滤" class="headerlink" title="基于方向过滤"></a>基于方向过滤</h2><p>可以指定获取 源src 或是 目的dst 方向的数据包，也可以用 src and dst 或是 src or dst</p><ul><li>例：只捕获目的ip为本机ip的ipv4数据包</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst host &lt;本机ip&gt;</span><br></pre></td></tr></table></figure><h2 id="基于类型过滤"><a href="#基于类型过滤" class="headerlink" title="基于类型过滤"></a>基于类型过滤</h2><p>可选项有 主机host，网段net，端口port，端口范围portrange 等</p><ul><li>例：只捕获端口不为80的数据包</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">not port 80</span><br></pre></td></tr></table></figure><h1 id="显示过滤器语法"><a href="#显示过滤器语法" class="headerlink" title="显示过滤器语法"></a>显示过滤器语法</h1><p>例：显示ip为本机ip的dns数据包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip.addr == &lt;本机ip&gt; &amp;&amp; dns</span><br></pre></td></tr></table></figure><p>但是会发现这样什么包都没有。</p><p>将显示过滤器条件简化为dns后发现能正确找到相关dns数据包，但是其src和dst都是我本机的临时Ipv6地址。</p><p>将表达式更改为以下式子即可正确获取dns数据包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipv6.addr == &lt;本机ip&gt; &amp;&amp; dns</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Computer Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Notes </tag>
            
            <tag> Computer Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FDU Operating System Lab2</title>
      <link href="/posts/10006.html"/>
      <url>/posts/10006.html</url>
      
        <content type="html"><![CDATA[<div class="note success simple"><p>薪火相传</p></div><p>因为中途才开始写博客，一些配置上的问题可能没讲清楚。目前只是自己做一个记录吧。</p><p>如果能帮到你理解这个lab就好啦</p><p>环境：WSL + xv6</p><p>LAB2：<a href="https://docs.qq.com/slide/DR2VtU3Fvb2hGWEN0">https://docs.qq.com/slide/DR2VtU3Fvb2hGWEN0</a></p><h1 id="实验准备"><a href="#实验准备" class="headerlink" title="实验准备"></a>实验准备</h1><p>切换到本次实验的环境分支下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git commit -am lab0</span><br><span class="line">git fetch</span><br><span class="line">git checkout syscall</span><br><span class="line">make clean</span><br></pre></td></tr></table></figure><p>随后按要求修改相应 <code>kernel</code> 与 <code>user</code> 文件夹下的文件，以任务1的 <code>procnum</code> 为例，其余同理。</p><p>在 <code>kernel/syscall.h</code> 中，添加一个宏定义</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> SYS_procnum 22</span></span><br></pre></td></tr></table></figure><p>然后在 <code>kernel/syscall.c</code> 指定系统调用的主体函数，即第22号System call会调用 <code>sys_procnum</code> 这个指针指向的函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> uint64 <span class="title function_">sys_procnum</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="title function_">uint64</span> <span class="params">(*syscalls[])</span><span class="params">(<span class="type">void</span>)</span> = &#123;</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line">[SYS_procnum]  sys_procnum,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>kernel/sysproc.c</code> 中添加具体实现的主体函数（在后面会介绍）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">uint64</span><br><span class="line"><span class="title function_">sys_procnum</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//implementation of sys_procnum</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>user/usys.pl</code> 中添加系统调用的存根</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">entry(<span class="string">&quot;procnum&quot;</span>);</span><br></pre></td></tr></table></figure><p>具体而言，就是 <code>Makefile</code> 会调用这个 <code>Perl</code> 脚本，生成一段汇编码在 <code>usys.S</code> 中，这是 <code>user.h</code> 中定义的函数实际的实现，即调用的地方。</p><p>点进 <code>usys.S</code> 可以看到诸如 <code>li a7, SYS_fork</code> 这种，还记得之前把 <code>SYS_fork</code> 宏定义为了数字吧，就是在这里派用场。</p><p>为了能够让用户程序访问到 <code>procnum</code> 系统调用，我们需要在 <code>user/user.h</code> 中声明该调用：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// system calls</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">procnum</span><span class="params">(<span class="type">int</span>*)</span>;</span><br></pre></td></tr></table></figure><p>你可能会注意到这里有一个参数列表上的不匹配，会发现所有 <code>kernel/sysproc.c</code> 中的系统调用实现形参列表都是void。</p><p>这是因为 <code>procnum()</code> 这样的函数是用户级别的函数，而 <code>sys_procnum()</code> 是内核级别的函数，用户空间和内核空间有不同的数据访问规则和隔离。</p><p>前者需要将参数在用户空间打包成适当的数据结构，后者会通过辅助函数 <code>argaddr()</code> 或 <code>argint()</code> 等获取用户空间的参数到内核空间，并在其中进行合法与安全性检查，确保不会引发内核的错误。</p><p>可以看看其它system call的实现方法，比如wait()，是怎么获取参数列表的</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">argaddr</span><span class="params">(<span class="type">int</span> n, uint64 *addr)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">argint</span><span class="params">(<span class="type">int</span> n, <span class="type">int</span> *ip)</span>;</span><br></pre></td></tr></table></figure><h1 id="任务1：process-counting"><a href="#任务1：process-counting" class="headerlink" title="任务1：process counting"></a>任务1：process counting</h1><ul><li>系统调用功能 procnum：统计系统总进程数</li></ul><p>在user文件夹下添加检验程序 procnum.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/types.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/riscv.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/sysinfo.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(argc &gt;= <span class="number">2</span>) &#123;</span><br><span class="line"><span class="built_in">fprintf</span>(<span class="number">2</span>, <span class="string">&quot;procnum: Too many arguments\n&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> num = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (procnum(&amp;num) &lt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">fprintf</span>(<span class="number">2</span>, <span class="string">&quot;procnum failed!\n&quot;</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Number of process: %d\n&quot;</span>, num);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在makefile中添加编译项</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPROGS=\</span><br><span class="line">    ...</span><br><span class="line">$U/_procnum\</span><br></pre></td></tr></table></figure><p>完成 <code>kernel/sysproc.c</code> 中函数的具体实现。我整体是对着 <code>sys_wait()</code> 函数学的。</p><p>先用 <code>argaddr()</code> 获取传过来的参数，是变量num的地址</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">uint64</span><br><span class="line"><span class="title function_">sys_procnum</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  uint64 p;</span><br><span class="line">  argaddr(<span class="number">0</span>, &amp;p);</span><br><span class="line">  <span class="keyword">return</span> procnum(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和 <code>sys_wait()</code> 函数一样，我们把实现放在了 <code>kernel/proc.c</code> 中，记得在 <code>defs.h</code> 中先定义函数</p><p>因为内核空间和用户空间存在隔离，所以只能使用 <code>copyout()</code> 这种辅助函数实现修改用户空间的变量，而不能直接拿指针去操作。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Count the total number of processes in the system.</span></span><br><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">procnum</span><span class="params">(uint64 addr)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">pp</span>;</span> <span class="comment">// 声明一个指向struct proc的指针pp，用于遍历进程表中的进程。</span></span><br><span class="line">  <span class="type">int</span> proc_num = <span class="number">0</span>; <span class="comment">// 统计进程数</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">p</span> =</span> myproc(); <span class="comment">//获取当前进程的指针并存储在p中。</span></span><br><span class="line">  <span class="keyword">for</span>(pp = proc; pp &lt; &amp;proc[NPROC]; pp++)&#123; <span class="comment">//遍历整个进程表，查找子进程。</span></span><br><span class="line"><span class="keyword">if</span>(pp-&gt;state != <span class="number">0</span>) &#123; <span class="comment">// 只要进程状态不是unused</span></span><br><span class="line">proc_num++;</span><br><span class="line">&#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(addr != <span class="number">0</span> &amp;&amp; copyout(p-&gt;pagetable, addr, (<span class="type">char</span> *)&amp;proc_num, <span class="keyword">sizeof</span>(proc_num)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="comment">// 这个比较复杂，，首先检查 addr 是否为非零值。</span></span><br><span class="line"><span class="comment">// 如果 addr 不为零就调用 copyout 函数，将数据从内核空间复制到用户空间。</span></span><br><span class="line"><span class="comment">// p 是当前进程的指针，p-&gt;pagetable 存储了当前进程的页表。页表是一种数据结构，用于将虚拟地址映射到物理地址，以便访问内存中的数据。</span></span><br><span class="line"><span class="comment">// addr 是用户程序提供的目标地址，数据将被复制到这里</span></span><br><span class="line"><span class="comment">// (char *)&amp;proc_num 是要复制的源数据的地址。需要以char*的形式传递源数据的地址</span></span><br><span class="line"><span class="comment">// sizeof(pp-&gt;xstate) 是要复制的数据的大小，以字节为单位。</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> proc_num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其余几项任务也差不多，照猫画虎。</p><blockquote><p>下面的部分是我很久之后参照着实验报告补的，可能并不全面，仅供参考</p></blockquote><h1 id="任务2：Free-Memory-Counting"><a href="#任务2：Free-Memory-Counting" class="headerlink" title="任务2：Free Memory Counting"></a>任务2：Free Memory Counting</h1><p>要统计空闲内存块的总字节数数，可以直接看在 kalloc.c 中的 kmem.freelist，遍历可以获得空闲“页数”，最后记得答案乘以 PGSIZE</p><p>为了操作定义在 kalloc.c 中的 kmem，可以在 kalloc.c 中添加一个函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">get_freemem</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> freemem_num = <span class="number">0</span>; <span class="comment">// 统计空闲内存数</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">run</span> *<span class="title">mem</span> =</span> kmem.freelist;</span><br><span class="line">  <span class="keyword">while</span> (mem) &#123;</span><br><span class="line">    freemem_num++;</span><br><span class="line">    mem = mem-&gt;next;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> freemem_num * PGSIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后在系统调用时调用 <code>get_freemem()</code> 这个函数，和实验 1 一样我还是把实现放在了proc.c 中。记得把这些函数都在头文件 defs.h 中定义一下。</p><h3 id="sysproc-c"><a href="#sysproc-c" class="headerlink" title="sysproc.c :"></a>sysproc.c :</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">uint64 </span><br><span class="line"><span class="title function_">sys_freemem</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  uint64 p;</span><br><span class="line">  argaddr(<span class="number">0</span>, &amp;p);</span><br><span class="line">  <span class="keyword">return</span> freemem(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="proc-c"><a href="#proc-c" class="headerlink" title="proc.c :"></a>proc.c :</h3><p>把答案写回 num</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">freemem</span><span class="params">(uint64 addr)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">p</span> =</span> myproc();</span><br><span class="line">  <span class="type">int</span> freemem_num = get_freemem();</span><br><span class="line">  <span class="keyword">if</span>(addr != <span class="number">0</span> &amp;&amp; copyout(p-&gt;pagetable, addr, (<span class="type">char</span> *)&amp;freemem_num, <span class="keyword">sizeof</span>(freemem_num)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> freemem_num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="任务3：System-call-tracing"><a href="#任务3：System-call-tracing" class="headerlink" title="任务3：System call tracing"></a>任务3：System call tracing</h1><p>这次 trace.c 已经给好了在 user 文件夹里</p><p>Trace 的用法不太一样，它传入一个参数 mask，每一个二进制位表示跟踪某一个system call。若某一 system call 处于被跟踪状态，则执行它时会输出相关信息</p><p>跟着 <a href="https://pdos.csail.mit.edu/6.S081/2022/labs/syscall.html">https://pdos.csail.mit.edu/6.S081/2022/labs/syscall.html</a> 中的提示，我们还是先同样在 sysproc.c 中添<br>加系统调用 sys_trace()，它负责接收参数 mask 到当前进程。这要求我们在 proc.h 中，对<br>每一个进程添加一个参数 mask。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Per-process state </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">proc</span> &#123;</span></span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  <span class="type">char</span> name[<span class="number">16</span>]; <span class="comment">// Process name (debugging)</span></span><br><span class="line">  <span class="type">int</span> mask; <span class="comment">// denote which syscall is being traced </span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>随后，我们需要修改 fork，让每一个子进程也继承到 mask。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> </span><br><span class="line"><span class="title function_">fork</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// ... </span></span><br><span class="line">  <span class="comment">// copy the trace_mask state</span></span><br><span class="line">  np-&gt;mask = p-&gt;trace_mask; </span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">  <span class="keyword">return</span> pid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，在 syscall.c 中修改 void syscall(void)，每次调用时检查所有的 system call，若对应 mask 位=1，则打印相关信息，格式和要求中相同。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> </span><br><span class="line"><span class="title function_">syscall</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> num; </span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">p</span> =</span> myproc(); </span><br><span class="line">  <span class="type">char</span>* syscall_name; </span><br><span class="line">  num = p-&gt;trapframe-&gt;a7; </span><br><span class="line">  <span class="keyword">if</span>(num &gt; <span class="number">0</span> &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) &#123;</span><br><span class="line">    <span class="comment">// Use num to lookup the system call function for num, call it, </span></span><br><span class="line"><span class="comment">// and store its return value in p-&gt;trapframe-&gt;a0 </span></span><br><span class="line">p-&gt;trapframe-&gt;a0 = syscalls[num](); </span><br><span class="line"><span class="comment">// 遍历所有 syscall </span></span><br><span class="line"><span class="keyword">if</span> ((p-&gt;mask &amp; (<span class="number">1</span> &lt;&lt; num)) != <span class="number">0</span>) &#123; <span class="comment">// 若处于跟踪状态； </span></span><br><span class="line">  <span class="comment">// 打印相关信息</span></span><br><span class="line">      syscall_name = syscall_names[num]; </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d: syscall %s -&gt; %d\n&quot;</span>, p-&gt;pid, syscall_name, p-&gt;trapframe-&gt;a0); </span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d %s: unknown sys call %d\n&quot;</span>, p-&gt;pid, p-&gt;name, num); </span><br><span class="line">p-&gt;trapframe-&gt;a0 = <span class="number">-1</span>; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Study </category>
          
          <category> Operating System </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Study </tag>
            
            <tag> Notes </tag>
            
            <tag> Operating System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自定义页面</title>
      <link href="/posts/10004.html"/>
      <url>/posts/10004.html</url>
      
        <content type="html"><![CDATA[<p>Hexo &amp; butterfly 会自动按照其设置指定的方式对markdown文件进行渲染，生成对应的博客页面。</p><p>不过可能除了写博客，我们还希望能在博客上部署一些小页面小功能，butterfly也是支持的。</p><p>我们可以在 <code>/source</code> 文件夹下新建一个html文件夹，将我们写好的页面（html、css、javascript）一起放进去。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">source</span><br><span class="line">    |-- html</span><br><span class="line">          |-- index.html  # 主要的小工具总览页面</span><br><span class="line">          |-- Tool1  # 各种不同的小工具</span><br><span class="line">          |-- Tool2</span><br><span class="line">          |-- ...</span><br></pre></td></tr></table></figure><p>在 <code>_config.yml</code> ，我们需要指定hexo让其跳过对html文件夹下内容的默认渲染：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">skip_render:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;html/**&quot;</span>  </span><br></pre></td></tr></table></figure><p>最后，我们可以在menu栏添加一个Tool图标，会首先跳转到一个总览页面，专门用于存放自己的小工具：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="attr">Tools:</span> <span class="string">/html/index.html</span> <span class="string">||</span> <span class="string">fas</span> <span class="string">fa-archive</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hexo &amp; Butterfly tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo &amp; Butterfly tutorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客书写指南</title>
      <link href="/posts/10003.html"/>
      <url>/posts/10003.html</url>
      
        <content type="html"><![CDATA[<p>每篇博客都是一个markdown文件，由Butterfly渲染生成页面，下面介绍一些文章的设置以及写法：</p><p class='p left logo large'>文章属性</p><p>每篇文章的开头都有一个<code>Front-matter</code>，用于提供这篇文章的相关信息，详情请看 <a href="https://butterfly.js.org/posts/dc584b87/">https://butterfly.js.org/posts/dc584b87/</a></p><p>以本篇文章的设置为例，讲一下各个属性的意义：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 博客书写指南</span><br><span class="line">cover: &#x27;https://picst.sunbangyan.cn/2023/10/13/oynsmu.jpg&#x27;</span><br><span class="line">abbrlink: 10003</span><br><span class="line">date: 2023-10-13 22:59:32</span><br><span class="line">tags: [Hexo &amp; Butterfly tutorial]</span><br><span class="line">categories: </span><br><span class="line"><span class="bullet">  -</span> [Hexo &amp; Butterfly tutorial]</span><br><span class="line">updated:</span><br><span class="line">type:</span><br><span class="line">comments:</span><br><span class="line">description: 介绍博客文章的书写方法</span><br><span class="line">keywords:</span><br><span class="line">top<span class="emphasis">_img:</span></span><br><span class="line"><span class="emphasis">mathjax:</span></span><br><span class="line"><span class="emphasis">katex:</span></span><br><span class="line"><span class="emphasis">aside:</span></span><br><span class="line"><span class="emphasis">aplayer:</span></span><br><span class="line"><span class="emphasis">highlight_</span>shrink:</span><br><span class="line"><span class="section">random:</span></span><br><span class="line"><span class="section">---</span></span><br></pre></td></tr></table></figure><ul><li><p>title</p><p>博客的标题</p></li><li><p>cover </p><p>博客的封面（显示在首页）</p></li><li><p>abbrlink</p><p>由插件 <code>hexo-abbrlink</code> 生成，替换hexo原生的页面url生成方案。该值可自定义，唯一指定一篇文章（不可重复），同时也是该页面的url地址。</p></li><li><p>date</p><p>文章的发表时间</p></li><li><p>tags</p><p>该篇文章的标签，语法为 tags:[tag1, tag2, …]</p></li><li><p>categories</p><p>该篇文章的分类，推荐语法为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">categories: </span><br><span class="line">  - [A, B]</span><br></pre></td></tr></table></figure><p>表示该文章属于分类A下的子类B</p></li><li><p>description</p><p>在首页看到的文章内容简介。如果设置了 <code>description</code> ，则会显示这个，否则会显示文章内容节选</p><p>这一项可以在 <code>_config.butterfly.yml</code> 中的 <code>index_post_content</code> 一栏修改（详见：<a href="https://anti-entrophic.github.io/posts/10002.html）">https://anti-entrophic.github.io/posts/10002.html）</a></p></li><li><p>待补充</p></li></ul><p class='p left logo large'>自定义页面字体</p><h1 id="创建css文件"><a href="#创建css文件" class="headerlink" title="创建css文件"></a>创建css文件</h1><p>以我目前使用的字体为例，首先需要在 <code>/&#123;root&#125;/source/css</code> 目录下新建一个文件，暂且命名为 <code>custom.css</code> ，内容如下：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*感谢安知鱼大佬的教程！*/</span></span><br><span class="line"><span class="keyword">@font-face</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: ZhuZiAYuanJWD;</span><br><span class="line">    <span class="attribute">src</span>: <span class="built_in">url</span>(<span class="string">https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2</span>);</span><br><span class="line">    <span class="attribute">font-display</span>: swap;</span><br><span class="line">    <span class="attribute">font-weight</span>: lighter;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="selector-tag">body</span> &#123;</span><br><span class="line">    <span class="attribute">font-family</span>: <span class="string">&quot;ZhuZiAYuanJWD&quot;</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>当然，你也可以不指定全局使用这一个字体，可以换，比如说仅指定导航栏当然也是可以的，可以自己魔改：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">div</span><span class="selector-id">#menus</span> &#123;</span><br><span class="line">  <span class="attribute">font-family</span>: <span class="string">&quot;ZhuZiAYuanJWD&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="引入css文件"><a href="#引入css文件" class="headerlink" title="引入css文件"></a>引入css文件</h1><p>在 <code>_config.butterfly.yml</code> 中找到 <code>inject</code> 这一栏，就像html链接css一样引入：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">inject:</span></span><br><span class="line">  <span class="attr">head:</span></span><br><span class="line">    <span class="comment"># 自定义CSS</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&lt;link</span> <span class="string">rel=&quot;stylesheet&quot;</span> <span class="string">href=&quot;/css/custom.css&quot;</span> <span class="string">media=&quot;defer&quot;</span> <span class="string">onload=&quot;this.media=&#x27;all&#x27;&quot;&gt;</span></span><br><span class="line">    <span class="comment"># 暂时不清楚media和onload有什么用</span></span><br></pre></td></tr></table></figure><p>之后，在 <code>_config.butterfly.yml</code> 中指定渲染时使用我们新引入的字体：（这步不清楚需不需要）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">font:</span></span><br><span class="line">  <span class="attr">global-font-size:</span></span><br><span class="line">  <span class="attr">code-font-size:</span></span><br><span class="line">  <span class="attr">font-family:</span> <span class="string">ZhuZiAYuanJWD</span></span><br><span class="line">  <span class="attr">code-font-family:</span> <span class="string">ZhuZiAYuanJWD</span></span><br></pre></td></tr></table></figure><p>其中，<code>font-family</code> 是全局的字体， <code>code-font-family</code> 是代码块中的字体</p>]]></content>
      
      
      <categories>
          
          <category> Hexo &amp; Butterfly tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo &amp; Butterfly tutorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo&amp;butterfly配置教程</title>
      <link href="/posts/10002.html"/>
      <url>/posts/10002.html</url>
      
        <content type="html"><![CDATA[<div class="note success simple"><p>介绍一些博客的 Hexo &amp; butterfly 配置修改方法</p></div><p class='p left logo large'>主页文章简介</p><p>在主页中看到的文章内容的简介，<code>butterfly</code> 共提供了四种选择：</p><ol><li>description： 只显示description</li><li>both： 优先选择description；如果没有配置description，则显示文章节选内容</li><li>auto_excerpt： 只显示文章节选内容</li><li>false： 不显示文章内容</li></ol><p>在 <code>_config.butterfly.yml</code> 修改条目如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">index_post_content:</span></span><br><span class="line">  <span class="attr">method:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">length:</span> <span class="number">500</span>  <span class="comment"># if you set method to 2 or 3, the length need to config</span></span><br></pre></td></tr></table></figure><p class='p left logo large'>跳过渲染</p><p>hexo会自动把source下的文件识别渲染为博客页面，但有时我们并不希望自动渲染，而是想要其维持我们设计的界面。</p><p>在 <code>_config.yml</code> 修改条目如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">skip_render:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;html/**&quot;</span>  <span class="comment"># &quot;**&quot;：通配符，html文件夹下的所有文件；&quot;*&quot;，html文件夹下一层的所有文件</span></span><br></pre></td></tr></table></figure><p class='p left logo large'>侧边栏</p><p>在 <code>_config.butterfly.yml</code> 相关条目：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">aside:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hide:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">button:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">mobile:</span> <span class="literal">true</span> <span class="comment"># display on mobile</span></span><br><span class="line">  <span class="attr">position:</span> <span class="string">right</span> <span class="comment"># left or right</span></span><br><span class="line">  <span class="attr">display:</span></span><br><span class="line">    <span class="attr">archive:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">tag:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">category:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">card_author:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">description:</span></span><br><span class="line">    <span class="attr">button:</span></span><br><span class="line">      <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">icon:</span> <span class="string">fab</span> <span class="string">fa-github</span></span><br><span class="line">      <span class="attr">text:</span> <span class="string">Follow</span> <span class="string">Me</span></span><br><span class="line">      <span class="attr">link:</span> <span class="string">https://github.com/Anti-Entrophic</span></span><br><span class="line">  <span class="attr">card_announcement:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">content:</span> <span class="string">This</span> <span class="string">is</span> <span class="string">my</span> <span class="string">Blog</span></span><br><span class="line">  <span class="attr">card_recent_post:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">limit:</span> <span class="number">5</span> <span class="comment"># if set 0 will show all</span></span><br><span class="line">    <span class="attr">sort:</span> <span class="string">date</span> <span class="comment"># date or updated</span></span><br><span class="line">    <span class="attr">sort_order:</span> <span class="comment"># Don&#x27;t modify the setting unless you know how it works</span></span><br><span class="line">  <span class="attr">card_categories:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">limit:</span> <span class="number">8</span> <span class="comment"># if set 0 will show all</span></span><br><span class="line">    <span class="attr">expand:</span> <span class="string">none</span> <span class="comment"># none/true/false</span></span><br><span class="line">    <span class="attr">sort_order:</span> <span class="comment"># Don&#x27;t modify the setting unless you know how it works</span></span><br><span class="line">  <span class="attr">card_tags:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">limit:</span> <span class="number">40</span> <span class="comment"># if set 0 will show all</span></span><br><span class="line">    <span class="attr">color:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">orderby:</span> <span class="string">random</span> <span class="comment"># Order of tags, random/name/length</span></span><br><span class="line">    <span class="attr">order:</span> <span class="number">1</span> <span class="comment"># Sort of order. 1, asc for ascending; -1, desc for descending</span></span><br><span class="line">    <span class="attr">sort_order:</span> <span class="comment"># Don&#x27;t modify the setting unless you know how it works</span></span><br><span class="line">  <span class="attr">card_archives:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">monthly</span> <span class="comment"># yearly or monthly</span></span><br><span class="line">    <span class="attr">format:</span> <span class="string">MMMM</span> <span class="string">YYYY</span> <span class="comment"># eg: YYYY年MM月</span></span><br><span class="line">    <span class="attr">order:</span> <span class="number">-1</span> <span class="comment"># Sort of order. 1, asc for ascending; -1, desc for descending</span></span><br><span class="line">    <span class="attr">limit:</span> <span class="number">8</span> <span class="comment"># if set 0 will show all</span></span><br><span class="line">    <span class="attr">sort_order:</span> <span class="comment"># Don&#x27;t modify the setting unless you know how it works</span></span><br><span class="line">  <span class="attr">card_webinfo:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">post_count:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">last_push_date:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">sort_order:</span> <span class="comment"># Don&#x27;t modify the setting unless you know how it works</span></span><br><span class="line">  <span class="attr">card_post_series:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">orderBy:</span> <span class="string">&#x27;date&#x27;</span> <span class="comment"># Order by title or date</span></span><br><span class="line">    <span class="attr">order:</span> <span class="number">-1</span> <span class="comment"># Sort of order. 1, asc for ascending; -1, desc for descending</span></span><br><span class="line"></span><br><span class="line"><span class="attr">social:</span></span><br><span class="line">  <span class="comment"># fab fa-github: https://github.com/Anti-Entrophic || Github || &#x27;#24292e&#x27;</span></span><br></pre></td></tr></table></figure><p><code>aside</code> 的注释很详细，对照着看就知道功能了。<code>social</code> 指的是在 Follow me 下面出现的图标。</p>]]></content>
      
      
      <categories>
          
          <category> Hexo &amp; Butterfly tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo &amp; Butterfly tutorial </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客时间线</title>
      <link href="/posts/d87f7e0c.html"/>
      <url>/posts/d87f7e0c.html</url>
      
        <content type="html"><![CDATA[<div class="timeline undefined"><div class='timeline-item headline'><div class='timeline-item-title'><div class='item-circle'><p>2023</p></div></div></div><div class='timeline-item'><div class='timeline-item-title'><div class='item-circle'><p>10-13</p></div></div><div class='timeline-item-content'><p>完成博客基础建设与部署</p></div></div></div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/4a17b156.html"/>
      <url>/posts/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* @font-face {  font-family: Candyhome;  src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/Candyhome.ttf);  font-display: swap;  font-weight: lighter;} */@font-face {    font-family: ZhuZiAYuanJWD;    src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2);    font-display: swap;    font-weight: lighter;  }    body {    font-family: "ZhuZiAYuanJWD";  }  div#menus {    font-family: "ZhuZiAYuanJWD";  }  h1#site-title {    font-family: ZhuZiAYuanJWD;    font-size: 3em !important;  }  a.article-title,  a.blog-slider__title,  a.categoryBar-list-link,  h1.post-title {    font-family: ZhuZiAYuanJWD;  }    .iconfont {    font-family: "iconfont" !important;    font-size: 3em;    /* 可以定义图标大小 */    font-style: normal;    -webkit-font-smoothing: antialiased;    -moz-osx-font-smoothing: grayscale;  }    /* 时间轴生肖icon */  svg.icon {    /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */    width: 1em;    height: 1em;    /* width和height定义图标的默认宽度和高度*/    vertical-align: -0.15em;    fill: currentColor;    overflow: hidden;  }    .icon-zhongbiao::before {    color: #f7c768;  }    /* bilibli番剧插件 */  #article-container .bangumi-tab.bangumi-active {    background: var(--anzhiyu-theme);    color: var(--anzhiyu-ahoverbg);    border-radius: 10px;  }  a.bangumi-tab:hover {    text-decoration: none !important;  }  .bangumi-button:hover {    background: var(--anzhiyu-theme) !important;    border-radius: 10px !important;    color: var(--anzhiyu-ahoverbg) !important;  }  a.bangumi-button.bangumi-nextpage:hover {    text-decoration: none !important;  }  .bangumi-button {    padding: 5px 10px !important;  }    a.bangumi-tab {    padding: 5px 10px !important;  }  svg.icon.faa-tada {    font-size: 1.1em;  }  .bangumi-info-item {    border-right: 1px solid #f2b94b;  }  .bangumi-info-item span {    color: #f2b94b;  }  .bangumi-info-item em {    color: #f2b94b;  }    /* 解决artitalk的图标问题 */  #uploadSource > svg {    width: 1.19em;    height: 1.5em;  }    /*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */  #page-header:not(.not-top-img):before {    background-color: transparent !important;  }    /* 首页文章卡片 */  #recent-posts > .recent-post-item {    background: rgba(255, 255, 255, 0.9);  }    /* 首页侧栏卡片 */  #aside-content .card-widget {    background: rgba(255, 255, 255, 0.9);  }    /* 文章页面正文背景 */  div#post {    background: rgba(255, 255, 255, 0.9);  }    /* 分页页面 */  div#page {    background: rgba(255, 255, 255, 0.9);  }    /* 归档页面 */  div#archive {    background: rgba(255, 255, 255, 0.9);  }    /* 标签页面 */  div#tag {    background: rgba(255, 255, 255, 0.9);  }    /* 分类页面 */  div#category {    background: rgba(255, 255, 255, 0.9);  }    /*夜间模式伪类遮罩层透明*/  [data-theme="dark"] #recent-posts > .recent-post-item {    background: #121212;  }    [data-theme="dark"] .card-widget {    background: #121212 !important;  }    [data-theme="dark"] div#post {    background: #121212 !important;  }    [data-theme="dark"] div#tag {    background: #121212 !important;  }    [data-theme="dark"] div#archive {    background: #121212 !important;  }    [data-theme="dark"] div#page {    background: #121212 !important;  }    [data-theme="dark"] div#category {    background: #121212 !important;  }    [data-theme="dark"] div#category {    background: transparent !important;  }  /* 页脚透明 */  #footer {    background: transparent !important;  }    /* 头图透明 */  #page-header {    background: transparent !important;  }    #rightside > div > button {    border-radius: 5px;  }    /* 滚动条 */    ::-webkit-scrollbar {    width: 10px;    height: 10px;  }    ::-webkit-scrollbar-thumb {    background-color: #3b70fc;    border-radius: 2em;  }    ::-webkit-scrollbar-corner {    background-color: transparent;  }    ::-moz-selection {    color: #fff;    background-color: #3b70fc;  }    /* 音乐播放器 */    /* .aplayer .aplayer-lrc {    display: none !important;  } */    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {    left: -66px !important;    transition: all 0.3s;    /* 默认情况下缩进左侧66px，只留一点箭头部分 */  }    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {    left: 0 !important;    transition: all 0.3s;    /* 鼠标悬停是左侧缩进归零，完全显示按钮 */  }    .aplayer.aplayer-fixed {    z-index: 999999 !important;  }    /* 评论框  */  .vwrap {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 30px 0px;  }    /* 设置评论框 */    .vcard {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 0px 0px;  }    /* md网站下划线 */  #article-container a:hover {    text-decoration: none !important;  }    #article-container #hpp_talk p img {    display: inline;  }    /* 404页面 */  #error-wrap {    position: absolute;    top: 40%;    right: 0;    left: 0;    margin: 0 auto;    padding: 0 1rem;    max-width: 1000px;    transform: translate(0, -50%);  }    #error-wrap .error-content {    display: flex;    flex-direction: row;    justify-content: center;    align-items: center;    margin: 0 1rem;    height: 18rem;    border-radius: 8px;    background: var(--card-bg);    box-shadow: var(--card-box-shadow);    transition: all 0.3s;  }    #error-wrap .error-content .error-img {    box-flex: 1;    flex: 1;    height: 100%;    border-top-left-radius: 8px;    border-bottom-left-radius: 8px;    background-color: #3b70fc;    background-position: center;    background-size: cover;  }    #error-wrap .error-content .error-info {    box-flex: 1;    flex: 1;    padding: 0.5rem;    text-align: center;    font-size: 14px;    font-family: Titillium Web, "PingFang SC", "Hiragino Sans GB", "Microsoft JhengHei", "Microsoft YaHei", sans-serif;  }  #error-wrap .error-content .error-info .error_title {    margin-top: -4rem;    font-size: 9em;  }  #error-wrap .error-content .error-info .error_subtitle {    margin-top: -3.5rem;    word-break: break-word;    font-size: 1.6em;  }  #error-wrap .error-content .error-info a {    display: inline-block;    margin-top: 0.5rem;    padding: 0.3rem 1.5rem;    background: var(--btn-bg);    color: var(--btn-color);  }    #body-wrap.error .aside-list {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    bottom: 0px;    position: absolute;    padding: 1rem;    width: 100%;    overflow: scroll;  }    #body-wrap.error .aside-list .aside-list-group {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    max-width: 1200px;    margin: 0 auto;  }    #body-wrap.error .aside-list .aside-list-item {    padding: 0.5rem;  }    #body-wrap.error .aside-list .aside-list-item img {    width: 100%;    object-fit: cover;    border-radius: 12px;  }    #body-wrap.error .aside-list .aside-list-item .thumbnail {    overflow: hidden;    width: 230px;    height: 143px;    background: var(--anzhiyu-card-bg);    display: flex;  }    #body-wrap.error .aside-list .aside-list-item .content .title {    -webkit-line-clamp: 2;    overflow: hidden;    display: -webkit-box;    -webkit-box-orient: vertical;    line-height: 1.5;    justify-content: center;    align-items: flex-end;    align-content: center;    padding-top: 0.5rem;    color: white;  }    #body-wrap.error .aside-list .aside-list-item .content time {    display: none;  }    /* 代码框主题 */  #article-container figure.highlight {    border-radius: 10px;  }]]></content>
      
    </entry>
    
    
  
</search>
